{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec434155-c2ce-41bb-a7eb-cac30ad18f2a",
   "metadata": {},
   "source": [
    "## Trying RAG From MD Files\n",
    "\n",
    "In this notebook I will try and extract context for summarisation out of series of .md files. The idea is to create a working ChatBot on initially Streameye's Blog articles, but later Streameye Documentation once it is ready.\n",
    "\n",
    "Challenges are:\n",
    "\n",
    "- Vectorising the md files and storing them in a vector DB\n",
    "- Extracting proper context for user queries\n",
    "- Using an LLM to answer these queries from the stored data\n",
    "- Avoiding LLM hallucinations, keeping the answers concise on the supplied context\n",
    "\n",
    "#### Resources\n",
    "\n",
    "Great resource by Venelin Valkov [here](https://www.mlexpert.io/prompt-engineering/langchain-quickstart-with-llama-2)\n",
    "\n",
    "Youtube tutorial and resource that explain the process with OpenAI's embeddings instead of HF [here](https://www.youtube.com/watch?v=tcqEUSNCn8I)\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "#### Loading the md files and tokenising\n",
    "\n",
    "Its good idea to split big documents or long texts into chunks. The idea is to load them faster and to make each chunk more focused and relevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2560a28b-babc-48b4-9ff2-97865dd9a26b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Downloading unstructured-0.12.2-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting chardet (from unstructured)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Downloading lxml-5.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting tabulate (from unstructured)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from unstructured) (4.12.2)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.10.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.11/site-packages (from unstructured) (0.6.3)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2024.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from unstructured) (1.26.2)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from unstructured) (4.9.0)\n",
      "Collecting unstructured-client>=0.15.1 (from unstructured)\n",
      "  Downloading unstructured_client-0.15.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (3.3.2)\n",
      "Requirement already satisfied: idna>=3.4 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (3.6)\n",
      "Collecting jsonpath-python>=1.0.6 (from unstructured-client>=0.15.1->unstructured)\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: marshmallow>=3.19.0 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (3.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (1.0.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (2.8.2)\n",
      "Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (1.16.0)\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (0.9.0)\n",
      "Requirement already satisfied: urllib3>=1.26.18 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (2.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Collecting click (from nltk->unstructured)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk->unstructured) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk->unstructured) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk->unstructured) (4.66.1)\n",
      "Downloading unstructured-0.12.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_client-0.15.2-py3-none-any.whl (20 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading emoji-2.10.0-py2.py3-none-any.whl (457 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.9/457.9 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lxml-5.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_iso639-2024.1.2-py3-none-any.whl (274 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=5fb3417737cc697b10f6eb5c4ff8ba9ed9c82bdbd68060c9be917c8d85c52e05\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "Successfully built langdetect\n",
      "Installing collected packages: filetype, wrapt, tabulate, rapidfuzz, python-magic, python-iso639, lxml, langdetect, jsonpath-python, emoji, click, chardet, backoff, nltk, unstructured-client, unstructured\n",
      "Successfully installed backoff-2.2.1 chardet-5.2.0 click-8.1.7 emoji-2.10.0 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 lxml-5.1.0 nltk-3.8.1 python-iso639-2024.1.2 python-magic-0.4.27 rapidfuzz-3.6.1 tabulate-0.9.0 unstructured-0.12.2 unstructured-client-0.15.2 wrapt-1.16.0\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m974.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.36.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (2.1.2)\n",
      "Collecting torchvision (from sentence-transformers)\n",
      "  Downloading torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.26.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (3.8.1)\n",
      "Collecting sentencepiece (from sentence-transformers)\n",
      "  Downloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (0.20.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence-transformers) (12.3.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision->sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Downloading torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=34b5fcb40a3efe80a7c33625dbca36f4dffb7fe05ac25988c4420d2f0cf22a99\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/ff/27/bf/ffba8b318b02d7f691a57084ee154e26ed24d012b0c7805881\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, torchvision, sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99 torchvision-0.16.2\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.4.22-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.11/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /opt/conda/lib/python3.11/site-packages (from chromadb) (2.5.3)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.109.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.26.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /opt/conda/lib/python3.11/site-packages (from chromadb) (1.26.2)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.3.2-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.11/site-packages (from chromadb) (4.9.0)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
      "  Downloading pulsar_client-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.22.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.22.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.22.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.11/site-packages (from chromadb) (0.15.0)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.11/site-packages (from chromadb) (4.66.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.11/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.11/site-packages (from chromadb) (6.1.1)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.60.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/conda/lib/python3.11/site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /opt/conda/lib/python3.11/site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=19.0 in /opt/conda/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting starlette<0.36.0,>=0.35.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading starlette-0.35.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2023.11.17)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.26.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/conda/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.1.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m807.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.22.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.22.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.22.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.22.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.43b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.2.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.7.2-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.6)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/conda/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb) (0.20.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting h11>=0.8 (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.11/site-packages (from starlette<0.36.0,>=0.35.0->fastapi>=0.95.2->chromadb) (4.1.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.36.0,>=0.35.0->fastapi>=0.95.2->chromadb) (1.3.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading chromadb-0.4.22-py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.0/509.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading build-1.0.3-py3-none-any.whl (18 kB)\n",
      "Downloading fastapi-0.109.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.60.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.22.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.22.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.22.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.22.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl (28 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl (14 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.43b0-py3-none-any.whl (36 kB)\n",
      "Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.22.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading posthog-3.3.2-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pulsar_client-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.26.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading google_auth-2.26.2-py2.py3-none-any.whl (186 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.5/186.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.7/228.7 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.5/318.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Downloading protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.35.1-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=fe23c53cb3b717cac37d6883134c7aebac642fa3dc926a8ec0da31181ef7834c\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, mmh3, flatbuffers, websockets, uvloop, typer, python-dotenv, pyproject_hooks, pyasn1, pulsar-client, protobuf, opentelemetry-util-http, opentelemetry-semantic-conventions, importlib-metadata, humanfriendly, httptools, h11, grpcio, deprecated, chroma-hnswlib, cachetools, bcrypt, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, opentelemetry-api, googleapis-common-protos, coloredlogs, build, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, onnxruntime, google-auth, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, kubernetes, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 7.0.0\n",
      "    Uninstalling importlib-metadata-7.0.0:\n",
      "      Successfully uninstalled importlib-metadata-7.0.0\n",
      "Successfully installed asgiref-3.7.2 bcrypt-4.1.2 build-1.0.3 cachetools-5.3.2 chroma-hnswlib-0.7.3 chromadb-0.4.22 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.109.0 flatbuffers-23.5.26 google-auth-2.26.2 googleapis-common-protos-1.62.0 grpcio-1.60.0 h11-0.14.0 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-6.11.0 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.16.3 opentelemetry-api-1.22.0 opentelemetry-exporter-otlp-proto-common-1.22.0 opentelemetry-exporter-otlp-proto-grpc-1.22.0 opentelemetry-instrumentation-0.43b0 opentelemetry-instrumentation-asgi-0.43b0 opentelemetry-instrumentation-fastapi-0.43b0 opentelemetry-proto-1.22.0 opentelemetry-sdk-1.22.0 opentelemetry-semantic-conventions-0.43b0 opentelemetry-util-http-0.43b0 posthog-3.3.2 protobuf-4.25.2 pulsar-client-3.4.0 pyasn1-0.5.1 pyasn1-modules-0.3.0 pypika-0.48.9 pyproject_hooks-1.0.0 python-dotenv-1.0.0 requests-oauthlib-1.3.1 rsa-4.9 starlette-0.35.1 typer-0.9.0 uvicorn-0.26.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
     ]
    }
   ],
   "source": [
    "# Installs - need to restart notebook after installs!\n",
    "\n",
    "!pip install unstructured\n",
    "!pip install sentence-transformers\n",
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4682c00c-3ace-44b0-a3f3-ec8bc220b0e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured[md] in /opt/conda/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: chardet in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (5.2.0)\n",
      "Requirement already satisfied: filetype in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (0.4.27)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (5.1.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (0.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (4.12.2)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (2.10.0)\n",
      "Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (0.6.3)\n",
      "Requirement already satisfied: python-iso639 in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (2024.1.2)\n",
      "Requirement already satisfied: langdetect in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (1.0.9)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (1.26.2)\n",
      "Requirement already satisfied: rapidfuzz in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (3.6.1)\n",
      "Requirement already satisfied: backoff in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (4.9.0)\n",
      "Requirement already satisfied: unstructured-client>=0.15.1 in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (0.15.2)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from unstructured[md]) (1.16.0)\n",
      "Collecting markdown (from unstructured[md])\n",
      "  Downloading Markdown-3.5.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured[md]) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured[md]) (3.3.2)\n",
      "Requirement already satisfied: idna>=3.4 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured[md]) (3.6)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured[md]) (1.0.6)\n",
      "Requirement already satisfied: marshmallow>=3.19.0 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured[md]) (3.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured[md]) (1.0.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured[md]) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured[md]) (2.8.2)\n",
      "Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured[md]) (1.16.0)\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured[md]) (0.9.0)\n",
      "Requirement already satisfied: urllib3>=1.26.18 in /opt/conda/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured[md]) (2.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->unstructured[md]) (2.5)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk->unstructured[md]) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk->unstructured[md]) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk->unstructured[md]) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk->unstructured[md]) (4.66.1)\n",
      "Downloading Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m803.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m0:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: markdown\n",
      "Successfully installed markdown-3.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install \"unstructured[md]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b31e32df-c5c8-4422-9fe0-7cda87be9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Includes\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.evaluation import load_evaluator\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
    "\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f043b2-49ae-4326-b3de-1bbb894618b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/streameye_blog/\"\n",
    "CHROMA_PATH = \"./data/streameye_blog/db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178dd03f-f434-41cf-ac49-4a8d05decb12",
   "metadata": {},
   "source": [
    "To split text into chunks we use the **RecursieveCharacterTextSplitter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "956092c3-a84a-4445-9b14-6d2417b4d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents():\n",
    "    loader = DirectoryLoader(DATA_PATH, glob=\"*.md\")\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "def split_text(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        add_start_index=True\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9c38cc6-b33f-4014-8211-459c98d69a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_chroma(chunks: list[Document]):\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH) ## Recursive delete\n",
    "    db = Chroma.from_documents(chunks, HuggingFaceEmbeddings(), persist_directory=CHROMA_PATH)\n",
    "    db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c1e6c6-0ef6-477e-8514-caecd14efc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "docs = load_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd8ae85-5942-4de3-9fbe-3405d674d372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 37 documents into 569 chunks.\n"
     ]
    }
   ],
   "source": [
    "chunks = split_text(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "955af15a-48cc-4a19-9e95-53f87d6f22dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9328717e1f3f4f1da6af86dc11175662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e582a27e1ad470dbb0ca3a2ddfca7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b085a064d8b4417386bf421b6b7f3012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac376cdd65d4941bf6b94616d19b55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b5dacefa3c4753a9e5a1a51e24d289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888ec9ff1190479499ec31567b70186a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb93d68d790a4bfe9c83b5ca384bb986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6479efc42754e7f94fb9a3a88721544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cea1ee69a294ee2914c8d7a2bf2599e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f401b66414584512885e4b49232db64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98ec3760c1b4062bb1473bba819fb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed1aaf283594710ac58d696c8116d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08d92a1b3d146c39e32ab7247add279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f584015c5e3e4f38870590298a6d64ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_to_chroma(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b64e71-0989-49f6-a086-a3ea5fc1fd9b",
   "metadata": {},
   "source": [
    "This is pretty bad running with the default HF Embeddings. Lets try and put a better LLM to be used. Lets try with a relatively small one first as I dont know if RAM is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee45e57a-08df-4cb0-85e7-1dca4d537035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.5988499147809145}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_evaluator = load_evaluator(\"pairwise_embedding_distance\", embeddings=HuggingFaceEmbeddings())\n",
    "hf_evaluator.evaluate_string_pairs(prediction=\"apple\", prediction_b=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924d343f-1b97-48ae-ae17-b4cbfdb4e64f",
   "metadata": {},
   "source": [
    "The above result is not good I think. OpenAI gives a vector distance of 0.1349. Compare with an LLM.\n",
    "\n",
    "Here are some source models for generating embedings: [hf embeddings](https://huggingface.co/thenlper/gte-large)\n",
    "\n",
    "A regular LLM like MS/phi-2 is not finetuned to supply embeddings. It also does not have a default padding token id in the tokenizer.. and results in errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d4c842d-2d95-4e10-b788-a94f2bc8535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"microsoft/phi-2\"\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c1727b2-fcf1-4769-afc5-d48254999caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de5bc3442a24e4d8cd16862025f38f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", trust_remote_code=True, load_in_8bit=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c3738-1e3e-4cce-92d5-6d13e0e5f527",
   "metadata": {},
   "source": [
    "Using the \"thenlper/gte-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f48fe24c-07ad-42c5-a496-b49a46e3351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gte_large = HuggingFaceEmbeddings(model_name=\"./data/embeddings/gte-large/\", \n",
    "                                       model_kwargs={\"device\": \"cuda\"}, \n",
    "                                       encode_kwargs={\"normalize_embeddings\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a654575c-38f2-4b69-94ee-9d21d21bdd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.08266134804374758}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_evaluator = load_evaluator(\"pairwise_embedding_distance\", embeddings=gte_large)\n",
    "hf_evaluator.evaluate_string_pairs(prediction=\"apple\", prediction_b=\"iphone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ff1b7b-33de-4c32-806f-eabf0ba8c2a1",
   "metadata": {},
   "source": [
    "Results in a pretty good score for distance between **apple** and **orange**! Calculated distance as per above is **0.179**!\n",
    "\n",
    "Remember OpenAI gives a score of **0.135** while the default HuggingFaceEmbeddings gives a score of **0.599**\n",
    "\n",
    "Now that we know this, we will run the `save_to_chroma()` with another parameter - the function to be used to create the embeddings. Like below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a58157-38fb-4bf5-80d5-c56b2b8f8c8e",
   "metadata": {},
   "source": [
    "### Saving the DB to persist on Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5d1d403-4db4-4c80-99b1-6d3b00b81e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_chroma_with_embeddings(chunks: list[Document], embeddings):\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH) ## Recursive delete\n",
    "    db = Chroma.from_documents(chunks, embeddings, persist_directory=CHROMA_PATH)\n",
    "    db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f92c812c-c223-4b53-8945-76bf75d632c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 37 documents into 569 chunks.\n"
     ]
    }
   ],
   "source": [
    "docs = load_documents()\n",
    "chunks = split_text(docs)\n",
    "save_to_chroma_with_embeddings(chunks, gte_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d8fe03-aac5-4d21-a73d-098f69c0a195",
   "metadata": {},
   "source": [
    "### Loading the Database\n",
    "\n",
    "We need to use the same embedding function that we used to create the DB and the path the DB. Like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd504f8-33a0-4f1e-82c1-35865663c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma(persist_directory=CHROMA_PATH, embedding_function=gte_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cf0ae65-64c4-483a-9ba5-7698d5db3afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ads that highlight the social aspect of sports betting'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = db.similarity_search_with_relevance_scores(\"What can sports betting ads be used for\", k=2)\n",
    "results[1][0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac5b8b6-e484-4560-aca7-104ec12f3cab",
   "metadata": {},
   "source": [
    "The results of this operation is actually relevant chunks from the vectorised documents that we can use as context to the LLM that can then provide a direct response to the question.\n",
    "\n",
    "First lets create the template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e870c42b-df9d-451e-8e13-9c4d33a7c1a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PromptTemplate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m PROMPT_TEMPLATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m<s>[INST]Answer the question based only on the following context and the chat history:\u001b[39m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;124m[/INST]\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[43mPromptTemplate\u001b[49m(template\u001b[38;5;241m=\u001b[39mPROMPT_TEMPLATE, input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PromptTemplate' is not defined"
     ]
    }
   ],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "<s>[INST]Answer the question based only on the following context and the chat history:\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "History: {history}\n",
    "\n",
    "Question: {question}[/INST]\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=PROMPT_TEMPLATE, input_variables=[\"context\", \"question\", \"history\"])\n",
    "# context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da7e5a0-5736-4f73-a0e6-5bb2af81dc88",
   "metadata": {},
   "source": [
    "### Creating the RetreivalQA Chain\n",
    "\n",
    "I am not sure how this will pass in the question and context. We dont seem to specify these anywhere..\n",
    "\n",
    "The Retreival API expects a pipeline however, not the actual model. So we use the HuggingFace pipeline with configuration to return a pipeline object to the RetreivalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca6f9693-3b40-41f4-b07b-2563db530aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "generation_config.max_new_tokens = 512\n",
    "generation_config.temperature = 0.01\n",
    "generation_config.top_p = 0.95\n",
    "generation_config.do_sample = True\n",
    "generation_config.repetition_penalty = 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4964a5f9-98ce-4481-b731-e9e7caefa679",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=text_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bd66f1e-0125-467b-8bc2-9ff55fe4a721",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt, \"memory\": ConversationBufferMemory(\n",
    "            memory_key=\"history\",\n",
    "            input_key=\"question\")},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86ba7d59-4eb9-4fcd-b100-81c55b3034b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Chain.dict of RetrievalQA(combine_documents_chain=StuffDocumentsChain(memory=ConversationBufferMemory(input_key='question'), llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['context', 'history', 'question'], template='\\n<s>[INST]Answer the question based only on the following context and the chat history:\\n\\nContext: {context}\\n\\nHistory: {history}\\n\\nQuestion: {question}[/INST]\\n'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7f38dcc19750>)), document_variable_name='context'), return_source_documents=True, retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7f39100ae4d0>, search_kwargs={'k': 3}))>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fd6b023-abdb-46cd-8e42-1f6670c93615",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = \"\\n\".join([doc.metadata[\"source\"] for doc in result[\"source_documents\"]])\n",
    "result[\"sources\"] = sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "340f7185-dedf-4ada-91e7-d16b5ab89a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My question:\n",
      "Could you give me some brief explanation about animated skins? I saw an article about them.\n",
      "\n",
      "Answer:\n",
      "Animated skins are a type of advertising format where a background image or design comes to life with motion and animation. They function as a non-intrusive, visually appealing backdrop for ads, allowing them to stand out on websites and apps without disrupting the user experience. Animated skins are fully responsive, adapting to various screen sizes and devices, making them suitable for multi-platform campaigns. Their use has become popular among advertisers seeking to create more engaging and memorable ads. While takeover skins have been in existence for some time, there's been a recent surge in interest due to their effectiveness in capturing audience attention.\n",
      "\n",
      "Sources:\n",
      "data/streameye_blog/How_Animated_Skins_Will_Revolutionize_Big_Ad_Campaigns.md\n",
      "data/streameye_blog/How_Animated_Skins_Will_Revolutionize_Big_Ad_Campaigns.md\n",
      "data/streameye_blog/How_Animated_Skins_Will_Revolutionize_Big_Ad_Campaigns.md\n"
     ]
    }
   ],
   "source": [
    "# sources = [doc[\"metadata\"][\"source\"] for doc in result[\"source_documents\"]]\n",
    "print(\"My question:\\n{query}\\n\\nAnswer:\\n{result}\\n\\nSources:\\n{sources}\".format(**result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07843a65-398f-47bf-8aed-aaeda0cb5bac",
   "metadata": {},
   "source": [
    "#### Implement History Later\n",
    "\n",
    "[here](https://stackoverflow.com/questions/76240871/how-do-i-add-memory-to-retrievalqa-from-chain-type-or-how-do-i-add-a-custom-pr) there seems to be a solution\n",
    "\n",
    "implemented above.\n",
    "\n",
    "### Checking out Gradio\n",
    "\n",
    "Try and use Gradio to take in some prompt and output some basic formatted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "514d29e0-9612-4a8b-9c3e-f79a41eaf6db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-4.15.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio)\n",
      "  Downloading altair-5.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.11/site-packages (from gradio) (0.109.0)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gradio-client==0.8.1 (from gradio)\n",
      "  Downloading gradio_client-0.8.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx (from gradio)\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.11/site-packages (from gradio) (0.20.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.11/site-packages (from gradio) (6.1.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (3.8.2)\n",
      "Requirement already satisfied: numpy~=1.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (1.26.2)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.9.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (2.1.4)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (10.1.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (2.5.3)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart (from gradio)\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.1.7 (from gradio)\n",
      "  Downloading ruff-0.1.14-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /opt/conda/lib/python3.11/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (0.26.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from gradio-client==0.8.1->gradio) (2023.10.0)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==0.8.1->gradio)\n",
      "  Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio) (4.20.0)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0->gradio) (2.14.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.11/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
      "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich<14.0.0,>=10.11.0 (from typer[all]<1.0,>=0.9->gradio)\n",
      "  Downloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /opt/conda/lib/python3.11/site-packages (from fastapi->gradio) (0.35.1)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx->gradio) (4.1.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx->gradio) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx->gradio)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from httpx->gradio) (3.6)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.17.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.1.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading gradio-4.15.0-py3-none-any.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-0.8.1-py3-none-any.whl (305 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading altair-5.2.0-py3-none-any.whl (996 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.9/996.9 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.9.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruff-0.1.14-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=3a919cd924759efe7e5ae165525711acb485e11d8ecb6b2915e58743dd5612e2\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/99/3b/84/22ac1eab7a10222ac6bbc3f7e69b04f3980db328978c533a3f\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, toolz, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, mdurl, httpcore, aiofiles, markdown-it-py, httpx, rich, gradio-client, altair, gradio\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 12.0\n",
      "    Uninstalling websockets-12.0:\n",
      "      Successfully uninstalled websockets-12.0\n",
      "Successfully installed aiofiles-23.2.1 altair-5.2.0 ffmpy-0.3.1 gradio-4.15.0 gradio-client-0.8.1 httpcore-1.0.2 httpx-0.26.0 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.9.12 pydub-0.25.1 python-multipart-0.0.6 rich-13.7.0 ruff-0.1.14 semantic-version-2.10.0 shellingham-1.5.4 tomlkit-0.12.0 toolz-0.12.0 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f39757-ee6f-4d92-8371-e94715946d7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def chatter(message, history):\n",
    "    result = qa_chain(message)\n",
    "    sources = \"\\n\".join([doc.metadata[\"source\"] for doc in result[\"source_documents\"]])\n",
    "    return f\"{result['result']}\\n\\nSources:{sources}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc7e2a-728d-45d9-aa21-78617dec1537",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.ChatInterface(chatter).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a735611-ffd2-465e-b394-dad6928e357c",
   "metadata": {},
   "source": [
    "#### Try gradio with threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21867d4d-6e39-4637-9344-3849cb3bbd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://6fdc30d7cba913e4a8.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6fdc30d7cba913e4a8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    <s>[INST]Answer the question based only on the following context and the chat history:\n",
      "    \n",
      "    Context: Animated skins are increasingly being used by advertisers to make their online campaigns more visually appealing and interactive. These skins are essentially background wallpapers that can be used to display ads without interfering with the site’s original content.\n",
      "\n",
      "While takeover skins have been around for years, they have recently gained attention due to their effectiveness. In fact, many advertisers are turning to takeover skins to make their ads more engaging and memorable.\n",
      "\n",
      "Isn’t that just a takeover skin?\n",
      "\n",
      "Takeover skins are generally static, but it is possible to create dynamic ones with tools like StreamEye. They are generally created to take advantage of full HD resolution (1920x1080) and are designed to fit the dimensions of the site’s content. However, takeover skins are generally aimed at desktop users because there just isn’t a good way to display content on the margins for a tall and narrow phone screen.\n",
      "\n",
      "Once you combine the takeover skin placeholder with the responsive banner functions, there comes her majesty, the animated skin, which we are discussing in today’s post.\n",
      "\n",
      "The Power of Animated Skins\n",
      "    \n",
      "    History: \n",
      "<human>:what are takeover skins?\n",
      "<bot>:\n",
      "    \n",
      "    Question: what are takeover skins?[/INST]\n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    <s>[INST]Answer the question based only on the following context and the chat history:\n",
      "    \n",
      "    Context: and even sound. And do not worry at all, because HTML banners are compatible with all devices and screen sizes, which means that you can retarget your potential clients on both mobile and desktop.\n",
      "\n",
      "Have you noticed how attached are people to their phones? Well, the digital marketing industry has not missed it, either. Mobile advertising is on the rise in the last few years and experts believe it could reach a revenue of $384.9 billion by 2023. If you do not want to be left behind, HTML5 banners are the way to go. They are compatible with different devices and screen sizes and are easy to optimize according to your needs. In other words, they will function flawlessly regardless of where\n",
      "\n",
      "Have all the advantages of the HTML5 banners in mind, If you are looking to create a successful mobile campaign. Apart from being adaptable, they offer a variety of dynamic features that are hard to compare to the animated GIFs’ limited arsenal.\n",
      "\n",
      "Interactivity gets the attention\n",
      "    \n",
      "    History: \n",
      "<human>:what are takeover skins?\n",
      "<bot>: Takeover skins are large-format advertising designs that cover an entire webpage or app screen, replacing the existing background or design. They are called \"takeover\" because they take over the entire space, providing maximum visibility for advertisements. While traditional takeover skins are usually static images, newer versions can also include animations or videos to make them more engaging and memorable for users.\n",
      "\n",
      "Sources:data/streameye_blog/How_Animated_Skins_Will_Revolutionize_Big_Ad_Campaigns.md\n",
      "data/streameye_blog/How_Animated_Skins_Will_Revolutionize_Big_Ad_Campaigns.md\n",
      "data/streameye_blog/How_Animated_Skins_Will_Revolutionize_Big_Ad_Campaigns.md\n",
      "<human>:can they be used in mobile devices?\n",
      "<bot>:\n",
      "    \n",
      "    Question: can they be used in mobile devices?[/INST]\n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    <s>[INST]Answer the question based only on the following context and the chat history:\n",
      "    \n",
      "    Context: 3. HTML5 banners are the next iteration of animated online ads. Similar to Flash, they provide interactive and feature-rich options but without the need for extra software or compatibility concerns across different browsers and devices. HTML5 banners have long replaced Flash and are soon to do the same with animated GIFs. They are smaller in size and at the same time you can embed Rich Media features thanks to the fact that HTML5 ads also use CSS and Javascript. This means that you can add\n",
      "\n",
      "1. Animated GIF banners came after the static ads. GIF stands for Graphic Interchange Format. GIF banners have the .gif extension and can be either static or animated. Because of their nature, they are the middle ground between static and video. Animated GIF banners are composed of a number of images (frames) that create a sense of motion when exported. Compared to videos in terms of size, animated GIF banners are smaller but still offer dynamic elements. The first-ever GIF was introduced in\n",
      "\n",
      "HTML5 banners are efficient, lightweight, and built to last. That's because HTML5 banners use vector graphics and other modern technologies. They are faster to load and easier on the bandwidth, thus not weighing down the website. GIFs, on the other hand, may have taken over social media, but when it comes to banners, they could be up to 20 times larger than HTML5 files, making them slower to load. This is a huge no-no in the ad world because no one wants to sit around and wait, right? And as an\n",
      "    \n",
      "    History: \n",
      "<human>:what are takeover skins?\n",
      "<bot>: Takeover skins are large-format advertising designs that cover an entire webpage or app screen, replacing the existing background or design. They are called \"takeover\" because they take over the entire space, providing maximum visibility for advertisements. While traditional takeover skins are usually static images, newer versions can also include animations or videos to make them more engaging and memorable for users.\n",
      "\n",
      "Sources:data/streameye_blog/How_Animated_Skins_Will_Revolutionize_Big_Ad_Campaigns.md\n",
      "data/streameye_blog/How_Animated_Skins_Will_Revolutionize_Big_Ad_Campaigns.md\n",
      "data/streameye_blog/How_Animated_Skins_Will_Revolutionize_Big_Ad_Campaigns.md\n",
      "<human>:can they be used in mobile devices?\n",
      "<bot>: Yes, takeover skins can be used on mobile devices. However, it's important to note that designing takeover skins for mobile requires careful consideration of smaller screens and touch interactions. HTML5 banners, which can be used to create interactive and dynamic takeover skins, are particularly well-suited for mobile advertising due to their compatibility with various devices and screen sizes.\n",
      "\n",
      "Sources:data/streameye_blog/Display_Ad_Retargeting_Why_Your_Business_Needs_It.md\n",
      "data/streameye_blog/Why_HTML5_Are_Showing_GIFs_The_Door.md\n",
      "data/streameye_blog/Why_HTML5_Are_Showing_GIFs_The_Door.md\n",
      "<human>:OK.. can you compare GIFs to HTML5 animated banners? list 3 points of comaprison\n",
      "<bot>:\n",
      "    \n",
      "    Question: OK.. can you compare GIFs to HTML5 animated banners? list 3 points of comaprison[/INST]\n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    <s>[INST]Answer the question based only on the following context and the chat history:\n",
      "    \n",
      "    Context: Find out how you can create your own HTML5 banner campaign on Streameye’s platform.\n",
      "\n",
      "The animated banner evolution: From animated GIFs to HTML5\n",
      "\n",
      "At Streameye, we make creative work more flexible and agile with a platform that requires less effort from your team. And yes, animated ads production is included and very cost-effective, too. It allows you to become more responsive to market changes and your competitors' actions. With Streameye, you can tweak creatives, update messaging, and change your offers in a matter of minutes, without the help of a developer or even a senior designer. Your custom templates and vast visual library mean\n",
      "\n",
      "At Streameye, we make creative work more flexible and agile with a platform that requires less effort from your team. And yes, animated ads production is included and very cost-effective, too. It allows you to become more responsive to market changes and your competitors' actions. With Streameye, you can tweak creatives, update messaging, and change your offers in a matter of minutes, without the help of a developer or even a senior designer. Your custom templates and vast visual library mean\n",
      "    \n",
      "    History: \n",
      "<human>:Can Streameye create animated GIFs. I want to create some for my emails\n",
      "<bot>:\n",
      "    \n",
      "    Question: Can Streameye create animated GIFs. I want to create some for my emails[/INST]\n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    <s>[INST]Answer the question based only on the following context and the chat history:\n",
      "    \n",
      "    Context: Of course, having all of these professionals on your side is crucial for the success of the campaign that eventually you are going to launch. However, maintaining effective communication and workflow can sometimes become challenging and lead to a bit of chaos.\n",
      "\n",
      "support that will elevate your creative abilities even further. Streameye doesn't just bring you creative templates fit for your brand. Our team will be there to help you get the most out of the platform from the start and stay up to date with the latest digital creative technology. We'll proactively bring you ideas to improve your demand generation results and make use of new creative opportunities. And as much as it’s good if the creative management tool can work according to your internal\n",
      "\n",
      "support that will elevate your creative abilities even further. Streameye doesn't just bring you creative templates fit for your brand. Our team will be there to help you get the most out of the platform from the start and stay up to date with the latest digital creative technology. We'll proactively bring you ideas to improve your demand generation results and make use of new creative opportunities. And as much as it’s good if the creative management tool can work according to your internal\n",
      "    \n",
      "    History: \n",
      "<human>:Can Streameye create animated GIFs. I want to create some for my emails\n",
      "<bot>: While the context mentions the evolution from animated GIFs to HTML5 and the ability to produce animated ads using the Streameye platform, it does not explicitly state whether Streameye creates and exports animated GIFs directly. However, since the text emphasizes the flexibility and ease of creating animations within their system, it's possible that they may offer an option to export as an animated GIF if needed. To get a definitive answer, contacting Streameye's support team would be the best course of action.\n",
      "\n",
      "Sources:data/streameye_blog/Rise_Of_HTML5_Banners.md\n",
      "data/streameye_blog/Programmatic_Trends_To_Follow_In_2023.md\n",
      "data/streameye_blog/Programmatic_Trends_To_Follow_In_2022.md\n",
      "<human>:Are there any contacts given for their support?\n",
      "<bot>:\n",
      "    \n",
      "    Question: Are there any contacts given for their support?[/INST]\n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import gradio as gr\n",
    "\n",
    "class StatefulThread(Thread):\n",
    "    def __init__(self, target, args):\n",
    "        super().__init__(target=target, args=args)\n",
    "        self._result = None\n",
    "    def run(self):\n",
    "        self._result = self._target(self._args)\n",
    "    def get_result(self):\n",
    "        return self._result\n",
    "\n",
    "\n",
    "    \n",
    "def chatter(message, history):\n",
    "    PROMPT_TEMPLATE = \"\"\"\n",
    "    <s>[INST]Answer the question based only on the following context and the chat history:\n",
    "    \n",
    "    Context: {context}\n",
    "    \n",
    "    History: {history}\n",
    "    \n",
    "    Question: {question}[/INST]\n",
    "    \"\"\"\n",
    "    history_transformer_format = history + [[message, \"\"]]\n",
    "    history_str = \"\".join([\"\".join([\"\\n<human>:\"+item[0], \"\\n<bot>:\"+item[1]])  #curr_system_message +\n",
    "                for item in history_transformer_format])\n",
    "    no_history_prompt = PROMPT_TEMPLATE.replace(\"{history}\", history_str)\n",
    "    prompt = PromptTemplate(template=no_history_prompt, input_variables=[\"context\", \"question\"])\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=db.as_retriever(search_kwargs={\"k\": 3}),\n",
    "        return_source_documents=True,\n",
    "        verbose=True,\n",
    "        chain_type_kwargs={\"prompt\": prompt, \"verbose\": True}\n",
    "    )\n",
    "    t = StatefulThread(target=qa_chain, args=(message))\n",
    "    t.start()\n",
    "    t.join()\n",
    "    result = t.get_result();\n",
    "    sources = \"\\n\".join([doc.metadata[\"source\"] for doc in result[\"source_documents\"]])\n",
    "    return f\"{result['result']}\\n\\nSources:\\n{sources}\"\n",
    "\n",
    "interface = gr.ChatInterface(chatter).launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf141eda-0e59-46c7-beb2-430e4e41ac40",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMChain\nprompt\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat are takeover skins\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an AI assistant that answers questions:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m qa_chain \u001b[38;5;241m=\u001b[39m \u001b[43mRetrievalQA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_chain_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchain_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstuff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_source_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchain_type_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhistory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mStatefulThread\u001b[39;00m(Thread):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, target, args):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain/chains/retrieval_qa/base.py:105\u001b[0m, in \u001b[0;36mBaseRetrievalQA.from_chain_type\u001b[0;34m(cls, llm, chain_type, chain_type_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load chain from chain type.\"\"\"\u001b[39;00m\n\u001b[1;32m    104\u001b[0m _chain_type_kwargs \u001b[38;5;241m=\u001b[39m chain_type_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m--> 105\u001b[0m combine_documents_chain \u001b[38;5;241m=\u001b[39m \u001b[43mload_qa_chain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchain_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_chain_type_kwargs\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(combine_documents_chain\u001b[38;5;241m=\u001b[39mcombine_documents_chain, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain/chains/question_answering/__init__.py:250\u001b[0m, in \u001b[0;36mload_qa_chain\u001b[0;34m(llm, chain_type, verbose, callback_manager, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chain_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loader_mapping:\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unsupported chain type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchain_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloader_mapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m     )\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchain_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain/chains/question_answering/__init__.py:74\u001b[0m, in \u001b[0;36m_load_stuff_chain\u001b[0;34m(llm, prompt, document_variable_name, verbose, callback_manager, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_stuff_chain\u001b[39m(\n\u001b[1;32m     65\u001b[0m     llm: BaseLanguageModel,\n\u001b[1;32m     66\u001b[0m     prompt: Optional[BasePromptTemplate] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     72\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StuffDocumentsChain:\n\u001b[1;32m     73\u001b[0m     _prompt \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;129;01mor\u001b[39;00m stuff_prompt\u001b[38;5;241m.\u001b[39mPROMPT_SELECTOR\u001b[38;5;241m.\u001b[39mget_prompt(llm)\n\u001b[0;32m---> 74\u001b[0m     llm_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# TODO: document prompt\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StuffDocumentsChain(\n\u001b[1;32m     83\u001b[0m         llm_chain\u001b[38;5;241m=\u001b[39mllm_chain,\n\u001b[1;32m     84\u001b[0m         document_variable_name\u001b[38;5;241m=\u001b[39mdocument_variable_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     89\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain_core/load/serializable.py:107\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for LLMChain\nprompt\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "message = \"what are takeover skins\"\n",
    "prompt = \"You are an AI assistant that answers questions:\"\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=db.as_retriever(search_kwargs={\"k\": 3}),\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": prompt, \"history\": history, \"question\": message}\n",
    "    )\n",
    "class StatefulThread(Thread):\n",
    "    def __init__(self, target, args):\n",
    "        super().__init__(target=target, args=args)\n",
    "        self._result = None\n",
    "    def run(self):\n",
    "        self._result = self._target(self._args)\n",
    "    def get_result(self):\n",
    "        return self._result\n",
    "\n",
    "tt = StatefulThread(target=qa_chain, args=(\"hi there\"))\n",
    "tt.start()\n",
    "tt.join()\n",
    "result = tt.get_result();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0ecbe29-524f-45c4-a920-1dd5db675a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'hi there',\n",
       " 'result': \"Hi there! Midjourney is an AI art generator that transforms text-based prompts into unique and impressive images. It's an independent tool that can be used to add visual interest to projects like HTML5 banner campaigns. One of its features is animated skins, which can bring banners to life by adding movement and dynamic elements. If you have any questions or would like to learn more, please don't hesitate to book a demo with us.\",\n",
       " 'source_documents': [Document(page_content='We tried out Midjourney.\\n\\nWe played around with it, unleashed our mutual creativity and, last but not least, we definitely enjoyed the whole process.\\n\\nWhat is Midjourney and why do I need to care about it?\\n\\nMidjourney is an independent AI art generator that turns text-based prompts into images. Only with a few words, Midjourney has the capacity to create unique and impressive artworks that will take your breath away.', metadata={'source': 'data/streameye_blog/We_Tried_Midjourney_So_That_You_Don’t_Have_To.md', 'start_index': 874}),\n",
       "  Document(page_content='Did we manage to get you on board? If you do not know where to start, book a demo with us. We will make sure to resolve all your questions and doubts about your very first HTML5 banner campaign.', metadata={'source': 'data/streameye_blog/Why_HTML5_Are_Showing_GIFs_The_Door.md', 'start_index': 5652}),\n",
       "  Document(page_content='Once you combine the takeover skin placeholder with the responsive banner functions, there comes her majesty, the animated skin, which we are discussing in today’s post.\\n\\nThe Power of Animated Skins', metadata={'source': 'data/streameye_blog/How_Animated_Skins_Will_Revolutionize_Big_Ad_Campaigns.md', 'start_index': 1759})]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
