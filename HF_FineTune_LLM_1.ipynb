{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6b75adf-4e7b-42fc-a4fe-f2385a4d1083",
   "metadata": {},
   "source": [
    "## Trying Out Finetuning of an LLM\n",
    "\n",
    "following this tutorial on [Youtube](https://www.youtube.com/watch?v=2PlPqSc3jM0)\n",
    "\n",
    "the idea is to try and compose an instruction prompt rather than features and labels and see if the LLM can train. We will use the Falcon 7B with Bits and Bytes tokenisation it seems\n",
    "\n",
    "We will use the OpenAssistant Guanaco, but lets try other stuff later if this works.\n",
    "\n",
    "I have used 'knkarthick/dialogsum' dataset to finetune the Falcon 7B model to summarise conversations. Subsequently I have merged the peft adapted model into the base model and quantised the result to 8bit saving it here: './data/finetuned_Falcon7b_summary_8bit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7015b73a-5f3c-4fd1-806e-eebeadfbfb08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.16.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting Click!=8.0.0,>=7.1 (from wandb)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (5.9.5)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.39.1-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.11/site-packages (from wandb) (6.0.1)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from wandb) (68.2.2)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0 (from wandb)\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-1.39.1-py2.py3-none-any.whl (254 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: appdirs, smmap, setproctitle, sentry-sdk, protobuf, einops, docker-pycreds, Click, gitdb, GitPython, wandb\n",
      "Successfully installed Click-8.1.7 GitPython-3.1.40 appdirs-1.4.4 docker-pycreds-0.4.0 einops-0.7.0 gitdb-4.0.11 protobuf-4.25.1 sentry-sdk-1.39.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.1\n"
     ]
    }
   ],
   "source": [
    "!pip install einops wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6db0b2d6-f753-4b44-afea-3d5da2351995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trl\n",
      "  Downloading trl-0.7.7-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from trl) (2.1.2)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.11/site-packages (from trl) (4.36.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.11/site-packages (from trl) (1.26.2)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (from trl) (0.25.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (from trl) (2.16.0)\n",
      "Collecting tyro>=0.5.11 (from trl)\n",
      "  Downloading tyro-0.6.2-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.3.101)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (0.20.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (4.66.1)\n",
      "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl)\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Collecting rich>=11.1.0 (from tyro>=0.5.11->trl)\n",
      "  Downloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
      "  Downloading shtab-1.6.5-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate->trl) (5.9.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (2.1.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (3.9.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.31.0->trl) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.31.0->trl) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.31.0->trl) (2023.11.17)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro>=0.5.11->trl)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "Downloading trl-0.7.7-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.6.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.6.5-py3-none-any.whl (13 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shtab, mdurl, docstring-parser, markdown-it-py, rich, tyro, trl\n",
      "Successfully installed docstring-parser-0.15 markdown-it-py-3.0.0 mdurl-0.1.2 rich-13.7.0 shtab-1.6.5 trl-0.7.7 tyro-0.6.2\n"
     ]
    }
   ],
   "source": [
    "!pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8015fed7-6cfd-4e27-82ac-c56b6f704a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer\n",
    ")\n",
    "from peft import LoraConfig, peft_model, get_peft_model, AutoPeftModelForCausalLM\n",
    "from peft.tuners.lora import LoraLayer\n",
    "# from trl import SFTTrainer # this is only needed when we Tune\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9089eabf-d2ff-450b-a266-03e12cc412f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1c7494-8165-4017-bd93-f678f1f9a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def release_mem(model, tokenizer, pipeline=None):\n",
    "    if model is not None:\n",
    "        del model\n",
    "    if tokenizer is not None:\n",
    "        del tokenizer\n",
    "    if pipeline is not None:\n",
    "        del pipeline\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8a5674f-b944-4fda-9376-5939454f33d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"timdettmers/openassistant-guanaco\"\n",
    "\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b61a9c-052a-4d45-ba49-aa9348ae47f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d9502d-f8c2-4e21-b2bb-280477e636c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset[\"train\"].shuffle()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00ac1173-f28a-42cf-82f4-3e96ac801bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"expand_frame_repr\", False)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4006b170-6d7a-4f8f-bd54-e892919a650c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>### Human: Por favor, explica por qué este chiste es gracioso para un adolescente de 11 años.\\n\\n- ¿Qué tiene Darth Vader en la nevera?\\n- Helado oscuro### Assistant: El chiste del helado oscuro es divertido para un adolescente de 11 años porque juega con la cultura pop que probablemente les sea familiar. Muchos adolescentes de 11 años conocen a Darth Vader, un personaje icónico de Star Wars, y el chiste hace referencia al concepto de \"El lado oscuro\" del cual Darth Vader hace parte. Esto es divertido para los adolescentes porque les permite ver un juego de palabras que les resulta familiar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>### Human: Tengo un Elekid en PokeMMO, qué habilidad es mejor \"spark\" o \"electro ball\", ten en cuenta las siguientes estadisticas que tiene mi Elekid:\\n- attack: 38\\n- defense: 25\\n- sp. atk: 37\\n- sp. def: 27\\n- speed: 53### Assistant: De las dos habilidades que mencionas, \"Spark\" y \"Electro Ball\", la habilidad que sería mejor para tu Elekid dependerá de cómo quieras utilizarlo en la batalla.\\n\\nSi estás buscando maximizar la potencia de sus movimientos eléctricos, entonces la habilidad \"Electro Ball\" es la mejor opción. La potencia de este movimiento aumenta a medida que la velocidad del usuario es mayor que la del objetivo, y dado que la velocidad de tu Elekid es relativamente alta (53), es posible que pueda causar una gran cantidad de daño a los oponentes más lentos.\\n\\nPor otro lado, si estás buscando una habilidad que aumente la probabilidad de causar un efecto secundario en los movimientos eléctricos de tu Elekid, entonces \"Spark\" sería una mejor opción. La habilidad \"Spark\" tiene una probabilidad del 30% de paralizar al objetivo cuando se usa un movimiento eléctrico, lo que puede ser útil para interrumpir la estrategia del oponente o para asegurarte de que tu Elekid tenga la oportunidad de atacar primero.\\n\\nEn última instancia, la elección de la habilidad dependerá de tus preferencias y estrategias en la batalla, así que asegúrate de considerar cómo planeas usar a tu Elekid antes de tomar una decisión final.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### Human: Was bist du?### Assistant: Ich bin eine künstliche Intelligenz(KI). Das Künstlich in KI steht dafür, dass ich von Menschen geschaffen worden bin. Die Intelligenz in KI steht dafür, dass ich in der Lage bin zu lernen.### Human: Was kannst du alles für Sachen?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>### Human: Haz una lista de las mejores tarjetas gráficas ordenada de mejor a peor, comparando las características de las mismas.### Assistant: Aquí te presento una lista de las mejores tarjetas gráficas disponibles actualmente en el mercado, ordenadas de mejor a peor en términos de características:\\n\\nNVIDIA GeForce RTX 3090: Es la tarjeta gráfica más potente actualmente disponible, con un alto rendimiento en juegos y aplicaciones de edición de video. Tiene una memoria GDDR6X de 24GB y un ancho de banda de memoria de 936 GB/s.\\nNVIDIA GeForce RTX 3080 Ti: Es la segunda tarjeta gráfica más potente, también con un alto rendimiento en juegos y edición de video. Cuenta con una memoria GDDR6X de 12GB y un ancho de banda de memoria de 912 GB/s.\\nAMD Radeon RX 6900 XT: Es una tarjeta gráfica potente que ofrece un buen rendimiento en juegos y aplicaciones de edición de video. Tiene una memoria GDDR6 de 16GB y un ancho de banda de memoria de 512 GB/s.\\nNVIDIA GeForce RTX 3080: Es una tarjeta gráfica de alto rendimiento que ofrece una buena experiencia de juego y edición de video. Tiene una memoria GDDR6X de 10GB y un ancho de banda de memoria de 760 GB/s.\\nAMD Radeon RX 6800 XT: Es una tarjeta gráfica de alta gama que ofrece un buen rendimiento en juegos y aplicaciones de edición de video. Tiene una memoria GDDR6 de 16GB y un ancho de banda de memoria de 512 GB/s.\\nNVIDIA GeForce RTX 3070 Ti: Es una tarjeta gráfica de alto rendimiento que ofrece una buena experiencia de juego y edición de video. Tiene una memoria GDDR6X de 8GB y un ancho de banda de memoria de 608 GB/s.\\nAMD Radeon RX 6800: Es una tarjeta gráfica de gama alta que ofrece un buen rendimiento en juegos y aplicaciones de edición de video. Tiene una memoria GDDR6 de 16GB y un ancho de banda de memoria de 512 GB/s.\\nNVIDIA GeForce RTX 3060 Ti: Es una tarjeta gráfica de gama media-alta que ofrece un buen rendimiento en juegos y edición de video. Tiene una memoria GDDR6 de 8GB y un ancho de banda de memoria de 448 GB/s.\\nNVIDIA GeForce RTX 3060: Es una tarjeta gráfica de gama media que ofrece un buen rendimiento en juegos y aplicaciones de edición de video. Tiene una memoria GDDR6 de 12GB y un ancho de banda de memoria de 360 GB/s.\\nAMD Radeon RX 6700 XT: Es una tarjeta gráfica de gama media que ofrece un buen rendimiento en juegos y aplicaciones de edición de video. Tiene una memoria GDDR6 de 12GB y un ancho de banda de memoria de 384 GB/s.\\nEs importante destacar que la mejor tarjeta gráfica para ti dependerá de tus necesidades y presupuesto específicos.### Human: Reduce la lista a las mejores tarjetas graficas en relación calidad precio teniendo en cuenta que usare un monitor 2K de 144Hz### Assistant: Teniendo en cuenta tu monitor 2K de 144Hz y la relación calidad-precio, estas son las mejores tarjetas gráficas:\\n\\nAMD Radeon RX 6800: Es una excelente opción para un monitor 2K de 144Hz, con un buen rendimiento en juegos y aplicaciones de edición de video, y una memoria GDDR6 de 16GB y un ancho de banda de memoria de 512 GB/s.\\n\\nNVIDIA GeForce RTX 3070 Ti: Ofrece un rendimiento sólido en juegos y edición de video, y es compatible con Ray Tracing y DLSS. Tiene una memoria GDDR6X de 8GB y un ancho de banda de memoria de 608 GB/s.\\n\\nAMD Radeon RX 6700 XT: Es una tarjeta gráfica de gama media con un buen rendimiento en juegos y aplicaciones de edición de video, y una memoria GDDR6 de 12GB y un ancho de banda de memoria de 384 GB/s.\\n\\nSi necesitas ayuda en algo más acá estoy para ti.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>### Human: ¿Cuál es el mejor momento del año para visitar Valencia? ¿Qué lugares debería visitar?### Assistant: El mejor momento depende mucho de tus preferencias personales. Hay quién busca la fiesta y el espectáculo, como las famosas fallas que se celebran en marzo, o la tranquilidad de pasear por su ciudad o albufera. Se considera que de mayo a octubre el clima es muy bueno. En la ciudad de Valencia hay lugares de interés aptos para ir con toda la familia, como su ciudad de las ciencias.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>### Human: Podrías contarme un chiste sobre gatos?### Assistant: Ahí va uno:\\n¿Qué es un gato debajo de un carro?\\nUn gato hidráulico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>### Human: Is the following sentence about climate change? Provide a reason why.\\n\\nSentence: How each country’s emissions and pledges compare### Assistant: Yes, the sentence is about climate change.\\n\\nThe reason is that the sentence refers to \"emissions\" and \"pledges,\" which are related to greenhouse gas emissions and efforts to mitigate climate change. The sentence implies that different countries have different levels of emissions and that they are making pledges to reduce those emissions. This is a central topic in discussions around climate change and efforts to address its impact.### Human: The answer is correct.### Assistant: Thank you! Do you have any other questions?### Human: yeah, do you think any sentences with emissions or pledges is related to climate change?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>### Human: Can you tell me a bit about what has gone into your creation?### Assistant: Sure! I was created using the latest in natural language processing technology, which enables me to understand and process natural language, allowing me to engage in conversations and provide relevant and accurate answers. My responses are generated using a combination of statistical models, deep learning algorithms, and semantic analysis. Additionally, I use a search engine to find relevant snippets from webpages to provide additional information and context. I'm constantly learning and improving as I interact with more people, and I'm always striving to provide the best possible experience for my users.### Human: Can you write paper with reference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>### Human: When is Diablo IV coming out?### Assistant: As of 2/4/2023 the release date for Diablo 4 is June 6, 2023 on PS5, Xbox Series X/S, PS4, Xbox One, and PC.\\n\\nWhile Diablo 4 is set to release on June 6, 2023, please note that video game release dates are commonly delayed as developers aim to create the best possible product for their players.### Human: Thank you for the information provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>### Human: В каком стиле написаны следующие два абзаца?\\n\\nИ не было бы смысла в нём, кроме зла, если бы эти истории нельзя было читать... ведь то, что собрано, поглощено, взято, обязательно должно вернуться обратно, так или иначе. таков закон Порядка. А металлическое ядро небесной планеты взяло много знаний и с ними обрело очень сильное поле... Оно могло бы послужить доброму делу: любой маг нашёл бы знания ядра полезными и нужными, если бы не притяжение поля. Оно сгубило бы его навсегда. Даже дракон не смог бы безопасно к нему приблизиться... Но у ядра было небо. А в небе жили вот такие духи:\\n\\nИх руки не всегда были руками. А лица не всегда были лицами. Сначала они были как бы обрывками ветра. вплетались в небо и носились вокруг тогда ещё пустого ядра, как воздушные кометы. Ветер на их планете был ураганным. На любой земле его сила ровняла бы с пылью горы и поднимала бы моря над континентами. Необузданным, изменчивым и яростным было то небо. Но духам такое нравилось. Они были вольны и радостны, как всякие дети на заре мира.### Assistant: Стиль предоставленного вами текста — художественный.### Human: Ну, такое я тоже могу понять. Даже, что это скорее всего фэнтези или фантастика. А можно ли как-то более детально?### Assistant: Данные абзацы написаны в жанре фэнтези/научной фантастики. Стиль написания описаний духов, небесной планеты, ядра и т.д. - это характеристика и атрибуты жанра. Язык достаточно выразителен, с элементами описательности, метафоричности, которые характерны для таких текстов.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ### Human: Por favor, explica por qué este chiste es gracioso para un adolescente de 11 años.\\n\\n- ¿Qué tiene Darth Vader en la nevera?\\n- Helado oscuro### Assistant: El chiste del helado oscuro es divertido para un adolescente de 11 años porque juega con la cultura pop que probablemente les sea familiar. Muchos adolescentes de 11 años conocen a Darth Vader, un personaje icónico de Star Wars, y el chiste hace referencia al concepto de \"El lado oscuro\" del cual Darth Vader hace parte. Esto es divertido para los adolescentes porque les permite ver un juego de palabras que les resulta familiar\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ### Human: Tengo un Elekid en PokeMMO, qué habilidad es mejor \"spark\" o \"electro ball\", ten en cuenta las siguientes estadisticas que tiene mi Elekid:\\n- attack: 38\\n- defense: 25\\n- sp. atk: 37\\n- sp. def: 27\\n- speed: 53### Assistant: De las dos habilidades que mencionas, \"Spark\" y \"Electro Ball\", la habilidad que sería mejor para tu Elekid dependerá de cómo quieras utilizarlo en la batalla.\\n\\nSi estás buscando maximizar la potencia de sus movimientos eléctricos, entonces la habilidad \"Electro Ball\" es la mejor opción. La potencia de este movimiento aumenta a medida que la velocidad del usuario es mayor que la del objetivo, y dado que la velocidad de tu Elekid es relativamente alta (53), es posible que pueda causar una gran cantidad de daño a los oponentes más lentos.\\n\\nPor otro lado, si estás buscando una habilidad que aumente la probabilidad de causar un efecto secundario en los movimientos eléctricos de tu Elekid, entonces \"Spark\" sería una mejor opción. La habilidad \"Spark\" tiene una probabilidad del 30% de paralizar al objetivo cuando se usa un movimiento eléctrico, lo que puede ser útil para interrumpir la estrategia del oponente o para asegurarte de que tu Elekid tenga la oportunidad de atacar primero.\\n\\nEn última instancia, la elección de la habilidad dependerá de tus preferencias y estrategias en la batalla, así que asegúrate de considerar cómo planeas usar a tu Elekid antes de tomar una decisión final.\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ### Human: Was bist du?### Assistant: Ich bin eine künstliche Intelligenz(KI). Das Künstlich in KI steht dafür, dass ich von Menschen geschaffen worden bin. Die Intelligenz in KI steht dafür, dass ich in der Lage bin zu lernen.### Human: Was kannst du alles für Sachen?\n",
       "3  ### Human: Haz una lista de las mejores tarjetas gráficas ordenada de mejor a peor, comparando las características de las mismas.### Assistant: Aquí te presento una lista de las mejores tarjetas gráficas disponibles actualmente en el mercado, ordenadas de mejor a peor en términos de características:\\n\\nNVIDIA GeForce RTX 3090: Es la tarjeta gráfica más potente actualmente disponible, con un alto rendimiento en juegos y aplicaciones de edición de video. Tiene una memoria GDDR6X de 24GB y un ancho de banda de memoria de 936 GB/s.\\nNVIDIA GeForce RTX 3080 Ti: Es la segunda tarjeta gráfica más potente, también con un alto rendimiento en juegos y edición de video. Cuenta con una memoria GDDR6X de 12GB y un ancho de banda de memoria de 912 GB/s.\\nAMD Radeon RX 6900 XT: Es una tarjeta gráfica potente que ofrece un buen rendimiento en juegos y aplicaciones de edición de video. Tiene una memoria GDDR6 de 16GB y un ancho de banda de memoria de 512 GB/s.\\nNVIDIA GeForce RTX 3080: Es una tarjeta gráfica de alto rendimiento que ofrece una buena experiencia de juego y edición de video. Tiene una memoria GDDR6X de 10GB y un ancho de banda de memoria de 760 GB/s.\\nAMD Radeon RX 6800 XT: Es una tarjeta gráfica de alta gama que ofrece un buen rendimiento en juegos y aplicaciones de edición de video. Tiene una memoria GDDR6 de 16GB y un ancho de banda de memoria de 512 GB/s.\\nNVIDIA GeForce RTX 3070 Ti: Es una tarjeta gráfica de alto rendimiento que ofrece una buena experiencia de juego y edición de video. Tiene una memoria GDDR6X de 8GB y un ancho de banda de memoria de 608 GB/s.\\nAMD Radeon RX 6800: Es una tarjeta gráfica de gama alta que ofrece un buen rendimiento en juegos y aplicaciones de edición de video. Tiene una memoria GDDR6 de 16GB y un ancho de banda de memoria de 512 GB/s.\\nNVIDIA GeForce RTX 3060 Ti: Es una tarjeta gráfica de gama media-alta que ofrece un buen rendimiento en juegos y edición de video. Tiene una memoria GDDR6 de 8GB y un ancho de banda de memoria de 448 GB/s.\\nNVIDIA GeForce RTX 3060: Es una tarjeta gráfica de gama media que ofrece un buen rendimiento en juegos y aplicaciones de edición de video. Tiene una memoria GDDR6 de 12GB y un ancho de banda de memoria de 360 GB/s.\\nAMD Radeon RX 6700 XT: Es una tarjeta gráfica de gama media que ofrece un buen rendimiento en juegos y aplicaciones de edición de video. Tiene una memoria GDDR6 de 12GB y un ancho de banda de memoria de 384 GB/s.\\nEs importante destacar que la mejor tarjeta gráfica para ti dependerá de tus necesidades y presupuesto específicos.### Human: Reduce la lista a las mejores tarjetas graficas en relación calidad precio teniendo en cuenta que usare un monitor 2K de 144Hz### Assistant: Teniendo en cuenta tu monitor 2K de 144Hz y la relación calidad-precio, estas son las mejores tarjetas gráficas:\\n\\nAMD Radeon RX 6800: Es una excelente opción para un monitor 2K de 144Hz, con un buen rendimiento en juegos y aplicaciones de edición de video, y una memoria GDDR6 de 16GB y un ancho de banda de memoria de 512 GB/s.\\n\\nNVIDIA GeForce RTX 3070 Ti: Ofrece un rendimiento sólido en juegos y edición de video, y es compatible con Ray Tracing y DLSS. Tiene una memoria GDDR6X de 8GB y un ancho de banda de memoria de 608 GB/s.\\n\\nAMD Radeon RX 6700 XT: Es una tarjeta gráfica de gama media con un buen rendimiento en juegos y aplicaciones de edición de video, y una memoria GDDR6 de 12GB y un ancho de banda de memoria de 384 GB/s.\\n\\nSi necesitas ayuda en algo más acá estoy para ti.\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ### Human: ¿Cuál es el mejor momento del año para visitar Valencia? ¿Qué lugares debería visitar?### Assistant: El mejor momento depende mucho de tus preferencias personales. Hay quién busca la fiesta y el espectáculo, como las famosas fallas que se celebran en marzo, o la tranquilidad de pasear por su ciudad o albufera. Se considera que de mayo a octubre el clima es muy bueno. En la ciudad de Valencia hay lugares de interés aptos para ir con toda la familia, como su ciudad de las ciencias.\n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ### Human: Podrías contarme un chiste sobre gatos?### Assistant: Ahí va uno:\\n¿Qué es un gato debajo de un carro?\\nUn gato hidráulico\n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ### Human: Is the following sentence about climate change? Provide a reason why.\\n\\nSentence: How each country’s emissions and pledges compare### Assistant: Yes, the sentence is about climate change.\\n\\nThe reason is that the sentence refers to \"emissions\" and \"pledges,\" which are related to greenhouse gas emissions and efforts to mitigate climate change. The sentence implies that different countries have different levels of emissions and that they are making pledges to reduce those emissions. This is a central topic in discussions around climate change and efforts to address its impact.### Human: The answer is correct.### Assistant: Thank you! Do you have any other questions?### Human: yeah, do you think any sentences with emissions or pledges is related to climate change?\n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ### Human: Can you tell me a bit about what has gone into your creation?### Assistant: Sure! I was created using the latest in natural language processing technology, which enables me to understand and process natural language, allowing me to engage in conversations and provide relevant and accurate answers. My responses are generated using a combination of statistical models, deep learning algorithms, and semantic analysis. Additionally, I use a search engine to find relevant snippets from webpages to provide additional information and context. I'm constantly learning and improving as I interact with more people, and I'm always striving to provide the best possible experience for my users.### Human: Can you write paper with reference\n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ### Human: When is Diablo IV coming out?### Assistant: As of 2/4/2023 the release date for Diablo 4 is June 6, 2023 on PS5, Xbox Series X/S, PS4, Xbox One, and PC.\\n\\nWhile Diablo 4 is set to release on June 6, 2023, please note that video game release dates are commonly delayed as developers aim to create the best possible product for their players.### Human: Thank you for the information provided.\n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ### Human: В каком стиле написаны следующие два абзаца?\\n\\nИ не было бы смысла в нём, кроме зла, если бы эти истории нельзя было читать... ведь то, что собрано, поглощено, взято, обязательно должно вернуться обратно, так или иначе. таков закон Порядка. А металлическое ядро небесной планеты взяло много знаний и с ними обрело очень сильное поле... Оно могло бы послужить доброму делу: любой маг нашёл бы знания ядра полезными и нужными, если бы не притяжение поля. Оно сгубило бы его навсегда. Даже дракон не смог бы безопасно к нему приблизиться... Но у ядра было небо. А в небе жили вот такие духи:\\n\\nИх руки не всегда были руками. А лица не всегда были лицами. Сначала они были как бы обрывками ветра. вплетались в небо и носились вокруг тогда ещё пустого ядра, как воздушные кометы. Ветер на их планете был ураганным. На любой земле его сила ровняла бы с пылью горы и поднимала бы моря над континентами. Необузданным, изменчивым и яростным было то небо. Но духам такое нравилось. Они были вольны и радостны, как всякие дети на заре мира.### Assistant: Стиль предоставленного вами текста — художественный.### Human: Ну, такое я тоже могу понять. Даже, что это скорее всего фэнтези или фантастика. А можно ли как-то более детально?### Assistant: Данные абзацы написаны в жанре фэнтези/научной фантастики. Стиль написания описаний духов, небесной планеты, ядра и т.д. - это характеристика и атрибуты жанра. Язык достаточно выразителен, с элементами описательности, метафоричности, которые характерны для таких текстов."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d903976-9d70-4f91-a5cc-c2ba328c8515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e88dae20784ddcac330de23166cd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"ybelkada/falcon-7b-sharded-bf16\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbd9b200-f512-4672-bf78-912412a8430e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# configs\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      4\u001b[0m lora_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m      5\u001b[0m lora_dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "\n",
    "model.config.use_cache = False\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "lora_r = 64\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"query_key_value\",\n",
    "        \"dense\",\n",
    "        \"dense_h_to_4h\",\n",
    "        \"dense_4h_to_h\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./data/finetuned_falcon7_summary_1\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=3,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=False,\n",
    "    max_grad_norm = 0.3,\n",
    "    eval_steps=0.25,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.001,\n",
    "    warmup_ratio=0.05,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    gradient_checkpointing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e436dd0d-3440-41a3-9a8f-5e888a507bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89afaf7a-f483-4034-ad88-0a39995f047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 1024\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27b9d494-9132-485f-99be-2d58347ff051",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnamed_modules():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name:\n\u001b[1;32m      3\u001b[0m         module \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "for name, module in trainer.model.named_modules():\n",
    "    if \"norm\" in name:\n",
    "        module = module.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e51334f-37f9-460c-9b19-3ee1e07f4e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msnoop088\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/wandb/run-20231228_140846-cfufrrz7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snoop088/huggingface/runs/cfufrrz7' target=\"_blank\">resilient-snow-3</a></strong> to <a href='https://wandb.ai/snoop088/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snoop088/huggingface' target=\"_blank\">https://wandb.ai/snoop088/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snoop088/huggingface/runs/cfufrrz7' target=\"_blank\">https://wandb.ai/snoop088/huggingface/runs/cfufrrz7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='614' max='614' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [614/614 1:11:18, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.346052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>492</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.329145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=614, training_loss=1.3918702315041607, metrics={'train_runtime': 4291.6324, 'train_samples_per_second': 4.588, 'train_steps_per_second': 0.143, 'total_flos': 2.6774139087649536e+17, 'train_loss': 1.3918702315041607, 'epoch': 2.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55091332-1b89-4fc5-af94-0b5e44c92a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./data/fine_tuned_falcon7B')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee0960-d7b9-4d20-a5e2-c252227847fe",
   "metadata": {},
   "source": [
    "### How to Merge a Peft Adapter with Base Model\n",
    "\n",
    "this is to export a full finetuned model instead of just the Peft Adapter. For sharing on HF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23db042b-f277-4599-b421-1199af2b0464",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6d0dd2a1c44de6a0dac883217fe46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"./data/finetuned_falcon7_summary_1\"\n",
    "#load the Peft adapter\n",
    "loaded_model = AutoPeftModelForCausalLM.from_pretrained(model_name, low_cpu_mem_usage=True)\n",
    "#merge the adapter with the Base Model\n",
    "merged_model = loaded_model.merge_and_unload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98980cef-8bf9-422e-8e43-a4ffccffb0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94059dc1-d7bf-41a2-a649-78144473d2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/merged_finetuned_Falcon7b_summary/tokenizer_config.json',\n",
       " './data/merged_finetuned_Falcon7b_summary/special_tokens_map.json',\n",
       " './data/merged_finetuned_Falcon7b_summary/tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the merged model\n",
    "merged_model.save_pretrained(\"./data/merged_finetuned_Falcon7b_summary\", safe_serialization=True)\n",
    "#Do not forget to save the tokenizer separately. The tokenizer is the same as the one on the Base Model\n",
    "tokenizer.save_pretrained(\"./data/merged_finetuned_Falcon7b_summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d9b880-8958-4b8d-99e6-76b739e22d4d",
   "metadata": {},
   "source": [
    "### Load a Dataset and Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9807d54-fb4e-4bb5-94f5-6ce5b2298dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('knkarthick/dialogsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f99b5e-1925-41e0-8f3b-f5c335f6f397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "722ba4c9-1b9f-4600-a546-ca92f504324e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_2491</td>\n",
       "      <td>#Person1#: What are your plans for today Mark? Nick and I are going shopping. Do you want to come too?\\n#Person2#: Well as a matter of fact. I'm eating Steve. He's writing an article and he's asked me to take some photos for it.\\n#Person1#: An article? About What?\\n#Person2#: Oh, just People. Anyway, I'm seeing Steve at the zoo at 10.\\n#Person1#: Oh. well, let's meet for lunch shall we? How about that sandwich bar we went to on Friday? I'll see you there about 12:30.\\n#Person2#: Sounds good. See you.</td>\n",
       "      <td>#Person1# invites Mark to shop, but Mark has to help Steve take photos. They'll meet for lunch then.</td>\n",
       "      <td>invitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1986</td>\n",
       "      <td>#Person1#: Excuse me. But are you Mrs. Smith from America?\\n#Person2#: That's it. I am Maria Smith. You must be Zhang Lin from Tianjin Sports Facility Co. Ltd.\\n#Person1#: Yes. Nice to meet you, Mrs. Smith.\\n#Person2#: Nice to meet you too, Mr. Zhang.</td>\n",
       "      <td>Mrs. Smith and Zhang Lin meet for the first time and greet each other.</td>\n",
       "      <td>social meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_5622</td>\n",
       "      <td>#Person1#: Hello, Pam.\\n#Person2#: I'm glad that you can make it.\\n#Person1#: It looks like there are a lot of people inside.\\n#Person2#: Yeah. I've invited a lot of friends besides you.\\n#Person1#: Should I take my shoes off?\\n#Person2#: We all keep our shoes on indoors.\\n#Person1#: Where are your parents?\\n#Person2#: They've gone out so that we could have the house to ourselves.\\n#Person1#: That's great!</td>\n",
       "      <td>Pam has invited lots of friends including #Person1#. Pam's parents are out so they could have the whole house.</td>\n",
       "      <td>Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_7647</td>\n",
       "      <td>#Person1#: David, imagine meeting you here!\\n#Person2#: Janice, I found you stole my vegetables at four o'clock this morning. Is that true?\\n#Person1#: All right! I stayed up yesterday and waited for your vegetables. I stole your peaches and flowers.\\n#Person2#: It is so hard to prevent them from being stolen. I also got something this morning.\\n#Person1#: How many vegetables do you steal today?\\n#Person2#: I stole many from Fred's farm, and from yours. I planned to have a dog on farm.\\n#Person1#: So funny. By stealing, I forgot all my sorrows and pressure from work.\\n#Person2#: I could not agree with you more. For us, there are so many unhappy things and I am so bored ; however, I got lots of fun from stealing.\\n#Person1#: I really want to be far away from the reality now.\\n#Person2#: But we still need to go back to it. Don't overdo it.</td>\n",
       "      <td>Janice stayed up and stole many vegetables from Fred's farm and David's and says it makes her forget all her sorrows and pressure. David asks her not to overdo it.</td>\n",
       "      <td>steal the vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_2368</td>\n",
       "      <td>#Person1#: Good morning. Miss Lee. My name is Alex Jones. I'm the new assistant in the office.\\n#Person2#: Welcome and nice to meet you. I heard you were coming today. Is today your first day here in the company?\\n#Person1#: Yes, I'm looking forward to meeting everybody and getting started on my new job.\\n#Person2#: First day is often exciting, isn't it? Here, let me show you to your desk. You can have this computer and telephone and share the copy machine with us in the office. How do you like it?\\n#Person1#: This is wonderful. Thank you for doing all this for me, Miss Lee.\\n#Person2#: You are welcome. And, please call me Betty.</td>\n",
       "      <td>Alex Jones comes to the office as a new assistant and Betty shows Alex to Alex's desk.</td>\n",
       "      <td>entrant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  \\\n",
       "0  train_2491   \n",
       "1  train_1986   \n",
       "2  train_5622   \n",
       "3  train_7647   \n",
       "4  train_2368   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            dialogue  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                          #Person1#: What are your plans for today Mark? Nick and I are going shopping. Do you want to come too?\\n#Person2#: Well as a matter of fact. I'm eating Steve. He's writing an article and he's asked me to take some photos for it.\\n#Person1#: An article? About What?\\n#Person2#: Oh, just People. Anyway, I'm seeing Steve at the zoo at 10.\\n#Person1#: Oh. well, let's meet for lunch shall we? How about that sandwich bar we went to on Friday? I'll see you there about 12:30.\\n#Person2#: Sounds good. See you.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        #Person1#: Excuse me. But are you Mrs. Smith from America?\\n#Person2#: That's it. I am Maria Smith. You must be Zhang Lin from Tianjin Sports Facility Co. Ltd.\\n#Person1#: Yes. Nice to meet you, Mrs. Smith.\\n#Person2#: Nice to meet you too, Mr. Zhang.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                          #Person1#: Hello, Pam.\\n#Person2#: I'm glad that you can make it.\\n#Person1#: It looks like there are a lot of people inside.\\n#Person2#: Yeah. I've invited a lot of friends besides you.\\n#Person1#: Should I take my shoes off?\\n#Person2#: We all keep our shoes on indoors.\\n#Person1#: Where are your parents?\\n#Person2#: They've gone out so that we could have the house to ourselves.\\n#Person1#: That's great!   \n",
       "3  #Person1#: David, imagine meeting you here!\\n#Person2#: Janice, I found you stole my vegetables at four o'clock this morning. Is that true?\\n#Person1#: All right! I stayed up yesterday and waited for your vegetables. I stole your peaches and flowers.\\n#Person2#: It is so hard to prevent them from being stolen. I also got something this morning.\\n#Person1#: How many vegetables do you steal today?\\n#Person2#: I stole many from Fred's farm, and from yours. I planned to have a dog on farm.\\n#Person1#: So funny. By stealing, I forgot all my sorrows and pressure from work.\\n#Person2#: I could not agree with you more. For us, there are so many unhappy things and I am so bored ; however, I got lots of fun from stealing.\\n#Person1#: I really want to be far away from the reality now.\\n#Person2#: But we still need to go back to it. Don't overdo it.   \n",
       "4                                                                                                                                                                                                                      #Person1#: Good morning. Miss Lee. My name is Alex Jones. I'm the new assistant in the office.\\n#Person2#: Welcome and nice to meet you. I heard you were coming today. Is today your first day here in the company?\\n#Person1#: Yes, I'm looking forward to meeting everybody and getting started on my new job.\\n#Person2#: First day is often exciting, isn't it? Here, let me show you to your desk. You can have this computer and telephone and share the copy machine with us in the office. How do you like it?\\n#Person1#: This is wonderful. Thank you for doing all this for me, Miss Lee.\\n#Person2#: You are welcome. And, please call me Betty.   \n",
       "\n",
       "                                                                                                                                                               summary  \\\n",
       "0                                                                 #Person1# invites Mark to shop, but Mark has to help Steve take photos. They'll meet for lunch then.   \n",
       "1                                                                                               Mrs. Smith and Zhang Lin meet for the first time and greet each other.   \n",
       "2                                                       Pam has invited lots of friends including #Person1#. Pam's parents are out so they could have the whole house.   \n",
       "3  Janice stayed up and stole many vegetables from Fred's farm and David's and says it makes her forget all her sorrows and pressure. David asks her not to overdo it.   \n",
       "4                                                                               Alex Jones comes to the office as a new assistant and Betty shows Alex to Alex's desk.   \n",
       "\n",
       "                  topic  \n",
       "0            invitation  \n",
       "1        social meeting  \n",
       "2                 Party  \n",
       "3  steal the vegetables  \n",
       "4               entrant  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset[\"train\"].shuffle()[:5])\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c674ef7-31d4-4e14-af6d-36b4a65c30f7",
   "metadata": {},
   "source": [
    "### Create a Function to Map a Dataset\n",
    "\n",
    "Creating the factory function to pass to the map of the DataSet to create a prompt and tokenize it for fine tuning. Excellent resource here: [Fine Tuning LLAMA2 on Custom DataSet](https://github.com/curiousily/Get-Things-Done-with-Prompt-Engineering-and-LangChain/blob/master/14.fine-tuning-llama-2-7b-on-custom-dataset.ipynb) by Venko\n",
    "\n",
    "Lets extract few functions to use as utils in the final mapped function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d3717e-edb2-4d0c-9be8-5197c7e5a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f1fd6c-68e9-42e3-9b80-7859f76a807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(input, summary):\n",
    "    INSTR = 'You are an AI assistant that will summarise the correspondence in ###Input as ###Summary'\n",
    "    inputs = input.split('\\n')\n",
    "    concat_inputs = \" \".join(inputs)\n",
    "    prompt = f\"\"\" ###Instruction: {INSTR}\\n\n",
    "###Input: {BeautifulSoup(input.strip())}\\n\n",
    "###Summary: {BeautifulSoup(summary.strip())}\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "def process_data(example):\n",
    "    # print(f\"{BeautifulSoup(example['dialogue'])}\\n\\n\")\n",
    "    return {\n",
    "        \"prompt\": create_prompt(example[\"dialogue\"], example[\"summary\"])\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c98cdc09-826a-4e5e-a47a-0eaff3df28c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "small_set = Dataset.from_dict(dataset[\"train\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a59f6328-c4a7-4ea0-af25-a915264825ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_set = dataset.map(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca91c1f9-3b23-480e-aab5-893a6ef4ae99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'prompt'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'prompt'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'prompt'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_set.remove_columns([\"dialogue\", \"summary\", \"topic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "974740ff-d548-4212-8e0d-e79112beee61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Instruction: You are an AI assistant that will summarise the correspondence in ###Input as ###Summary\n",
      "\n",
      "###Input: #Person1#: This is a good basic computer package. It's got a good CPU, 256 megabytes of RAM, and a DVD player.\n",
      "#Person2#: Does it come with a modem?\n",
      "#Person1#: Yes, it has a built-in modem. You just plug a phone line into the back of the computer.\n",
      "#Person2#: How about the monitor?\n",
      "#Person1#: A 15 - inch monitor is included in the deal. If you want, you can switch it for a 17 - inch monitor, for a little more money.\n",
      "#Person2#: That's okay. A 15 - inch is good enough. All right, I'll take it.\n",
      "\n",
      "###Summary: #Person1# shows a basic computer package to #Person2#. #Person2# thinks it's good and will take it.\n"
     ]
    }
   ],
   "source": [
    "print(processed_set[\"train\"][8]['prompt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9808fd55-82be-4795-b250-ae3338bb893a",
   "metadata": {},
   "source": [
    "### Try Finetuning the Falcon 7 to the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c074485-7b0d-400d-aaec-44b66c763c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9098c64e5d294f549ac1b6d93fbdf9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_seq_length = 1024\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=processed_set[\"train\"],\n",
    "    eval_dataset=processed_set[\"validation\"],\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"prompt\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9184753-19ff-4cbe-ba14-f89a23481c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in trainer.model.named_modules():\n",
    "    if isinstance(module, LoraLayer):\n",
    "        if training_arguments.bf16:\n",
    "            module = module.to(torch.bfloat16)\n",
    "    if \"norm\" in name:\n",
    "        module = module.to(torch.float32)\n",
    "    if \"lm_head\" in name or \"embed_tokens\" in name:\n",
    "        if hasattr(module, \"weight\"):\n",
    "            if training_arguments.bf16 and module.weight.dtype == torch.float32:\n",
    "                module = module.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32cbf94c-5eaa-4a71-b763-e4f6fb28dc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msnoop088\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/wandb/run-20231230_095512-len9wprq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snoop088/huggingface/runs/len9wprq' target=\"_blank\">bright-plant-9</a></strong> to <a href='https://wandb.ai/snoop088/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snoop088/huggingface' target=\"_blank\">https://wandb.ai/snoop088/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snoop088/huggingface/runs/len9wprq' target=\"_blank\">https://wandb.ai/snoop088/huggingface/runs/len9wprq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='778' max='778' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [778/778 1:23:45, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.146200</td>\n",
       "      <td>1.294437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.251200</td>\n",
       "      <td>1.278507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>1.129100</td>\n",
       "      <td>1.270795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=778, training_loss=1.2670443421157895, metrics={'train_runtime': 5045.7962, 'train_samples_per_second': 2.469, 'train_steps_per_second': 0.154, 'total_flos': 1.393849329095424e+17, 'train_loss': 1.2670443421157895, 'epoch': 1.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc1fdbe7-d16d-4982-9a71-c3fb7b5fad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./data/finetuned_falcon7_summary_1/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deedab58-5ca8-451d-aa9f-08d3c1621878",
   "metadata": {},
   "source": [
    "### Playing around with the Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fbb7ac2-b955-468b-a41e-0982f4477924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = './data/merged_finetuned_Falcon7b'\n",
    "model_name = './data/finetuned_falcon7_summary_1/'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5be718-12a2-44fe-b236-7b951aea55e5",
   "metadata": {},
   "source": [
    "#### Loading a Peft Adapted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c8c0519-57fb-4dc2-9a68-6bd83358598a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f714b6b5b4c4b06bd62671007e16b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_model = AutoPeftModelForCausalLM.from_pretrained(model_name, low_cpu_mem_usage=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cd4939-7790-470c-a9e9-2ed966009bb1",
   "metadata": {},
   "source": [
    "#### Processing the test dataset to take an input for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be087d4-4dc1-4f16-8ba7-25cea6c2ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_set = Dataset.from_dict(dataset[\"test\"].shuffle()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883ead91-ae7a-4cff-bab4-7a58d23030a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b188ab93613446648655ea7f6a41b9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_input = small_set.map(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88157bd7-79c6-46e0-a031-94d1b4ef8564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'test_88_3',\n",
       " 'dialogue': \"#Person1#: What are the main differences between this country and your country?\\n#Person2#: Well, in Russia, everything happens very fast. People talk quickly, they drive their cars too fast, the good deals go by really quickly...but here in Canada, it seems like people are a little more relaxed.\\n#Person1#: Is that true for everything?\\n#Person2#: No, of course not. In Russia, going to the bank can take hours. The same is true for the post office and the supermarket. In Canada, however, these places are pretty easy to get through quickly.\\n#Person1#: So, what is it that makes some things go either faster or slower compared to us here in Canada? I was born and raised here, so I guess I don't notice these things. I've also never been outside the country before.\\n#Person2#: I think the people in Russia are fast movers by nature, at least in the big cities. Public places are still very slow because they haven't tried to do business any differently than they used to.\\n#Person1#: But in Canada, it's the opposite?\\n#Person2#: Right. The government here does a great job of solving problems and using new technology to make businesses work better. But I think Canadians are just more calm in general than Russians are... and they're definitely more relaxed than Americans!\\n#Person1#: Well, I agree with you about that last part!\",\n",
       " 'summary': '#Person1# and #Person2# are sharing their opinions towards how different is Russia from Canada in lifestyle, especially the speed in life.',\n",
       " 'topic': 'country differences',\n",
       " 'prompt': \"###Instruction: You are an AI assistant that will summarise the correspondence in ###Input as ###Summary\\n\\n###Input: #Person1#: What are the main differences between this country and your country?\\n#Person2#: Well, in Russia, everything happens very fast. People talk quickly, they drive their cars too fast, the good deals go by really quickly...but here in Canada, it seems like people are a little more relaxed.\\n#Person1#: Is that true for everything?\\n#Person2#: No, of course not. In Russia, going to the bank can take hours. The same is true for the post office and the supermarket. In Canada, however, these places are pretty easy to get through quickly.\\n#Person1#: So, what is it that makes some things go either faster or slower compared to us here in Canada? I was born and raised here, so I guess I don't notice these things. I've also never been outside the country before.\\n#Person2#: I think the people in Russia are fast movers by nature, at least in the big cities. Public places are still very slow because they haven't tried to do business any differently than they used to.\\n#Person1#: But in Canada, it's the opposite?\\n#Person2#: Right. The government here does a great job of solving problems and using new technology to make businesses work better. But I think Canadians are just more calm in general than Russians are... and they're definitely more relaxed than Americans!\\n#Person1#: Well, I agree with you about that last part!\\n\\n###Summary: #Person1# and #Person2# are sharing their opinions towards how different is Russia from Canada in lifestyle, especially the speed in life.\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_input[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "622583a7-a682-4003-a40d-d99fe90ea4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"###Instruction: You are an AI assistant that will summarise the correspondence in ###Input as ###Summary\\n\\n###Input: #Person1#: What are the main differences between this country and your country?\\n#Person2#: Well, in Russia, everything happens very fast. People talk quickly, they drive their cars too fast, the good deals go by really quickly...but here in Canada, it seems like people are a little more relaxed.\\n#Person1#: Is that true for everything?\\n#Person2#: No, of course not. In Russia, going to the bank can take hours. The same is true for the post office and the supermarket. In Canada, however, these places are pretty easy to get through quickly.\\n#Person1#: So, what is it that makes some things go either faster or slower compared to us here in Canada? I was born and raised here, so I guess I don't notice these things. I've also never been outside the country before.\\n#Person2#: I think the people in Russia are fast movers by nature, at least in the big cities. Public places are still very slow because they haven't tried to do business any differently than they used to.\\n#Person1#: But in Canada, it's the opposite?\\n#Person2#: Right. The government here does a great job of solving problems and using new technology to make businesses work better. But I think Canadians are just more calm in general than Russians are... and they're definitely more relaxed than Americans!\\n#Person1#: Well, I agree with you about that last part!\\n\\n###Summary:\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_of_summary = processed_input[4][\"prompt\"].find(\"###Summary:\")\n",
    "summaryless = processed_input[4][\"prompt\"][:index_of_summary + len(\"###Summary:\")]\n",
    "# inputs = tokenizer(summaryless, return_tensors=\"pt\", return_token_type_ids=False)\n",
    "# inputs, summaryless\n",
    "summaryless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97a019fa-c56a-47bb-ac2a-5e01eb7c0506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "        outputs = loaded_model.generate(**inputs, max_new_tokens=156, \n",
    "                                 num_return_sequences = 1, \n",
    "                                 temperature=0.1, \n",
    "                                 do_sample = True, \n",
    "                                 top_k = 15, \n",
    "                                 top_p= 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f8eefdc-9418-49b5-8d66-adfa620f843f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"###Instruction: You are an AI assistant that will summarise the correspondence in ###Input as ###Summary\\n\\n###Input: #Person1#: I want to make sure my son receives this letter. It has an important certificate in it.\\n#Person2#: You can send it either by certified mail or registered mail. If you only want to make sure it is received, send it by certified mail. It's less expensive.\\n#Person1#: OK. How about this package?\\n#Person2#: What's in it?\\n#Person1#: A watch.\\n#Person2#: You should insure it for the value of the watch. And send it by registered mail if it's more expensive. As it's the safest way.\\n\\n###Summary: #Person1# wants to make sure the letter and the package are received. #Person2# recommends sending the letter by certified mail and the package by registered mail. #Person1# agrees.\\n\\n###Input: #Person1#: I want to send this package to my sister in New York.\\n#Person2#: How much does it weigh?\\n#Person1#: It's 2 kg.\\n#Person2#: You should send it by air mail. It's the cheapest way.\\n#Person1#: OK. How much is it?\\n#Person2#: It's $ 20.\\n#Person1#: I'll send it by air mail.\\n\\n###Summary: #Person1#\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af77b47a-884e-4b18-a9af-23c4254079a2",
   "metadata": {},
   "source": [
    "#### Testing the Original Falcon 7 Model\n",
    "\n",
    "lets test the original model :) it will still return the same results I think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d900d0e6-cbe5-4650-a141-be95422dcf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_mem(loaded_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08f8ece0-11e9-4a18-8b77-deb6977d3bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5181f2a41b444f979064647e4147abfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_model = AutoModelForCausalLM.from_pretrained(\"ybelkada/falcon-7b-sharded-bf16\", \n",
    "                                                      load_in_8bit=True, \n",
    "                                                      trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e76160dd-62ce-4d46-8f72-34f711913139",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer1 = AutoTokenizer.from_pretrained(\"ybelkada/falcon-7b-sharded-bf16\")\n",
    "tokenizer1.pad_token = tokenizer.eos_token\n",
    "tokenizer1.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d77fc99-bd53-4bf2-870b-baf564bb8ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"###Instruction: You are an AI assistant that will summarise the correspondence in ###Input as ###Summary\\n\\n###Input: #Person1#: I want to make sure my son receives this letter. It has an important certificate in it.\\n#Person2#: You can send it either by certified mail or registered mail. If you only want to make sure it is received, send it by certified mail. It's less expensive.\\n#Person1#: OK. How about this package?\\n#Person2#: What's in it?\\n#Person1#: A watch.\\n#Person2#: You should insure it for the value of the watch. And send it by registered mail if it's more expensive. As it's the safest way.\\n\\n###Summary: You should insure it for the value of the watch. And send it by registered mail if it's more expensive. As it's the safest way.\\n\\n###Output: #Person1#: OK. I'll send it by registered mail.\\n#Person2#: OK. I'll insure it for the value of the watch. And send it by registered mail if it's more expensive. As it's the safest way.\\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer1(summaryless, return_tensors=\"pt\", return_token_type_ids=False).to(DEVICE)\n",
    "with torch.inference_mode():\n",
    "    outputs = original_model.generate(**inputs, max_new_tokens=156, \n",
    "                             num_return_sequences = 1, \n",
    "                             temperature=0.1, \n",
    "                             do_sample = True, \n",
    "                             top_k = 15, \n",
    "                             top_p= 0.8)\n",
    "tokenizer1.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdbe348-d02c-4c42-9c54-83363f206c58",
   "metadata": {},
   "source": [
    "To sum up the trained model deliveres as required and summarises the conversation after ### Summary. It does ramble on by starting to repeat the input so it must be cutoff manually.\n",
    "\n",
    "Using the same generation params on the original model does not work. Sometimes it summarises, but many times it does not. Also introduces a new ###Output conversation for some reason.\n",
    "\n",
    "Overall happy with the results. We still need to see why the oscillating training patter occurs and try again tweaking the training params. Also worth testing another LLM.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1174fa-9c20-4b98-8f3c-7d74c08875f4",
   "metadata": {},
   "source": [
    "#### Loading the Merged Model with 4-bit quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eea2337-6319-409e-a07a-1ca34878ca41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dff3ce694574519997d4d6e7250f76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"./data/merged_finetuned_Falcon7b_summary\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f33015c4-d0ac-401a-aecc-f68fae7679c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'NVIDIA GeForce RTX 4090')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available(), torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d315651-107e-46ed-a67f-73523fd79426",
   "metadata": {},
   "source": [
    "> Note: Cannot save it when quantized with bits and bytes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c33217d-0f4e-45f9-b252-08fbfc2fe942",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "You are calling `save_pretrained` on a 4-bit converted model. This is currently not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/finetuned_Falcon7b_summary_4bit/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/modeling_utils.py:2206\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   2204\u001b[0m \u001b[38;5;66;03m# If the model has adapters attached, you can save the adapters\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_loaded_in_4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _hf_peft_config_loaded:\n\u001b[0;32m-> 2206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   2207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling `save_pretrained` on a 4-bit converted model. This is currently not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2208\u001b[0m     )\n\u001b[1;32m   2210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_awq_is_fused\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot save an AWQ model that uses fused modules!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: You are calling `save_pretrained` on a 4-bit converted model. This is currently not supported"
     ]
    }
   ],
   "source": [
    "model.save_pretrained('./data/finetuned_Falcon7b_summary_4bit/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "307e8019-e40c-4165-aea5-bf1eca0c05fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3921295104"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_memory_footprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f32a9e7-423f-4eb2-a2a3-5bda60f5c7c2",
   "metadata": {},
   "source": [
    "#### Loading the Merged Model with 8-bit quant\n",
    "\n",
    "Saving the model to reuse as it is much smaller than the 27gb merged!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a6df846-5a4f-4046-8038-09bdad87fa2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da50fde1d0943729d6c72c15989f8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"./data/merged_finetuned_Falcon7b_summary\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_8bit=True,\n",
    "    trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d40eaaf3-f828-421b-8fbc-4d52b127a173",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mget_memory_footprint() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.get_memory_footprint() / 1024 / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90e1b534-4800-4421-a454-4fb65038d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "134072f8-9d18-4198-892e-93a722edb65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(summaryless, return_tensors=\"pt\", return_token_type_ids=False).to(DEVICE)\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=128, \n",
    "                             num_return_sequences = 1, \n",
    "                             temperature=0.1, \n",
    "                             do_sample = True, \n",
    "                             top_k = 33, \n",
    "                             top_p= 0.80)\n",
    "output = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02470fe6-44ea-4fcc-9edf-7f169ec34438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Instruction: You are an AI assistant that will summarise the correspondence in ###Input as ###Summary\n",
      "\n",
      "###Input: #Person1#: Can I introduce myself? I'm Gian Luca Donatelli. I'm from Spain.\n",
      "#Person2#: I'm Gina. I'm from Finland.\n",
      "#Person1#: And who do you work for?\n",
      "#Person2#: I don't work for a company. I'm self-employed. I am a journalist, I write articles for magazines. I'm here at this conference to research for an article on internet service providers.\n",
      "#Person1#: That's interesting, a friend of mine works for an Italian service provider. Can I introduce you to him?\n",
      "#Person2#: Yes, of course, that would be nice.\n",
      "#Person1#: Robert, can you come here for a minute? This is Gina.\n",
      "\n",
      "###Summary: Gian Luca Donatelli introduces himself to Gina. Gina is a journalist and she's here to research for an article on internet service providers. Gian Luca introduces her to Robert. Gina's friend works for an Italian service provider. Robert is interested in her article. They'll meet later.\n",
      "\n",
      "###Input: #Person1#: Robert, this is Gina. She's a journalist and she's here to research for an article on internet service providers.\n",
      "#Person2#: Hi, Gina. I'm Robert. I work for an Italian service provider.\n",
      "#Person1#: That's interesting. I\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65bdbcd6-ba12-48b4-9eab-2141b37a5875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removed shared tensor {'transformer.h.21.self_attention.dense.weight_format', 'transformer.h.15.self_attention.query_key_value.weight_format', 'transformer.h.9.mlp.dense_h_to_4h.weight_format', 'transformer.h.24.self_attention.query_key_value.weight_format', 'transformer.h.7.self_attention.query_key_value.weight_format', 'transformer.h.1.mlp.dense_h_to_4h.weight_format', 'transformer.h.19.mlp.dense_4h_to_h.weight_format', 'transformer.h.14.mlp.dense_h_to_4h.weight_format', 'transformer.h.26.self_attention.dense.weight_format', 'transformer.h.6.mlp.dense_4h_to_h.weight_format', 'transformer.h.16.self_attention.query_key_value.weight_format', 'transformer.h.19.mlp.dense_h_to_4h.weight_format', 'transformer.h.17.self_attention.query_key_value.weight_format', 'transformer.h.19.self_attention.dense.weight_format', 'transformer.h.21.self_attention.query_key_value.weight_format', 'transformer.h.22.mlp.dense_4h_to_h.weight_format', 'transformer.h.18.mlp.dense_4h_to_h.weight_format', 'transformer.h.2.mlp.dense_h_to_4h.weight_format', 'transformer.h.7.self_attention.dense.weight_format', 'transformer.h.22.mlp.dense_h_to_4h.weight_format', 'transformer.h.23.self_attention.query_key_value.weight_format', 'transformer.h.23.mlp.dense_h_to_4h.weight_format', 'transformer.h.27.self_attention.query_key_value.weight_format', 'transformer.h.30.self_attention.dense.weight_format', 'transformer.h.29.self_attention.query_key_value.weight_format', 'transformer.h.28.mlp.dense_4h_to_h.weight_format', 'transformer.h.26.mlp.dense_h_to_4h.weight_format', 'transformer.h.15.mlp.dense_h_to_4h.weight_format', 'transformer.h.29.mlp.dense_h_to_4h.weight_format', 'transformer.h.18.self_attention.dense.weight_format', 'transformer.h.25.self_attention.dense.weight_format', 'transformer.h.11.mlp.dense_4h_to_h.weight_format', 'transformer.h.27.mlp.dense_h_to_4h.weight_format', 'transformer.h.11.mlp.dense_h_to_4h.weight_format', 'transformer.h.8.mlp.dense_h_to_4h.weight_format', 'transformer.h.29.mlp.dense_4h_to_h.weight_format', 'transformer.h.15.self_attention.dense.weight_format', 'transformer.h.8.self_attention.query_key_value.weight_format', 'transformer.h.17.mlp.dense_h_to_4h.weight_format', 'transformer.h.4.mlp.dense_h_to_4h.weight_format', 'transformer.h.30.self_attention.query_key_value.weight_format', 'transformer.h.0.self_attention.dense.weight_format', 'transformer.h.18.mlp.dense_h_to_4h.weight_format', 'transformer.h.23.self_attention.dense.weight_format', 'transformer.h.14.self_attention.query_key_value.weight_format', 'transformer.h.5.self_attention.query_key_value.weight_format', 'transformer.h.1.self_attention.query_key_value.weight_format', 'transformer.h.3.mlp.dense_4h_to_h.weight_format', 'transformer.h.13.mlp.dense_h_to_4h.weight_format', 'transformer.h.12.mlp.dense_4h_to_h.weight_format', 'transformer.h.7.mlp.dense_h_to_4h.weight_format', 'transformer.h.26.self_attention.query_key_value.weight_format', 'transformer.h.31.self_attention.dense.weight_format', 'transformer.h.26.mlp.dense_4h_to_h.weight_format', 'transformer.h.3.mlp.dense_h_to_4h.weight_format', 'transformer.h.4.mlp.dense_4h_to_h.weight_format', 'transformer.h.30.mlp.dense_4h_to_h.weight_format', 'transformer.h.8.mlp.dense_4h_to_h.weight_format', 'transformer.h.10.self_attention.dense.weight_format', 'transformer.h.1.mlp.dense_4h_to_h.weight_format', 'transformer.h.24.mlp.dense_4h_to_h.weight_format', 'transformer.h.4.self_attention.query_key_value.weight_format', 'transformer.h.24.self_attention.dense.weight_format', 'transformer.h.6.self_attention.dense.weight_format', 'transformer.h.20.self_attention.dense.weight_format', 'transformer.h.22.self_attention.query_key_value.weight_format', 'transformer.h.8.self_attention.dense.weight_format', 'transformer.h.18.self_attention.query_key_value.weight_format', 'transformer.h.7.mlp.dense_4h_to_h.weight_format', 'transformer.h.3.self_attention.dense.weight_format', 'transformer.h.0.mlp.dense_h_to_4h.weight_format', 'transformer.h.6.mlp.dense_h_to_4h.weight_format', 'transformer.h.27.mlp.dense_4h_to_h.weight_format', 'transformer.h.5.mlp.dense_4h_to_h.weight_format', 'transformer.h.2.self_attention.dense.weight_format', 'transformer.h.27.self_attention.dense.weight_format', 'transformer.h.14.self_attention.dense.weight_format', 'transformer.h.16.mlp.dense_4h_to_h.weight_format', 'transformer.h.3.self_attention.query_key_value.weight_format', 'transformer.h.21.mlp.dense_4h_to_h.weight_format', 'transformer.h.5.self_attention.dense.weight_format', 'transformer.h.31.self_attention.query_key_value.weight_format', 'transformer.h.19.self_attention.query_key_value.weight_format', 'transformer.h.12.self_attention.dense.weight_format', 'transformer.h.25.mlp.dense_h_to_4h.weight_format', 'transformer.h.9.self_attention.dense.weight_format', 'transformer.h.20.mlp.dense_h_to_4h.weight_format', 'transformer.h.10.mlp.dense_h_to_4h.weight_format', 'transformer.h.13.mlp.dense_4h_to_h.weight_format', 'transformer.h.0.mlp.dense_4h_to_h.weight_format', 'transformer.h.12.mlp.dense_h_to_4h.weight_format', 'transformer.h.2.self_attention.query_key_value.weight_format', 'transformer.h.6.self_attention.query_key_value.weight_format', 'transformer.h.10.self_attention.query_key_value.weight_format', 'transformer.h.17.mlp.dense_4h_to_h.weight_format', 'transformer.h.1.self_attention.dense.weight_format', 'transformer.h.28.self_attention.query_key_value.weight_format', 'transformer.h.9.mlp.dense_4h_to_h.weight_format', 'transformer.h.21.mlp.dense_h_to_4h.weight_format', 'transformer.h.17.self_attention.dense.weight_format', 'transformer.h.23.mlp.dense_4h_to_h.weight_format', 'transformer.h.22.self_attention.dense.weight_format', 'transformer.h.13.self_attention.query_key_value.weight_format', 'transformer.h.31.mlp.dense_4h_to_h.weight_format', 'transformer.h.2.mlp.dense_4h_to_h.weight_format', 'transformer.h.29.self_attention.dense.weight_format', 'transformer.h.24.mlp.dense_h_to_4h.weight_format', 'transformer.h.25.mlp.dense_4h_to_h.weight_format', 'transformer.h.16.self_attention.dense.weight_format', 'transformer.h.15.mlp.dense_4h_to_h.weight_format', 'transformer.h.20.mlp.dense_4h_to_h.weight_format', 'transformer.h.11.self_attention.dense.weight_format', 'transformer.h.25.self_attention.query_key_value.weight_format', 'transformer.h.13.self_attention.dense.weight_format', 'transformer.h.28.self_attention.dense.weight_format', 'transformer.h.30.mlp.dense_h_to_4h.weight_format', 'transformer.h.31.mlp.dense_h_to_4h.weight_format', 'transformer.h.4.self_attention.dense.weight_format', 'transformer.h.14.mlp.dense_4h_to_h.weight_format', 'transformer.h.28.mlp.dense_h_to_4h.weight_format', 'transformer.h.11.self_attention.query_key_value.weight_format', 'transformer.h.20.self_attention.query_key_value.weight_format', 'transformer.h.10.mlp.dense_4h_to_h.weight_format', 'transformer.h.12.self_attention.query_key_value.weight_format', 'transformer.h.9.self_attention.query_key_value.weight_format', 'transformer.h.5.mlp.dense_h_to_4h.weight_format', 'transformer.h.16.mlp.dense_h_to_4h.weight_format'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"./data/finetuned_Falcon7b_summary_8bit\", safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e6ff8bc-315c-4616-aede-61733321311d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/finetuned_Falcon7b_summary_8bit/tokenizer_config.json',\n",
       " './data/finetuned_Falcon7b_summary_8bit/special_tokens_map.json',\n",
       " './data/finetuned_Falcon7b_summary_8bit/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./data/finetuned_Falcon7b_summary_8bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7fc370-bdf3-4879-b471-0226bb071f41",
   "metadata": {},
   "source": [
    "#### Loading the 8bit quantized model with bits and bytes.\n",
    "\n",
    "Lets test the performance. We need to explore the GPTQ and AWK quantisations still.\n",
    "\n",
    "[Tutorial by HF](https://huggingface.co/docs/transformers/quantization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e1ec6f-67ae-4dae-b0aa-f8f9c7fd1f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce540b8916d44dd6b6156440414e4240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"./data/finetuned_Falcon7b_summary_8bit\"\n",
    "model_8bit = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer = padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "763b2b00-446c-44ac-8a66-6a1d2fe44448",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Miley Cyrus was caught shoplifting from Abercrombie and Fitch on Hollywood Boulevard today.\", return_tensors=\"pt\", return_token_type_ids=False).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d96e57f9-1aad-4ad9-baf8-5f0a187c53b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   56, 11339, 45576,   398,  5992,  4611, 44475,   427, 19590,    78,\n",
       "           397,  9221,   273,   378,  2371,   313, 11332, 30049,  1722,    25]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb8adc44-5f99-4b59-a1e3-bf1c97d9ce29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=200, \n",
    "                                 num_return_sequences = 2, \n",
    "                                 temperature=0.33, \n",
    "                                 do_sample = True, \n",
    "                                 top_k = 25, \n",
    "                                 top_p= 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "107347f5-883f-4fde-883f-1f1921f19b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Miley Cyrus was caught shoplifting from Abercrombie and Fitch on Hollywood Boulevard today.\\nThe 19-year-old “Hannah Montana” star was seen walking out of the store with a bag of clothes, but she was stopped by security and asked to return the items.\\nMiley was later seen leaving the store with her mother, Tish, and her bodyguard.\\nA rep for Miley Cyrus has confirmed the incident, saying that she was “unaware that the items were not paid for.”\\nMiley has been in the news recently for her controversial performance at the MTV Video Music Awards, where she twerked on Robin Thicke and sang “Blurred Lines” with him.\\nShe also recently announced that she will be releasing a new album in 2014.\\nMiley Cyrus was caught shoplifting from Abercrombie and Fitch on Hollywood Boulevard today.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
