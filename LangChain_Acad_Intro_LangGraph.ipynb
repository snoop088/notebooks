{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12895f45-3aa5-442e-b0fe-09c6c1527260",
   "metadata": {},
   "source": [
    "# Introduction to LangGraph\n",
    "\n",
    "Setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd11501-63f9-46a9-a663-34951802e5e8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.42.4)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.0-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n",
      "Downloading transformers-4.46.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.42.4\n",
      "    Uninstalling transformers-4.42.4:\n",
      "      Successfully uninstalled transformers-4.42.4\n",
      "Successfully installed tokenizers-0.20.1 transformers-4.46.0\n",
      "Collecting langchain_groq\n",
      "  Downloading langchain_groq-0.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
      "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-core<0.4,>=0.3 (from langchain_groq)\n",
      "  Downloading langchain_core-0.3.13-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain_groq) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain_groq) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain_groq) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain_groq) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core<0.4,>=0.3->langchain_groq)\n",
      "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain_groq) (24.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain_groq) (8.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (3.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (2.2.2)\n",
      "Downloading langchain_groq-0.2.0-py3-none-any.whl (14 kB)\n",
      "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.13-py3-none-any.whl (408 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.0/408.0 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.9/296.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langsmith, groq, langchain-core, langchain_groq\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.92\n",
      "    Uninstalling langsmith-0.1.92:\n",
      "      Successfully uninstalled langsmith-0.1.92\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.21\n",
      "    Uninstalling langchain-core-0.2.21:\n",
      "      Successfully uninstalled langchain-core-0.2.21\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langgraph 0.1.9 requires langchain-core<0.3,>=0.2.19, but you have langchain-core 0.3.13 which is incompatible.\n",
      "langchain-huggingface 0.0.3 requires langchain-core<0.3,>=0.1.52, but you have langchain-core 0.3.13 which is incompatible.\n",
      "langchain-text-splitters 0.2.2 requires langchain-core<0.3.0,>=0.2.10, but you have langchain-core 0.3.13 which is incompatible.\n",
      "langchain 0.2.9 requires langchain-core<0.3.0,>=0.2.20, but you have langchain-core 0.3.13 which is incompatible.\n",
      "langchain-openai 0.1.17 requires langchain-core<0.3.0,>=0.2.20, but you have langchain-core 0.3.13 which is incompatible.\n",
      "langchain-community 0.2.7 requires langchain-core<0.3.0,>=0.2.12, but you have langchain-core 0.3.13 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed groq-0.11.0 langchain-core-0.3.13 langchain_groq-0.2.0 langsmith-0.1.137\n",
      "Requirement already satisfied: langchain-community in /opt/conda/lib/python3.11/site-packages (0.2.7)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n",
      "Collecting langchain<0.4.0,>=0.3.4 (from langchain-community)\n",
      "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (0.3.13)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.4->langchain-community)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.4->langchain-community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.6)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain-community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: pydantic-settings, langchain-text-splitters, langchain, langchain-community\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.2.2\n",
      "    Uninstalling langchain-text-splitters-0.2.2:\n",
      "      Successfully uninstalled langchain-text-splitters-0.2.2\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.2.9\n",
      "    Uninstalling langchain-0.2.9:\n",
      "      Successfully uninstalled langchain-0.2.9\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.2.7\n",
      "    Uninstalling langchain-community-0.2.7:\n",
      "      Successfully uninstalled langchain-community-0.2.7\n",
      "Successfully installed langchain-0.3.4 langchain-community-0.3.3 langchain-text-splitters-0.3.0 pydantic-settings-2.6.0\n",
      "Requirement already satisfied: langchain-core in /opt/conda/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain-core) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.11/site-packages (from langchain-core) (0.1.137)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain-core) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.11/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (3.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.20.1)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (4.4.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (2.2.2)\n",
      "Collecting dotenv\n",
      "  Downloading dotenv-0.0.5.tar.gz (2.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[83 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /opt/conda/lib/python3.11/site-packages/setuptools/__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Requirements should be satisfied by a PEP 517 installer.\n",
      "  \u001b[31m   \u001b[0m         If you are using pip, you can try `pip install --use-pep517`.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   dist.fetch_build_eggs(dist.setup_requires)\n",
      "  \u001b[31m   \u001b[0m   \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m╰─>\u001b[0m \u001b[31m[17 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 14, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/tmp/pip-wheel-6fi80nmi/distribute_85646607760b4d5686cdb0e9143081bb/setuptools/__init__.py\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     from setuptools.extension import Extension, Library\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/tmp/pip-wheel-6fi80nmi/distribute_85646607760b4d5686cdb0e9143081bb/setuptools/extension.py\", line 5, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     from setuptools.dist import _get_unpatched\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/tmp/pip-wheel-6fi80nmi/distribute_85646607760b4d5686cdb0e9143081bb/setuptools/dist.py\", line 7, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     from setuptools.command.install import install\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/tmp/pip-wheel-6fi80nmi/distribute_85646607760b4d5686cdb0e9143081bb/setuptools/command/__init__.py\", line 8, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     from setuptools.command import install_scripts\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/tmp/pip-wheel-6fi80nmi/distribute_85646607760b4d5686cdb0e9143081bb/setuptools/command/install_scripts.py\", line 3, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     from pkg_resources import Distribution, PathMetadata, ensure_directory\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/tmp/pip-wheel-6fi80nmi/distribute_85646607760b4d5686cdb0e9143081bb/pkg_resources.py\", line 1518, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     register_loader_type(importlib_bootstrap.SourceFileLoader, DefaultProvider)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m AttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[31m   \u001b[0m \u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "  \u001b[31m   \u001b[0m \u001b[1;36mhint\u001b[0m: See above for details.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/setuptools/installer.py\", line 101, in _fetch_build_egg_no_warn\n",
      "  \u001b[31m   \u001b[0m     subprocess.check_call(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/subprocess.py\", line 413, in check_call\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, cmd)\n",
      "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['/opt/conda/bin/python3.11', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/tmp/tmpv7qosfkw', '--quiet', 'distribute']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-bpgukyoo/dotenv_bbc6373219174ec1aee0276c5309d1de/setup.py\", line 13, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(name='dotenv',\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/setuptools/__init__.py\", line 102, in setup\n",
      "  \u001b[31m   \u001b[0m     _install_setup_requires(attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/setuptools/__init__.py\", line 75, in _install_setup_requires\n",
      "  \u001b[31m   \u001b[0m     _fetch_build_eggs(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/setuptools/__init__.py\", line 80, in _fetch_build_eggs\n",
      "  \u001b[31m   \u001b[0m     dist.fetch_build_eggs(dist.setup_requires)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/setuptools/dist.py\", line 641, in fetch_build_eggs\n",
      "  \u001b[31m   \u001b[0m     return _fetch_build_eggs(self, requires)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/setuptools/installer.py\", line 38, in _fetch_build_eggs\n",
      "  \u001b[31m   \u001b[0m     resolved_dists = pkg_resources.working_set.resolve(\n",
      "  \u001b[31m   \u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/pkg_resources/__init__.py\", line 889, in resolve\n",
      "  \u001b[31m   \u001b[0m     dist = self._resolve_dist(\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/pkg_resources/__init__.py\", line 925, in _resolve_dist\n",
      "  \u001b[31m   \u001b[0m     dist = best[req.key] = env.best_match(\n",
      "  \u001b[31m   \u001b[0m                            ^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/pkg_resources/__init__.py\", line 1256, in best_match\n",
      "  \u001b[31m   \u001b[0m     return self.obtain(req, installer)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/pkg_resources/__init__.py\", line 1292, in obtain\n",
      "  \u001b[31m   \u001b[0m     return installer(requirement) if installer else None\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/setuptools/installer.py\", line 103, in _fetch_build_egg_no_warn\n",
      "  \u001b[31m   \u001b[0m     raise DistutilsError(str(e)) from e\n",
      "  \u001b[31m   \u001b[0m distutils.errors.DistutilsError: Command '['/opt/conda/bin/python3.11', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/tmp/tmpv7qosfkw', '--quiet', 'distribute']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -U langgraph\n",
    "!pip install langgraph-sdk\n",
    "!pip install langgraph-checkpoint-sqlite\n",
    "!pip install langsmith\n",
    "!pip install -U langchain-community\n",
    "!pip install -U langchain-core\n",
    "\n",
    "!pip install -U langchain_huggingface\n",
    "!pip install -U langchain_openai\n",
    "\n",
    "!pip install -U dotenv\n",
    "\n",
    "!pip install tavily-python\n",
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556eef1b-b948-4038-93f8-a1a73d1cc8d3",
   "metadata": {},
   "source": [
    "Importing all env vars to enable our integrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c0f50c-d92e-4070-9b39-f4595be0b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49103505-5cd0-4085-bd7d-f957334bb63a",
   "metadata": {},
   "source": [
    "Initialise the ChatGPT 4o\n",
    "\n",
    "Initialise other tools that we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a8eb8b-7ec9-4333-87b9-ce7efdfdab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c19366cf-7e3f-48ba-a5b9-ad6632c8d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = HumanMessage(content=\"Hi there, who are you?\", name=\"Roy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "241ed58c-693a-436e-9940-fc3f8d18a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0568bc07-64e5-4255-aa25-c5cbcd2e434d",
   "metadata": {},
   "source": [
    "Checking that all is in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6a18b5-4818-4b02-85a5-d053febe2a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm an AI language model created by OpenAI, here to help answer your questions and provide information on a wide range of topics. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 16, 'total_tokens': 51, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_45cf54deae', 'finish_reason': 'stop', 'logprobs': None}, id='run-e30a32ef-3fe3-4729-ba9d-6e1e9b6352f4-0', usage_metadata={'input_tokens': 16, 'output_tokens': 35, 'total_tokens': 51, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4o_chat.invoke([msg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c780e568-e96d-4bea-8f81-4d06b1683379",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "search_docs = tavily_search.invoke(\"What kind of platform is Streameye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d3eb08b-6e04-4c25-a9dc-c6b6697f998a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.elecard.com/products',\n",
       "  'content': 'Elecard StreamEye Studio is a set of powerful software tools for video quality analysis designed for professional use in video compression, processing, communication and streaming media industries. ... Professional platform for real-time encoding and transcoding into HEVC/H.265, AVC/H.264 and MPEG-2 video supporting adaptive bitrate streaming ...'},\n",
       " {'url': 'https://www.streameye.com/blog/streameye_integrates_with_google_studio',\n",
       "  'content': \"The English sports streaming service DAZN has been relying on StreamEye to be its digital production partner for years. ... seamlessly integrating SteamEye's content production abilities with the analytical powerhouse of Google's Marketing Platform. StreamEye + Google Studio, the Best of Both Worlds. Before this integration, DAZN had one ...\"},\n",
       " {'url': 'https://videocompressionguru.medium.com/overview-of-elecard-streameye-studio-set-of-applications-1d4d8b0a27ab',\n",
       "  'content': 'Elecard StreamEye Studio is a set of powerful software tools for video quality analysis designed for professional use in video compression, processing, communication and streaming media industries. It includes 5 separate stand-alone applications and command line tools for all-around video analysis.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a13c80-f052-47b3-8ddb-9b868d20ba61",
   "metadata": {},
   "source": [
    "## The Simplest Graph\n",
    "\n",
    "Simple graph with 3 nodes and conditional edge that would choose which node follows node 1.\n",
    "\n",
    "![Simple Graph](https://camo.githubusercontent.com/8ec53b6c113f6b577fefce84dd3089bc0d7192ded112d76d464f400c712ae693/68747470733a2f2f63646e2e70726f642e776562736974652d66696c65732e636f6d2f3635623863643732383335636565616364343434396135332f3636646261356634363566366539613234383261643933355f73696d706c652d6772617068312e706e67 \"Simple Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ac8c66-3c16-4f98-8576-5ee7f1754d29",
   "metadata": {},
   "source": [
    "### State\n",
    "\n",
    "Defining the state of the graph. This serves as a shared state along all the nodes and edges of the graph.\n",
    "\n",
    "Let's use the TypedDict class from python's typing module as our schema, which provides type hints for the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8351dd61-9f22-4130-b583-61d759243def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    graph_state: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae2c63-c637-41fb-a7dc-04c3d129ab0d",
   "metadata": {},
   "source": [
    "### Nodes\n",
    "\n",
    "Nodes are just Python functions. The first position argument in these functions is the state!\n",
    "\n",
    "The nodes operate on the state. By default the would overrid the previous state value with new, hence mutating the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32e0b22a-6819-44d8-b7ab-2ea340b6d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" I am\"}\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"---Node 2---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" happy!\"}\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"---Node 3---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" sad!\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f0ed1c-3814-4d32-903c-f0809406cd0e",
   "metadata": {},
   "source": [
    "### Edges\n",
    "\n",
    "Edges connexct the nodes.\n",
    "\n",
    "Normal edges always go from specific node to next, while conditional apply some logic to route between possible edges.\n",
    "\n",
    "Conditional edges are implemented as functions that return the next edge to visit based on that logic.\n",
    "\n",
    "A node can have MULTIPLE outgoing edges. If a node has multiple out-going edges, all of those destination nodes will be executed in parallel as a part of the next superstep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2223e2af-b465-40e5-8cce-4f452a0c9b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Literal\n",
    "\n",
    "def decide_mood(state) -> Literal[\"node_2\", \"node_3\"]:\n",
    "    \n",
    "    # Often, we will use state to decide on the next node to visit\n",
    "    # user_input = state['graph_state'] \n",
    "    \n",
    "    # Here, let's just do a 50 / 50 split between nodes 2, 3\n",
    "    if random.random() < 0.5:\n",
    "\n",
    "        # 50% of the time, we return Node 2\n",
    "        return \"node_2\"\n",
    "    \n",
    "    # 50% of the time, we return Node 3\n",
    "    return \"node_3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f2f6de-11a3-4434-8b01-1bafad4832ee",
   "metadata": {},
   "source": [
    "### Graph Construction\n",
    "\n",
    "We can build the graph from the components defined above.\n",
    "\n",
    "We will use the StateGraph class in this exmaple.\n",
    "\n",
    "1. Initialise the StateGraph with the `state` defined above.\n",
    "2. We add the nodes and edges\n",
    "3. We use the special node `START`, which indicates where to start the graph.\n",
    "4. Similarly `END` node is a special node that indicates where the graph terminates.\n",
    "\n",
    "Finally the graph is compiled.\n",
    "\n",
    "We can visualise the graph via a Mermaid diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d334a73-f9f5-4a78-804d-5951bbc93357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State) # remember State is a class defined above as a \n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
    "builder.add_edge(\"node_2\", END)\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c67fa5-aade-4cc1-9132-e33e6e1dd308",
   "metadata": {},
   "source": [
    "### Graph Invocation\n",
    "\n",
    "The compiled graph implements the [runnable](https://python.langchain.com/v0.1/docs/expression_language/interface/) protocol.\n",
    "\n",
    "This interface provides a standard way to execute LangChain commands.\n",
    "\n",
    "`Invoke` is a method from this interface. The input should be a dictionary of type State which sets the initial state of the graph. E.g. `{\"graph_state\": \"Hi, this is Snoop.\"}`\n",
    "\n",
    "When invoke is called, the graph starts execution from the START node.\n",
    "\n",
    "It progresses through the defined nodes (node_1, node_2, node_3) in order.\n",
    "\n",
    "The conditional edge will traverse from node 1 to node 2 or 3 using a 50/50 decision rule.\n",
    "\n",
    "Each node function receives the current state and returns a new value, which overrides the graph state.\n",
    "\n",
    "The execution continues until it reaches the END node.\n",
    "\n",
    "`Invoke` runs the whole graph synchrounously. I.e. waiting for each step/ node function to complete before going to the next as defined by the edges. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dd764ac-240e-4b70-84ad-2c1a8c920cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "---Node 3---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'graph_state': 'Hi, this is Snoop. I am sad!'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"graph_state\": \"Hi, this is Snoop.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c0c35-5519-4bf7-9e49-80028cf005a9",
   "metadata": {},
   "source": [
    "### Routing to Tools in LangGraph\n",
    "\n",
    "The idea of this section is to design a graph that would conditionally route execution between a tool node or directly answer a question via an LLM. \n",
    "\n",
    "To achieve this we must initialise an LLM like above and register a tool in it. Lets do it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae506e33-78d0-47b1-8906-0f28a207f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff8ebe3-b304-4c62-880e-1f12c9c9dc3f",
   "metadata": {},
   "source": [
    "After this, we can use the following two ideas:\n",
    "\n",
    "1. Add a node that will call our tool.\n",
    "    - We use the built-in ToolNode and simply pass a list of our tools to initialize it.\n",
    "3. Add a conditional edge that will look at the chat model output, and route to our tool calling node or simply end if no tool call is performed.\n",
    "   - We use the built-in tools_condition as our conditional edge.\n",
    "\n",
    ">Note: Instead of defining our own State class here, we use the prebuilt MessagesState. The cool thing for this class is that it already has the messages key defined, but also more importantly it uses LangChains add_meesages reducer to add/ append new messages to the state instead of overwriting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2628980b-8534-463b-87c3-4833105cda71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19aa75cd-3b83-4806-9f76-b4a8e9e32a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x776135dbed90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    # messages are appended somehow via this reducer instead of overwritten\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]} \n",
    "# Build the Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode([multiply]))\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\"tool_calling_llm\", tools_condition)\n",
    "builder.add_edge(\"tools\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d180cb1-9a61-411e-8011-5688a962e8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile and View\n",
    "graph = builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09eae857-19c6-40bd-9ce3-33f9eef6e115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Can you tell me which is the most densely populated country in the world?', id='da40064a-7570-49a2-afcb-baf944e187b5'),\n",
       "  AIMessage(content='As of the latest data, the most densely populated country in the world is Monaco. Monaco has an extremely high population density due to its small area and relatively large population. The population density of Monaco is over 25,000 people per square kilometer.', response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 67, 'total_tokens': 118}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5', 'finish_reason': 'stop', 'logprobs': None}, id='run-aa174be6-5932-4e46-bbb4-2437ac26cd54-0', usage_metadata={'input_tokens': 67, 'output_tokens': 51, 'total_tokens': 118})]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = {\"messages\": \"Can you tell me which is the most densely populated country in the world?\"}\n",
    "graph.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "953ee6cb-a6c1-4e27-8090-9c36ee8145c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "please multiply 5 and 125\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_PLIsPkp3sNdLjHbWjHE9B4KW)\n",
      " Call ID: call_PLIsPkp3sNdLjHbWjHE9B4KW\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 125\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "625\n"
     ]
    }
   ],
   "source": [
    "tool_message = {\"messages\": \"please multiply 5 and 125\"}\n",
    "response = graph.invoke(tool_message)\n",
    "for r in response['messages']:\n",
    "    r.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d872d7ad-e585-4c9f-9f81-a8d12d0d429f",
   "metadata": {},
   "source": [
    "### Agents\n",
    "\n",
    "Agents are like Routers but output of the tools are fed back to the edge node (the LLM in this case) and LLM reasons what to do next. Compare the two architectures below:\n",
    "\n",
    "| Router   | Agent | \n",
    "| -------    | ------  |\n",
    "| ![Router Architecture](https://camo.githubusercontent.com/3e12a13cebe803eca00c2260c9934d5e1dd3a2d17b3075d11859ae36536ae70f/68747470733a2f2f63646e2e70726f642e776562736974652d66696c65732e636f6d2f3635623863643732383335636565616364343434396135332f3636646261633062613062643334623534316334343863635f6167656e74312e706e67 \"Router Architecture\")     |  ![Agent Architecture](https://camo.githubusercontent.com/f5f9c339b6e85deb9f01b26585c2bbd5cf706cb185dea5606fd02ff778777bca/68747470733a2f2f63646e2e70726f642e776562736974652d66696c65732e636f6d2f3635623863643732383335636565616364343434396135332f3636646261633062346132633165356530326633653738625f6167656e74322e706e67 \"Agent Archutecture\")    |\n",
    "\n",
    "In the above router, we invoked the model and, if it chose to call a tool, we returned a ToolMessage to the user.\n",
    "\n",
    "But, what if we simply pass that ToolMessage back to the model?\n",
    "\n",
    "We can let it either (1) call another tool or (2) respond directly.\n",
    "\n",
    "This is the intuition behind ReAct, a general agent architecture.\n",
    "\n",
    "- **act** - let the model call specific tools\n",
    "- **observe** - pass the tool output back to the model\n",
    "- **reason** - let the model reason about the tool output to decide what to do next (e.g., call another tool or just respond directly)\n",
    "\n",
    "OK, lets give it a go. Let's define few more tools so that we can see if the LLM would reason which to use when."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed23059f-5627-451c-ad75-376531ecfa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import OpenLLMCreatorHF\n",
    "\n",
    "llm_factory = OpenLLMCreatorHF(model=\"meta-llama/Llama-3.2-3B-Instruct\", temperature=0.2, max_tokens=1024, top_p=0.85)\n",
    "llm = llm_factory.get_from_endpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee44fc7-dfbd-4788-8b07-33d26b41bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "from typing_extensions import TypedDict, Literal\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# @tool(parse_docstring=True)\n",
    "# def multiply(a: int, b: int) -> int:\n",
    "#     \"\"\"Multiply a by b.\n",
    "\n",
    "#     Args:\n",
    "#         a: first number\n",
    "#         b: second number\n",
    "#     \"\"\"\n",
    "#     return a * b\n",
    "\n",
    "# # This will be a tool\n",
    "# @tool(parse_docstring=True)\n",
    "# def add(a: float, b: float) -> float:\n",
    "#     \"\"\"Adds a and b.\n",
    "\n",
    "#     Args:\n",
    "#         a: first float\n",
    "#         b: second float\n",
    "#     \"\"\"\n",
    "#     return a + b\n",
    "\n",
    "# @tool(parse_docstring=True)\n",
    "# def divide(a: float, b: float) -> float:\n",
    "#     \"\"\"Adds a and b.\n",
    "\n",
    "#     Args:\n",
    "#         a: first float\n",
    "#         b: second float\n",
    "#     \"\"\"\n",
    "#     return a / b\n",
    "\n",
    "# tools = [add, multiply, divide]\n",
    "\n",
    "# class Multiply(BaseModel):\n",
    "#     '''Multiplies first argument with second argument, returning a float'''\n",
    "\n",
    "#     a: int = Field(description=\"the first argument of the function as integer\")\n",
    "#     b: int = Field(description=\"the second argument of the function as integer\")\n",
    "    \n",
    "# @tool(args_schema=Multiply, return_direct=True)\n",
    "# def multiply(a: int, b: int) -> float:\n",
    "#     '''Multiplies the first argument by the second argument, returns a float'''\n",
    "\n",
    "#     return a * b\n",
    "\n",
    "# class Add(BaseModel):\n",
    "#     '''Get the current population in a given location'''\n",
    "\n",
    "#     location: str = Field(description=\"The city to report population for, e.g. San Francisco\")\n",
    "\n",
    "class Operands(TypedDict):\n",
    "    a: float\n",
    "    b: float\n",
    "\n",
    "class CalculatorModel(BaseModel):\n",
    "    operands: Operands\n",
    "    op: Literal[\"add\", \"sub\", \"mult\", \"div\"]\n",
    "\n",
    "@tool(args_schema=CalculatorModel)\n",
    "def calculator(operands: Operands, op: Literal[\"add\", \"sub\", \"mult\", \"div\"]) -> float:\n",
    "    '''Perform basic arithmetic operations on calculator model. Return a float'''\n",
    "    \n",
    "    if (op == \"add\"):\n",
    "        return operands[\"a\"] + operands[\"b\"]\n",
    "    elif (op == \"mult\"):\n",
    "        return operands[\"a\"] * operands[\"b\"]\n",
    "    elif (op == 'sub'):\n",
    "        return operands[\"a\"] - operands[\"b\"]\n",
    "    elif (op == 'div'):\n",
    "        return operands[\"a\"] / operands[\"b\"]\n",
    "    else:\n",
    "        return -1.\n",
    "\n",
    "tools = [calculator]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4730ee4-2ff8-4cb5-bcd5-4ddd930122bf",
   "metadata": {},
   "source": [
    "> Here we will create a GPT 4o LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6f79c5a-47ec-4656-9365-97a8b3599255",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478314a9-d44e-4c81-abc3-1a9c993f60e4",
   "metadata": {},
   "source": [
    "> Here lets try an open source LLM like the Meta LLama 3.1\n",
    "\n",
    "**IMPORTANT** Currently unable to run tools on local models with ChatHuggingFace. Nor was I able to work with the HuggingFaceEndpoint. The tool returned result, but the LLM kept calling it, reaching the limit of 25 recursive calls.\n",
    "\n",
    "Potentially try Ollama, ***but for now recommended is to use Groq or try Cerebras which are free and fast.***\n",
    "\n",
    "Following sections are all commented out for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185ac228-d254-4db3-9b3f-b320afdea328",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.45.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "# upgrading transformers\n",
    "# !pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f17a547e-8c4f-4114-aeb6-af0ef7f37954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8e9f8b28284643816d1c720de1604a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import (\n",
    "#     AutoTokenizer,\n",
    "#     BitsAndBytesConfig,\n",
    "#     TrainingArguments,\n",
    "#     AutoModelForCausalLM,\n",
    "#     DataCollatorForLanguageModeling,\n",
    "#     GenerationConfig,\n",
    "#     pipeline\n",
    "# )\n",
    "\n",
    "# model_name = \"../ext_models/Meta-Llama-3.1-8B-Instruct\"\n",
    "# DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, \n",
    "#                                              device_map=DEVICE, \n",
    "#                                              torch_dtype=\"auto\")\n",
    "# generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37a52d8-1460-4ce6-95bc-06dfb3339c10",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# stop_token = \"<|eot_id|>\"  \n",
    "# stop_token_id = tokenizer.encode(stop_token)[0]\n",
    "# begin_token = \"<|begin_of_text|>\"\n",
    "# begin_token_id = tokenizer.encode(begin_token)[0]\n",
    "# generation_config.eos_token_id = stop_token_id\n",
    "# generation_config.begin_token_id = begin_token_id\n",
    "# generation_config.max_new_tokens = 1024\n",
    "# generation_config.temperature = 0.1\n",
    "# generation_config.top_p = 0.9\n",
    "# generation_config.do_sample = True\n",
    "# generation_config.repetition_penalty = 1.15\n",
    "# generation_config.pad_token_id = tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "318c6fb5-d65a-4b9f-ad6a-8da1cc5d209e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "# llm_pipeline = pipeline(\"text-generation\", \n",
    "#                         model=model, \n",
    "#                         tokenizer=tokenizer, \n",
    "#                         generation_config=generation_config, \n",
    "#                         return_full_text=False) \n",
    "# open_llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "# open_chat = ChatHuggingFace(llm=open_llm, verbose=True)\n",
    "# llm_with_tools = open_chat.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494dfe5-ba83-4fb3-9a7a-b026bb3b705a",
   "metadata": {},
   "source": [
    "So we are stuck here pretty much. We need to have this extended to open source agents.\n",
    "\n",
    "OK - so lets try the ChatHugginFace class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8878f074-6625-4297-96b3-ecdf6a0863cd",
   "metadata": {},
   "source": [
    "Let's create our LLM and prompt it with the overall desired agent behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6919a67-0c02-4da2-ae93-638677f275cc",
   "metadata": {},
   "source": [
    "### Using HF Endpoint instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe04a486-e4d0-4a71-94b6-897d40d3386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "# open_llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "#     # repo_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=1024,\n",
    "#     do_sample=True,\n",
    "#     repetition_penalty=1.1,\n",
    "# )\n",
    "# chat = ChatHuggingFace(llm=open_llm, verbose=True)\n",
    "chat_with_tools = chat.bind_tools(tools=simple_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "828b3b24-c536-48c7-9c08-de64b0984ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40fb422d-0328-4730-ac7c-b7a2fdd6e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System message - we will add a system message this time\n",
    "sys_msg = SystemMessage(content=\"You are a helpfull assistant tasked with performing arithmetic operations on set of inputs.\")\n",
    "\n",
    "# The Assistant Node\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "### The below was me trying to convert messages into another form, but it was all waste of time since \n",
    "### the MessagesState uses a reducer with HumanMessage, AIMessage formatting\n",
    "    \n",
    "# def open_assistant(state: MessagesState):\n",
    "\n",
    "#     print(\"state\", state[\"messages\"])\n",
    "#     m = [{\"role\": \"system\", \"content\": \"You are a very helpful assistant, tasked with performing arithmetic operations on set of inputs.\"},\n",
    "#          {\"role\": \"user\", \"content\": \"can you multiply 3 by 2 please\"}]\n",
    "\n",
    "#     templated = tokenizer.apply_chat_template(m, tokenize=False )\n",
    "#     print(\"TMPL\", templated)\n",
    "#     result = llm_with_tools.invoke(m)\n",
    "#     print(\"RES\", result)\n",
    "#     return {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e262da4-c998-4a0e-90b3-171225551968",
   "metadata": {},
   "source": [
    "As before, we use MessagesState and define a Tools node with our list of tools.\n",
    "\n",
    "We create a graph with Assistant and Tools nodes.\n",
    "\n",
    "We add `tools_condition` edge, which routes to End or to Tools based on whether the Assistant calls a tool.\n",
    "\n",
    "*Now, we add one new step:*\n",
    "\n",
    "We connect the Tools node back to the Assistant, forming a loop.\n",
    "\n",
    "- After the assistant node executes, tools_condition checks if the model's output is a tool call.\n",
    "- If it is a tool call, the flow is directed to the tools node.\n",
    "- The tools node connects back to assistant.\n",
    "- This loop continues as long as the model decides to call tools.\n",
    "- If the model response is not a tool call, the flow is directed to END, terminating the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39571f49-4d16-42df-abb0-ee1d3dce8bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x798320782f90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"assistant\")\n",
    "# tools_condition is a ready to use conditional function that would route to tool or END automatically.\n",
    "# If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "# If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "# below is the loop, instead of routing tools to END and finishing on the first cycle of the GRAPH we loop back to the Assistant\n",
    "builder.add_edge(\"tools\", \"assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15354c51-e264-4d03-999f-ff014c36edd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "react_graph = builder.compile()\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4be38b67-0101-4b5f-afd6-6b3027989ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/inference/_generated/types/base.py:139: FutureWarning: Accessing 'ChatCompletionOutputToolCall' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/inference/_generated/types/base.py:139: FutureWarning: Accessing 'ChatCompletionOutputToolCall' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/inference/_generated/types/base.py:139: FutureWarning: Accessing 'ChatCompletionOutputToolCall' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/inference/_generated/types/base.py:139: FutureWarning: Accessing 'ChatCompletionOutputToolCall' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/inference/_generated/types/base.py:139: FutureWarning: Accessing 'ChatCompletionOutputToolCall' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/inference/_generated/types/base.py:139: FutureWarning: Accessing 'ChatCompletionOutputToolCall' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/inference/_generated/types/base.py:139: FutureWarning: Accessing 'ChatCompletionOutputToolCall' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/inference/_generated/types/base.py:139: FutureWarning: Accessing 'ChatCompletionOutputToolCall' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/inference/_generated/types/base.py:139: FutureWarning: Accessing 'ChatCompletionOutputToolCall' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/inference/_generated/types/base.py:139: FutureWarning: Accessing 'ChatCompletionOutputToolCall' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/inference/_generated/types/base.py:139: FutureWarning: Accessing 'ChatCompletionOutputToolCall' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/inference/_generated/types/base.py:139: FutureWarning: Accessing 'ChatCompletionOutputToolCall' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/inference/_generated/types/base.py:139: FutureWarning: Accessing 'ChatCompletionOutputToolCall' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m messages \u001b[38;5;241m=\u001b[39m [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiply 6 by 6 and add 315 divided by 15 to the product\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mreact_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1600\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1599\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1600\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1348\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1340\u001b[0m     msg \u001b[38;5;241m=\u001b[39m create_error_message(\n\u001b[1;32m   1341\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1342\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mGRAPH_RECURSION_LIMIT,\n\u001b[1;32m   1347\u001b[0m     )\n\u001b[0;32m-> 1348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   1350\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Multiply 6 by 6 and add 315 divided by 15 to the product\")]\n",
    "\n",
    "result = react_graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74bcbe8-7cbc-46dc-95d2-4bf12fb4ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in result['messages']:\n",
    "    m.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31736de-d270-4998-b825-154dff882a78",
   "metadata": {},
   "source": [
    "### Memory\n",
    "\n",
    "Extending our agent with memory. Same tools apply!\n",
    "\n",
    "if we add another prompt like: \"Multiply that by 2\", the model does not know what \"that\" is. State is transient to single graph execution.\n",
    "\n",
    "We have to address this via persistence.\n",
    "\n",
    "LangGraph can use a checkpointer to automatically save the graph state after each step.\n",
    "\n",
    "This built-in persistence layer gives us memory, allowing LangGraph to pick up from the last state update.\n",
    "\n",
    "One of the easiest checkpointers to use is the MemorySaver, an in-memory key-value store for Graph state.\n",
    "\n",
    "All we need to do is simply compile the graph with a checkpointer, and our graph has memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f53ef94e-6405-44cc-9016-50a617226355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62f5c9f4-0272-4ace-8de7-901ef88dd546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "react_graph_mem = builder.compile(checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph_mem.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ae208-3ada-4a9b-b0bf-dbb610acbe94",
   "metadata": {},
   "source": [
    "When we use memory we need to specify a thread_id, which will store our collection of graph states (or checkpoints).\n",
    "\n",
    "We can access this thread later using this ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46bab077-afff-49b4-a77d-1f447e754b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the thread_id as part of a config\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b327207-d5e6-425d-9807-00fce5a099af",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Multiply 5 and 7\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f294efff-61fb-40a7-9fe8-b2dcda6a219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model on the messages\n",
    "result = react_graph_mem.invoke({\"messages\": messages}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d2fba4f-83bc-45bf-8809-4fa69619c03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 5 and 7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  calculator (call_DBf6J1k0bpTa3w51rNDPeSJc)\n",
      " Call ID: call_DBf6J1k0bpTa3w51rNDPeSJc\n",
      "  Args:\n",
      "    operands: {'a': 5, 'b': 7}\n",
      "    op: mult\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calculator\n",
      "\n",
      "35.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 5 and 7 is 35.\n"
     ]
    }
   ],
   "source": [
    "for r in result[\"messages\"]:\n",
    "    r.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "123cfb8d-2f14-4a2b-8c90-80d87df126f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 5 and 7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  calculator (call_DBf6J1k0bpTa3w51rNDPeSJc)\n",
      " Call ID: call_DBf6J1k0bpTa3w51rNDPeSJc\n",
      "  Args:\n",
      "    operands: {'a': 5, 'b': 7}\n",
      "    op: mult\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calculator\n",
      "\n",
      "35.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 5 and 7 is 35.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add that to 211 and divide the result by 8\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  calculator (call_uHuAs15DMjLAp3Jfjoas2FCx)\n",
      " Call ID: call_uHuAs15DMjLAp3Jfjoas2FCx\n",
      "  Args:\n",
      "    operands: {'a': 35, 'b': 211}\n",
      "    op: add\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calculator\n",
      "\n",
      "246.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  calculator (call_ocz1X4106vLNX6Ij4Ct2js6T)\n",
      " Call ID: call_ocz1X4106vLNX6Ij4Ct2js6T\n",
      "  Args:\n",
      "    operands: {'a': 246, 'b': 8}\n",
      "    op: div\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calculator\n",
      "\n",
      "30.75\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "After adding 35 to 211, the result is 246. Dividing 246 by 8 gives 30.75.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Add that to 211 and divide the result by 8\")]\n",
    "result = react_graph_mem.invoke({\"messages\": messages}, config=config)\n",
    "for r in result[\"messages\"]:\n",
    "    r.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba387e89-e6fa-48c3-9aa0-941d09064e3b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 5 and 7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  calculator (call_DBf6J1k0bpTa3w51rNDPeSJc)\n",
      " Call ID: call_DBf6J1k0bpTa3w51rNDPeSJc\n",
      "  Args:\n",
      "    operands: {'a': 5, 'b': 7}\n",
      "    op: mult\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calculator\n",
      "\n",
      "35.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 5 and 7 is 35.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add that to 211 and divide the result by 8\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  calculator (call_uHuAs15DMjLAp3Jfjoas2FCx)\n",
      " Call ID: call_uHuAs15DMjLAp3Jfjoas2FCx\n",
      "  Args:\n",
      "    operands: {'a': 35, 'b': 211}\n",
      "    op: add\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calculator\n",
      "\n",
      "246.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  calculator (call_ocz1X4106vLNX6Ij4Ct2js6T)\n",
      " Call ID: call_ocz1X4106vLNX6Ij4Ct2js6T\n",
      "  Args:\n",
      "    operands: {'a': 246, 'b': 8}\n",
      "    op: div\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calculator\n",
      "\n",
      "30.75\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "After adding 35 to 211, the result is 246. Dividing 246 by 8 gives 30.75.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "If the result is in cm, how many inches would that be?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To convert centimeters to inches, you divide the number of centimeters by 2.54 (since 1 inch is equal to 2.54 cm). \n",
      "\n",
      "So, to convert 30.75 cm to inches:\n",
      "\n",
      "\\[ \\text{inches} = \\frac{30.75}{2.54} \\approx 12.11 \\]\n",
      "\n",
      "Therefore, 30.75 cm is approximately 12.11 inches.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"If the result is in cm, how many inches would that be?\")]\n",
    "result = react_graph_mem.invoke({\"messages\": messages}, config=config)\n",
    "for r in result[\"messages\"]:\n",
    "    r.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7a4f86-dd7a-44a6-9963-83cc63fd674e",
   "metadata": {},
   "source": [
    "### Overwriting State\n",
    "\n",
    "Let's use a TypedDict for our state schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98872790-9b83-49f1-ba37-3909903bdbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from dataclasses import dataclass\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c8e1801-70cc-4e5c-926b-6d6ec7e0d191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class State(TypedDict):\n",
    "    foo: int\n",
    "def node_1(state):\n",
    "    print(\"node_1\")\n",
    "    return({\"foo\": state[\"foo\"] + 1})\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d14e39f-624f-4380-8d62-234de9d1510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'foo': 34}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"foo\": 33})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87e8bb0-cef5-4846-be5b-a44985aaeef6",
   "metadata": {},
   "source": [
    "### Using Reducers\n",
    "\n",
    "We should use reducers mainly when we perform state updates in parallel. This will result in an error since each node will update the same key in the state. Hence we need a way to append to existing list of values rather than overwrite existing value.\n",
    "\n",
    "This is where reducers come in. We will be using the built-in operator 'add' in python as a function in our reducer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c57bf5c-1dbd-4893-b696-ad0b9c9e57eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from operator import add\n",
    "from typing import Annotated\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: Annotated[list[int], add]\n",
    "\n",
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"foo\": [state['foo'][-1] + 2]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "824447b8-0228-4c6c-a4c4-b0e4435577f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'foo': [9, 11]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"foo\": [9]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d8308d2-2c6b-4f1e-b105-f66f7028a2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [1,2,3,4]\n",
    "\n",
    "arred = add(arr, [arr[-1] + 1])\n",
    "arred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d26fc6-5dca-4789-b38f-0ef464851d43",
   "metadata": {},
   "source": [
    "So it seems that when we pass State to graph it adds current state with current value. It passess to operator.add(state['foo'], whatever the return is from the node)\n",
    "\n",
    "i.e. `add(state['foo'], [state['foo'][-1] + 2])` as in the example above\n",
    "\n",
    "lets try the branching with parallel state updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24a0f121-7b6c-4395-b338-149a807aad6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAFNAOYDASIAAhEBAxEB/8QAHQABAAMBAQEBAQEAAAAAAAAAAAUGBwQIAwECCf/EAFcQAAEEAQIDAgcLCAUJBAsAAAEAAgMEBQYRBxIhEzEIFBciUVaUFRYjMkFhdZWz0dM2N0JUVXF00jVSgZOyJDNDcpGhsbTBJSeC1AkYRUZXY2SDpPDx/8QAGwEBAQADAQEBAAAAAAAAAAAAAAECAwUEBgf/xAA4EQEAAQICBwUECgIDAAAAAAAAAQIRA1EEEhQhMVKRQWFxodEFgZLBExUjMjNCQ2Kx4SLwU7Lx/9oADAMBAAIRAxEAPwD/AFTREQEREBERAREQEX8ve2Npc4hrWjcknYAKsMFzWvwzbNnGYLf4MV3dlPdH9YvHnRxn5OXlee/cDodlFGtvmbRC2T9zKUseQLVuCtuNx20rWf8AErl99WF/bFD2ln3rlpaC03j9zBgse2Q9XSurtfI8+lzyC5x+ckrq96uF/Y9D2Zn3LZ9jHbPl/a7j31YX9sUPaWfenvqwv7Yoe0s+9Perhf2PQ9mZ9ye9XC/seh7Mz7k+x7/I3Hvqwv7Yoe0s+9PfVhf2xQ9pZ96e9XC/seh7Mz7k96uF/Y9D2Zn3J9j3+RuPfVhf2xQ9pZ96DVOFJ2GXob/xLPvT3q4X9j0PZmfcnvVwv7HoezM+5Pse/wAjckILMVqMSQysmjP6Ubg4f7Qvoq5Pw/whf21Ko3DXANm28WBXkHXfryjZw3+RwI6ncL7YvKW6eRbicuWvsPa59S7G3lZaYO9pH6MrR1Le5w85v6TWSaKZi+HN+7tS2SdREWhBERAREQEREBERAREQEREBERAREQVnXbvGqeNw+4DcxdZTkG56whj5ZW9P60cT2/8AiVla0MaGtAa0DYAdwVa1k3sMhpjIEHsqmUa2Qgb7CWGWBv7vPlj6qzL0V/h0RHDf1v6WWeECIi86KPqDjXozS+sq2lMjmTHn5+xAqQ1J5+z7V/JF2r42OZFzu6N5y3f5FX+H/hB4rXfE7WOjGUb9S3gr3icMzqFrs7AbCySR7pDCI4tnOc1rXO3eGhzdw4KicZfdjTvFpuY4e4PVkWt7bsfXtyQY4zYHMVRLs5tmU7tidFG+TaTdjh3DmB6S2mbWe0Rxl4r45mm8tNZ1LahyeEyraL5Ma8sx0cfLNO3zYiJYS0hxBPM3bv3QXvRPH3QfETUBwmBz3jWU7J08cE1Set28bSA58TpY2iVo3G5YXDqqpqPwt9DVuHOo9U6cs2tTNxONlvtjr424yGRzCGCJ03YFrHc72BwPVrSXkBoJGQ8O8bqXJcUuDmocxiuId7MUnXItT5DUFeZtOpanpPbyQQ9GMh7UEdpEzkDez5n7kK66E4c5214CV3R8eHsUdRW9P5OvHjbcRrymeR05a1zXgFpcXDv2+Nug3Hh5ruhxG0tUzeOZajhlAD2XKU9RzX8oLgGTMY4t69HAbH5CVZVSeD+rffdoehK/CZrAz1Ioqs1TOY+SnKHtjZzFrXgczdyRzDoSDsrsgKva9qST6Xu2K4b49Qab1RztxtNGC5vUfIdi0/M4jY77KwqF1pfGM0lmLPK57mVJORjRu57y0hrQPlJJAH71uwbxiU2zhY4pOjcjyFKvahJMU8bZWE9/K4bj/ivuuHB484nCY+iSHGtXjhJHceVoH/Rdy11WiqbcEERFiCIiAiIgIiICIiAiIgIiICIiDjy+Kr5zF2sfbaX17Mbonhp2IBHeD8hHeCO4gFRWKzz6FmLEZuWOHIk8tewfNjvD5Czf9PYedH3g7kbt2KsK5shjauWqSVbtaK3Wk+NFMwOaf7CttNcW1auH8f75r4qTlPB+4ZZvJW8jkNAabu37crp7Fmxi4XySyOJLnucW7kkkkk+lc7/Bv4UyuBfw40u8gBu7sTAegGwHxfkAAU+NAwV+lHMZrHx/JFFedIxv7hLz7D5h0Ce8mx61Z7++h/CWephzwr8p/stGaW07pvFaRw1fE4TG1cRi63MIadKFsUUfM4uPK1oAG7nE/vJUkqv7ybHrVnv76H8JPeTY9as9/fQ/hJ9Hh8/lJaM1oRZXpTH5XM6w1tjLOqcwK2Hu14Kpjlh5i19SGV3P8H380jtu7pt+9Wz3k2PWrPf30P4SfR4fP5SWjN+6w4X6P4hTVpdT6YxOoJarXNgfkqcc5iDtiQ0uB232Hd6FXf8A1auE2+/k20t9UQfyqw+8mx61Z7++h/CT3k2PWnPH/wC9D+En0eHz+UlozNK8PNHcMob8+ndPYfTEVhrXW5KFWOs2QM5uUvLQNw3mdtv3blGH3636s7WEYCnKJ43SNLTdnaQWPaD/AKJh84H9Nwa4ea0F/wBINA4sSxy3nW8zLGQWe6dl87GkHcERk8gIPXfl36Dr0Csia1GH9ybznl4G6OAiIvOgiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIM94fkHiTxR2JJGTpb/V9f5/uWhLPeH+/lJ4od39J0u4Df+j6/ft/1WhICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgzzh8NuJXFLzgf+06XQDu/7Ord60NZ5w928pXFLY9fdOlv02/9nVv9q0NAREQEREBERAREQEREBERAREQEREBERAREQEREBEVVy2q7zshPRwdGvckrHks2bk7ooo3kAhjeVji92xBPcBuOpO4GzDw6sSbUra61IqR7u6w/UMH7XN+Gnu7rD9Qwftc34a9Gy15x1gsu6i9VZW3gtMZjJUMc7L3qdOaxXx7H8jrUjGFzYg7Y8pcQG77HbfuKrnu7rD9Qwftc34ae7usP1DB+1zfhpstecdYLPJXg4+HHc4qcdMhgcZw6lin1PeisTyvyw2oQw1o4pHu+AHPsIiQCRuSG7jvXuxeaOE/g/TcH+JmttaYfH4Y3tSyBwgdYlaykwnnkjj2j+K+Tzvm2aPk67B7u6w/UMH7XN+Gmy15x1gsu6Kke7usP1DB+1zfhp7u6w/UMH7XN+Gmy15x1gsu6KkjO6vB64/CEegXJhv8A29l0U9p7UIzQsQzQGnkKrg2xWLucN335XNdsOZjgDsdh3EEAgga68CuiNabW7puWTCIi86CIiAiIgIiICIiAiIgIiICIiAiIgLPtKHd+eJ7zl7XX/wAey0FZ9pP42d+l7f2hXv0f7lfuZRwlPIiLYxEREBFD6U1didb4cZTC2/HaBnmrdr2b4/hIpXRSN2eAej2OG+2x23G42KmFARfxLKyCJ8sr2xxsaXOe87BoHeSfkCjdMaoxWtMHXzGEvR5LF2C8Q2od+STle5ji0nvHM07EdD3jcEFBKqN04f8AvGzQ9OKpb/P8Na//AH+0qSUZp384+a+iaX21pZ/p4nh84WO1dkRFykEREBERAREQEREBERAREQEREBERAWfaT+Nnfpe39oVoKz7Sfxs79L2/tCvfo/3K/cyjhKeXl/W1fM57UXhAXG6v1HjDpavXt4etj8nJBBWm9y45i4sb0e0vaCWO3Z1ceXdxK9QKty8OdOzyarkfj+Z+qY2xZg9vJ/lTRD2AHxvM+DHL5nL6e/qspi7Fg2m7mZ46aj1Q7MawzWlq2CwWJsU48HedSYJbVPxiW1Ly/wCcAeS0NduwCN3Q7lcHDnWOo/CDy+h8PndQZbTlb3l19Q2mYO06jYyVqSd8HOZGecImiPm5GkAmUb9AAto1H4PfD/Vjce3J6fE3iNFmNiMVyxCX1WfFglLJGmZg/qycw6n0ldureCui9btw4yuDjLsPH2WPkpTy05K0ewHZsfC5jgzYAcm/L07lhqyPKWgspquxgdA8O8DasurXLGpL1iX3cfibF98GTkYGeNRQyPBAe6RzWNaXdDuANj6g4IYPWundN5ClrS3Hblbfe7HH3QdfmjqFrOWOWd0URkc1/aecW78paCSRuvybweuH0+j8dpc6dYzDY2zLboxx2Z2S1ZZHue90UzXiVm7nu6NcBsdu4ALoGg8zo3D0MPw8tYPAYqDtHyw5ehZyD3ve7mLg8Wo3bklxJdzEk96sRMCy6t0hiddYOXD5yoL+Lmex81V7nBkvK4ODXgEczdwN2noR0IIJCzLwPGhng26Ka0BrRDOAAOgHjMq0LSVTV1V9r30ZXC5Jjg3xcYjGTUyw9ebn7SxLzb9NtuXbY9+/Tq0fo/EaB03SwGBqeIYmmHNgr9q+TkDnFx855Lj1cT1PyrK2+4mVGad/OPmvoml9taUmozTv5x819E0vtrS2fp4nh84WO1dkRFykEREBERAREQEREBERAREQEREBERAWfaT+Nnfpe39oVoKz3U75uHzctmTHFYwUj3XLD5LUcDqriAHHeRzWFjiN/jAgk9+/T26NVFqqJm12UZJ9FWcRqrMZvGVr9fRWcjgsMEjG2zWrygHu5o5JmvYfmcAR6F1+62e9TMr7VS/HXq1P3R8UepZNooT3Wz3qZlfaqX46e62e9TMr7VS/HTU/dHxR6lk2ihPdbPepmV9qpfjp7rZ71MyvtVL8dNT90fFHqWTaKE91s96mZX2ql+OnutnvUzK+1Uvx01P3R8UepZNqM07+cfNfRNL7a0oLMa/tYC9jamS0xk6L8jL2FaaeaqIHS9OWN0olLWOcSA1riC49GgkEK46Wwdupau5TI8jL91scfi8Ty5kELC4sbv8ApO3e8uIAHUAb8vMca5jDw6omY3xbdMT2xkcFiREXKYiIiAiIgIiICIiAiIgIiICIiAiKqal1daiyQwGnqrcjqGSPne+UHxXHRkdJrLgQdifixNPPIe7lYHyMDt1VrCppVlWJ8U9/JXXmOljabQ+ey4bb8oJAa1u4LnuIY0EcxG43h8Pou9mb9bN6ykguZGCQTU8TWcX0ca8b7OZzNaZpgDt2zwNtvMbHu7mk9J6IqaYks3pJX5PP3msF7MWQO3scu/KwbdGRNJdyxN2a3mcduZznOsaAiIgIiICIiAiIg5cpi6Wcx1nH5GnBkKFmN0U9W1E2SKVhGxa5rgQ4Ed4IVGMWY4VsBgbd1Lo9pJdAA+zkcYzp/m9t32oR18zrM39HtQQxmhog48Rl6OfxlbI423DfoWWCSGzXeHxyNPyhw6Fdio+X0ff05lLOf0eWMsWJDLkcFK4Mq5En40jT/obH/wAwea/ukB8ySOwaX1TR1djTcpGRjo5DBZq2GdnPVmABdFKw9WuG4PoILXAlrgSEwiIgIiICIiAiIgIiICIiAiIgqmsNR3Y71TTmBdGdQX2Ok7aRofHj646OsyN3HMObZjGd73kdzWyObK6a0zS0rjnVagfI+WR1izamIM1qZ3x5ZHADdx2HcAAAGtAa0AVbhEfduhmdWTczrOdyM7mF4ILKkMj4KzACTsORnabD9KV5+XdX9AREQEREBERAREQEREBERAVR1Xpi4zIDUmnOSHUMMbWTQO2bFlIGkkV5j8hHM4xyd8bnHvY6Rj7ciCK0xqWlq7CQZSiX9jIXxvjlHLJDKx5ZLFIOvK9j2uY4fI5pClVQMaHaa4yZDHRBwoaixpyzWAHlZarvjgndv3Dnjmq9Bt1jcepcVf0BERAREQEREBEULmNbae0/aFbJ5zHY+yRzdjZtMY/b08pO+yzpoqrm1MXlbXTSKreVLR3rTiPbY/vTypaO9acR7bH9627Pjck9JXVnJaVFaj1Zg9HUY7ufzOPwdOSQQssZK0yvG6QgkMDnkAu2a47d+wPoUX5UtHetOI9tj+9ZT4UGJ0Rx54MZ3S/vnw3ulyeN42V12P4O3GCY/wBLoHbuYT6HlNnxuSekmrOSxeDVrrTWe4aaexOM1Disjla9N0s1GrdjlnjYJCC5zGuLgN3N6n+sPStdXhz/ANHfoLTfB7QeS1LqXLY3G6rzsnZeLWrLGTVasbjysIJ3aXu3cR6AxeuvKlo71pxHtsf3ps+NyT0k1ZyWlFVvKlo71pxHtsf3p5UtHetOI9tj+9NnxuSekmrOS0oq7T4jaVyFiOCtqTFTTSODGRsuRlznHuAG/U/MrEtVdFeHuriY8UtMcRERYIIiICIvhev1sXUltXLEVSrEOaSed4Yxg9JcegViJmbQPuiq7uKOj2kg6oxAI6EeOx/evzypaO9acR7bH9637Pjck9JZas5LSiq3lS0d604j22P708qWjvWnEe2x/emz43JPSTVnJn2q+K+iKHHXSos6xwFd1HFZmpaEuUgb4vN21D4OTd45X7xv80jfzHd2xWx0rtfJ0q9ynYit1LEbZYZ4Hh8cjHDdrmuHQggggjoQV/mlxp8GbTmsPDFx9+jmscdB6jnOXy9yO2zkrSB3NYiLtzs6V3VvzyH+qV/oPW4k6IpVoq9fUmFggiYI44o7cbWsaBsAAD0AHyJs+NyT0k1ZyW1FVvKlo71pxHtsf3p5UtHetOI9tj+9NnxuSekmrOS0oqt5UtHetOI9tj+9TuLzNDOVjYx12vfgDiwy1pWyNDh3tJB7x6FhVhYlEXqpmPclph2IiLUjizVx2Pw960wAvggklaD6WtJH/BVHSVSOtgKUgHNPZiZPPM7q+aRzQXPcT1JJP9nd3BWfVX5MZj+Dm/wFV7TX5OYr+Ei/wBdDA3YU+K9iSREWaCIiAiIgIiIPnZrQ3a8kFiJk8EjS18UrQ5rge8EHoQnDu3LY09JFLI+XxS5ZqMfI4ucY45ntYCSSSQ0Abk7nbc96+i5eGn9DZH6WvfbvUxN+DPjHzXsW1ERc1BERAVIzxbk9fQ07A7WvRoMtxROG7RK+R7OfbuJDWbAkdOZ23eVd1Rr/AOc239D1/tp17NF+9VPcsJZERb0EREBERAREQFDWOXF6007ZrgRTZGeShZLBt20YrzTN5vSWui80ncjmeBsHO3mVCZn8qdFfSsv/ACFtbKPzR3T/ABKwvyIi5CIvVX5MZj+Dm/wFV7TX5OYr+Ei/wBWHVX5MZj+Dm/wFV7TX5OYr+Ei/wBdHB/Bnx+S9iSWFaJ8JTKamoaFzWS0QcLprV1puPqXhlWWJorLmSFofCIx8G4xOaH82/duxu+y3VYRgeBGfxfCjhLpiW5jXX9JZqpkr0jJZDFJHEZuYREs3LvhG7BwaOh6hSb9iPq7wl7Pir9St0fM7hszK+5TtS+6DO138Y8WNgVeTcwCbzebn5tgTybKq8f8AjpqXIcOOJw0Vp+37kYCOfHWdVxZYU5YbbNu18XjDeZ4jJAc/mZ1Dg3m2UhN4P2s36Uk4atyeDbw1kypum58N7qCobfjRq9ny9nvznk7Xn+L+huufWfAbiK/SvEfRmmb2mZtLastW78M2WksRW6Utl3PLFtGxzXM5+YtduCObqHbbLCdawmtf+FRjtFaqvacpQYW9dxNeGTIuzOpa2JPPJGJGxwNl3Mz+UtJ+K0cwHNvuBrmg9Z4/iJozC6mxXae5+Vqx24WzN5Xta4b8rh12I7jsT1Cy+/wr1vpPX+o8/oqTTN+nqRleS7T1GJmmpaiiEXawuia7na5rW8zHcvVvRw3V0yPFjB6Tte5OUhzDshWYwTnGaayNisXFgcezfFA9hHX5HHbuPUFZxM33ip+EVp9lPS2e1nb1xqbTsGIxT/FKWGv+Kw+Nbu5HOa0bzPe90bAx5Le4AbkrReHcubn0BpqTUrQ3UT8bWdkmhobtZMTe16DoPP5ugWP8T8HrfjNntHZnR0OEs6Qwtg334zVQv42W1eZuInSROrc3ZxdHt32DnHc9GhbXpV+ckwFR2pYcfXzZDvGY8VLJLWaeY8vI6RrXHzeXfdo67pHESy5eGn9DZH6WvfbvXUuXhp/Q2R+lr3271nifg1eMfNexbURFzEEREBUa/wDnNt/Q9f7adXlUa/8AnNt/Q9f7adezReNXh84WO1LLOdf8UstpjXmA0lg9MM1Bk8zRt3YpJsiKkMPYOhBEhLHnlIl72hx3AHLsS5ujKiZvQl/JcZtK6uimrNxuKxV+jPE9zhM58767mFo5di0CF2+5B6jYHrtum/Yin1/CQkymB06zFaVmuazzORu4pmnpLrImV5qbnNtOkscpAjZyghwaS7nYA3c9EnhJ+LYW1WsaVtN15Dm2aebpaK2x5ltviEzHNsbBvYmE9oZC0bAHdu/Qw9XgJqzT1mnqHDXsM/U+L1Nm8tVr3Hy+KWKWQkcXQyPaznjkA7N27WuAczbzgd18LHg9avnfNrP3YwzOJrtRR59reSU4wMZW8UbTLtu0LexJ3k5Qeb9Fa/8AIcGH465XQ+qeMOc17TmxMeKZhYq2DZlm2a7JZmStaIZHcjGCRxYXOIZtsS7o3dXThJ4R9LiVrOfS1iviK+WFF2Rhfgs/Bl674mvax7XSRhpjkBezzS3YgkgnYqsZLwfNY65fr/I6jyODxGbzU2Hu4qTEOmsxVLNAvc3tBIxnO0ktB27wXdBsN9B09mNV6PoZDLcQKOBq1Y2xRQR6Pp3b8xeSQ9zmiLn5T5mzWsPLsSXH5EXGi3axuUrFds0tYyxujE0BAkj3G3M0kEAjvG4KwTg9ds4zj3qzSuM1Pns3p3GYmJ1yDVFt81lmQM5bz1zKBI6Exg7uaOz5i3lPyDQq/FzGanMmL0+3LwZuxFI2nJltM5OCq2UMJaZXvgY0N3HXdw37gdyFX9HcO9bZHixW11rizgKtjH4iXE1KGnTNI2QSyMe+SWSVrT/oxswAgbk7+nKd9rDX1CZn8qdFfSsv/IW1NqEzP5U6K+lZf+QtrfR+bwq/6ysL8iIuQiL1V+TGY/g5v8BVe01+TmK/hIv8AVpzNN2RxF6owgPngkiBPyFzSP8AqqhpK5HYwNOEHks1oWQWIHdHwyNaA5jgeoIP+0bEdCF0MDfhTHevYmERFmgiIgIiICIiAuXhp/Q2R+lr32719bduChXksWZo68EbS58srw1rQO8knoAv64eU5a2nnyyxPhNu5ZtsjkaWuEckz3M3BAIJaQdiNxvse5TE3YM+MfNexZkRFzUEREBUa/8AnNt/Q9f7adXlUjP8uL15Fdsnsq12gypHM47M7Vkj38hPcCQ8kbnrynbuXs0X71UZwsJRERb0EREBERAREQFCZn8qdFfSsv8AyFtTahZizK600/WruE0uNnkv2eQ7iFhrzQt5vQXOl6A7E8riNw07bKPzT3T/ABKwvqIi5CChcxorT+obAsZTB43IzgcoltVI5HgejdwJ2U0iyprqom9M2k4Kt5K9GeqeE+r4v5U8lejPVPCfV8X8qtKLdtGNzz1lbzmq3kr0Z6p4T6vi/lTyV6M9U8J9Xxfyq0om0Y3PPWS85sd4H8O9L5XhRpu3e09ir1uWuTJYsU4pHvPO4blxB37vSrz5K9GeqeE+r4v5VD8B94uGtSo528lC9kaD+/oYbs8W3X/U+7otBTaMbnnrJec1W8lejPVPCfV8X8qeSvRnqnhPq+L+VWlE2jG556yXnNXqPDvSuMsx2Kmm8TWnjcHMkipRtc1w7iCG9D86sKItVddeJN65v4l7iIiwQREQF8LtKvkqsla3XitVpByvhmYHscPQQehX3RWJmJvAq7uFujXOLjpTCkk7k+58X8q/PJXoz1Twn1fF/KrSi37Rjc89ZW85qt5K9GeqeE+r4v5U8lejPVPCfV8X8qtKJtGNzz1kvObHs7w60tFxm0fTj09io6c2Gy0s1RtOIRyuZLQDHubt1Led4B2O3O7qN+t48lejPVPCfV8X8qiL73W+PmEY13mUNM33SN3PfPaphh9HdWk+fv2+VaAm0Y3PPWS85qt5K9GeqeE+r4v5U8lejPVPCfV8X8qtKJtGNzz1kvOareSvRnqnhPq+L+VT2MxFHCVvF8fSr0a/MX9lWibG3mPedgB1PpXWiwqxcSuLVVTPvLzIiItSCIiAiIgIiIM90IDpvX+tNOSM7OG1YZn6B67PinaGTtHyFzbEcjjt3CeP07nQlWNcaTm1BFQv4yeOlqLEymxjrUgPISWlr4ZdupikaeVw+Qhrx5zGEdGktYV9VQWIzC/H5ak4R38XYI7aq8jpvt0c12xLXjzXDqD37BPoiICIiAiIgIiICIiAiIgIio+qM3b1Vds6U05Ylgn25Mrm6583GRnvjjd3OtOHxWj/ADQIlftvEyYObh806g1zrXVRZtWkmhwdGQg/CQVO07R43/8AqZ7Ldx3iNp6jbbQVxYbDUtO4ili8bWjp4+lCyvXrxDZscbQA1o/cAF2oCIiAiIgIiICIiAiIgIiICrWq9C0tTWauRjllxWfpAinmKRDZ4mk7mN2/SSJxA5o3gtOwOwc1rhZUQUCtxDu6Snhx+voa+NdI8RQahqNLcXacSA0O5nOdVkcTsGSuLSSAyWRxIF/Xys1obtaWvYiZPXlYY5IpWhzXtI2LSD0II6bFUIaNzegH9toyVt7D828ml8jOWxRN+U05iHOhPoifvEdg1vYglyDQkXlnhr4eOmuI/hE2+HsFaOth5q8cWLyr5hzT3g0unhdsSzbr2bCxzgXREtc8St5fUyAiIgIiICIuHN5qjpvD3srk7LKeOpQvsWLEnxY42guc4/uAKDuUdqDUWM0ripsnl70GOoQ7c89h4a3cnYNHpcSQA0dSSAASV5p4AeG4fCGnzmE09pVzdUVLEslZlm2yKp4gX7R2ZXEmQFu7GPZGx5LnMI2a89nu2A4dtgysWd1HfOpNRsHwdmSMx1ae46irXLnCEHr5xL5CDs6RwAACNM2peJTuWEW9HaUeOs7w6HL3mkdzWObvTYf6zvhjudmwuAcbpgsDj9M4mvjMVTio0K4Ijghbs0bkkn5ySSST1JJJJJK70QEREBERAREQEREBERAREQEREBERAURq3I47F6cvy5axLWoOiMUj68skc3nDl2jdGQ8PO+zSwhwO2xBUuvPfEbUsmqNYW2B5OPxUjqleMHoZR0mkI9PNuwegNO23MV0tA0OdMxdSd0RvlXnvIeCtw8OpquW07h72l205hNXLMjJJPzNO7H7h20ZBG+wLv9Zbydd6yP8A712x/q06m32KiEX3NGhaNhxqxhx74if5ux1pS/v61l62XPZKn4Ke/rWXrZc9kqfgqIRbNm0f/ip+GPQ1pS/v61l62XPZKn4Ke/rWXrZc9kqfgqIULqjVlPSTMW65HPIMjkIMbF2DQeWSU7NLtyNmjbqRufmKlWj6NTF5w6fhj0NaVx9/WsvWy57JU/BVZ4kV8xxV0dd0xqDUl61iLnL28LI4YTIAQ4AmNjTtuAdt+u3Vd6K7Lo8/p0/DHoa0qr4PHBPhjwX1rj83LhZ4M3X5462dN+V0MZkY6N3aRF2zAWuI5jzNHNueXYEe0F5Zc0OBBAIPQg/KtX4I6lltUruAsvL340MfVc49TXfuGs+fkc1w+ZpYF817U9m0YVE4+DFojjHzheLT0RF8qCIiAiIgIiICIiAiIgIiICIiAiIgLytHzie8JN+1bdstk3/rCZ4d/vBXqlYJxR0tJprVNi+yPbF5WQStkA6R2D0ew+jm2DwflLnj5Bv9J7ExaaMWrDq41Ru93YvYqiKM1BiruXqRw0c1bwcrZA82KcUMjnDYjlIlje3bqD0G/Qde9QA0TqAA/wDeFnDuPlp4/p/+MvsKqpibRTM9PVrcfHnKZPDcItS3MPJJBdjgb8NCCXxRmRoleNtju2MvO4II27wswx+hK+Gx2ZyWI1Lpt1V2nrrp8dgIZWeOxuiPJLJz2Zdy122z9t/OIJ6raMNpbLY682a7q7KZmvyua6nbrU2Rv3G3UxwMd0/euvG6J07ho7bMfgMXRZcaWWW1qccYnae8PAaOYH0FeTEwJxq9eYt49nfunt7fBWK6ewVbSeQ4RZLCVuxymYxc7L0naOLrx8Q7Zvaknd20jQQT3dw2CrGIxumb2leGeo/GYrutL+pKDslamsk2nTGU9rG9m/QMI2DdtgANgvTzcHjWOx5bj6rTjgW0yIW/5MC3kIj6eYOXzfN26dO5R50Hpo5N2S972K90nSic3PEYu2MgO7X8/LvzA9Qd91qnQ54Ra39Rv8d3mJ1FTPeRqD/4h532PH/+WX6dEagJ/OFnB8wp4/8A8svdr1ck+Xqi5K38GuY8RpeXfkGKm5+vTczQ8v8Awf8A71S2f5LVb20xf2bPPmk2BOw6uOwAHp6ABbNwa0lPhcZby96J0F3KchZDICHRV2g9mHA9Q4lz3EdCOZoI3aVz/amNThaLVFXGrdH+9zOnNoqIi/PQREQEREBERAREQEREBERAREQEREBcuTxdTNUJqV6vHaqTN5ZIpBu1w/8A71B+QjddSKxMxN4GOZzgfkK8rn4HJwzwkkirlOZpb8wlYCSP3sJ9JKhDwn1kDt4ljD87b7tv98S35F2qPbGlURaZifGP/F9zAPJRrL9Rxvt7vw08lGsv1HG+3u/DW/otn11pOUdJ9TdkwDyUay/Ucb7e78NPJRrL9Rxvt7vw1v6J9daTlHSfU3ZMA8lGsv1HG+3u/DX9x8I9YykA18TB6XSXnkD+wRdf9y3xE+utJyjp/ZuyZxpDg1Vw9yG/mbYzFyFwkhhbF2daFw6hwYSS9wPUFx2B2IaCAVo6IuRj6Ri6TVr4tV5BERedBERAREQEREBERB//2Q==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"foo\": [state['foo'][-1] + 1]}\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"---Node 2---\")\n",
    "    return {\"foo\": [state['foo'][-1] + 1]}\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"---Node 3---\")\n",
    "    return {\"foo\": [state['foo'][-1] + 1]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_1\", \"node_3\")\n",
    "builder.add_edge(\"node_2\", END)\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c521635-db2f-46bc-bd7e-a1e1d6ce7e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "---Node 2---\n",
      "---Node 3---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'foo': [1, 2, 3, 3]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'foo': [1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c544363-58ba-44e4-b6d8-4282594cde70",
   "metadata": {},
   "source": [
    "This results in the initial state `[1]` then in node_1 it adds `[2]` and node_2 and node_3 add the same `[3]` simultaneously\n",
    "\n",
    "Below we will implement custom reducer `reduce_list` which takes two lists and handles `None` being supplied instead of a list as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e11bee3-10df-446e-99a6-54b0a2381cb0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Annotated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 21\u001b[0m\n\u001b[1;32m     15\u001b[0m         right \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m+\u001b[39m right\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129;43m@dataclass\u001b[39;49m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mDataClassState\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfoo\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAnnotated\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_list\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDefaultState\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[39], line 22\u001b[0m, in \u001b[0;36mDataClassState\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDataClassState\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     foo: \u001b[43mAnnotated\u001b[49m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], reduce_list]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Annotated' is not defined"
     ]
    }
   ],
   "source": [
    "def reduce_list(left: list | None, right: list | None):\n",
    "    \"\"\"Safely combine two lists, handling cases where either or both inputs might be None.\n",
    "\n",
    "    Args:\n",
    "        left (list | None): The first list to combine, or None.\n",
    "        right (list | None): The second list to combine, or None.\n",
    "\n",
    "    Returns:\n",
    "        list: A new list containing all elements from both input lists.\n",
    "               If an input is None, it's treated as an empty list.\n",
    "    \"\"\"\n",
    "    if not left:\n",
    "        left = []\n",
    "    if not right:\n",
    "        right = []\n",
    "    return left + right\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataClassState:\n",
    "    foo: Annotated[list[int], reduce_list]\n",
    "\n",
    "class DefaultState:\n",
    "    foo: Annotated[list[int], add]\n",
    "\n",
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"foo\": [2]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(DataClassState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "try:\n",
    "    print(graph.invoke({\"foo\" : None}))\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83499061-1791-442f-8aa0-03170a34dfd3",
   "metadata": {},
   "source": [
    "### Filtering and Trimming Messages\n",
    "\n",
    "Let's start by creating a simple chat with some initial messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bbd7127-d2a0-420a-a4bb-c6f59b270343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "from langgraph.graph import MessagesState, START, END, StateGraph\n",
    "from pprint import pprint\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "messages = [HumanMessage(\"Hey AI can you answer some animal questions?\"), AIMessage(\"Sure, go ahead and ask, I am here to assist\")]\n",
    "messages.append(HumanMessage(\"I am interested to know which of the creatures currently inhabiting Earth has the longest lifespan. \\\n",
    "Which creature lives the longest?\"))\n",
    "\n",
    "sys_message = SystemMessage(\"You are an everhelpful assistant trying to assist your human friend. You are polite, thoughtful \\\n",
    "and with great sense of humour.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08826f0a-c2d7-4a9c-bd40-a4e5558f4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.75)\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3417bbbd-d0bc-42c5-bebc-e76912638411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The Assistant Node\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke([sys_message] + state[\"messages\"])]}\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_edge(\"assistant\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "462df6e2-3873-41c0-9790-24c9ff7e6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = graph.invoke({\"messages\": messages}, config={\"configurable\": {\"thread_id\": 42}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9706773f-54f8-4ead-a634-7543b8f4c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hey AI can you answer some animal questions?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure, go ahead and ask, I am here to assist\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I am interested to know which of the creatures currently inhabiting Earth has the longest lifespan. Which creature lives the longest?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ah, the quest for immortality through the animal kingdom! The creature with the longest lifespan is the ocean quahog clam (*Arctica islandica*), some of which have been known to live over 500 years. One particular clam, nicknamed \"Ming,\" was found to be 507 years old! Talk about a slow pace of life.\n",
      "\n",
      "If you're wondering about vertebrates, the Greenland shark (*Somniosus microcephalus*) holds the record, with some individuals estimated to live up to 400 years. Clearly, the secret to a long life involves living in cold, deep waters and moving at a glacial pace. Maybe we should take notes?\n"
     ]
    }
   ],
   "source": [
    "for item in r[\"messages\"]:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "145e58b7-2bfe-44a9-be60-12f7ba840183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hey AI can you answer some animal questions?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure, go ahead and ask, I am here to assist\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I am interested to know which of the creatures currently inhabiting Earth has the longest lifespan. Which creature lives the longest?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ah, the quest for immortality through the animal kingdom! The creature with the longest lifespan is the ocean quahog clam (*Arctica islandica*), some of which have been known to live over 500 years. One particular clam, nicknamed \"Ming,\" was found to be 507 years old! Talk about a slow pace of life.\n",
      "\n",
      "If you're wondering about vertebrates, the Greenland shark (*Somniosus microcephalus*) holds the record, with some individuals estimated to live up to 400 years. Clearly, the secret to a long life involves living in cold, deep waters and moving at a glacial pace. Maybe we should take notes?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Isn't there some jellyfish that lives longer?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ah, you're thinking of the infamous *Turritopsis dohrnii*, often dubbed the \"immortal jellyfish.\" This little marvel of the sea has a fascinating trick up its tentacles: it can revert its cells to an earlier stage of development when it faces environmental stress or injury, essentially starting its life cycle over again. It's like being able to hit a biological \"reset\" button, which theoretically means it could live indefinitely under the right conditions. \n",
      "\n",
      "However, while this jellyfish can potentially keep resetting its life clock, it doesn't make them invincible—they still face threats from predators and disease. So, while not immortal in the traditional sense, *Turritopsis dohrnii* certainly has mastered the art of a comeback!\n"
     ]
    }
   ],
   "source": [
    "r = graph.invoke({\"messages\": [HumanMessage(\"Isn't there some jellyfish that lives longer?\")]}, config={\"configurable\": {\"thread_id\": 42}})\n",
    "for item in r[\"messages\"]:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d7db0379-df4a-401e-bb71-5fa76f802423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hey AI can you answer some animal questions?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure, go ahead and ask, I am here to assist\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I am interested to know which of the creatures currently inhabiting Earth has the longest lifespan. Which creature lives the longest?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ah, the quest for immortality through the animal kingdom! The creature with the longest lifespan is the ocean quahog clam (*Arctica islandica*), some of which have been known to live over 500 years. One particular clam, nicknamed \"Ming,\" was found to be 507 years old! Talk about a slow pace of life.\n",
      "\n",
      "If you're wondering about vertebrates, the Greenland shark (*Somniosus microcephalus*) holds the record, with some individuals estimated to live up to 400 years. Clearly, the secret to a long life involves living in cold, deep waters and moving at a glacial pace. Maybe we should take notes?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Isn't there some jellyfish that lives longer?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ah, you're thinking of the infamous *Turritopsis dohrnii*, often dubbed the \"immortal jellyfish.\" This little marvel of the sea has a fascinating trick up its tentacles: it can revert its cells to an earlier stage of development when it faces environmental stress or injury, essentially starting its life cycle over again. It's like being able to hit a biological \"reset\" button, which theoretically means it could live indefinitely under the right conditions. \n",
      "\n",
      "However, while this jellyfish can potentially keep resetting its life clock, it doesn't make them invincible—they still face threats from predators and disease. So, while not immortal in the traditional sense, *Turritopsis dohrnii* certainly has mastered the art of a comeback!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How big is it? Where does it live?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The *Turritopsis dohrnii* is quite the diminutive wonder—it measures only about 4.5 millimeters in diameter, which is about the size of your pinky nail! Despite its tiny size, it has managed to capture a lot of attention with its unique ability to cheat death.\n",
      "\n",
      "As for its habitat, the \"immortal jellyfish\" is originally from the Mediterranean Sea, but it has spread to various oceans around the world, likely hitching rides in ballast water of ships. It's found in temperate to tropical waters, although it's not the kind of critter you'd easily spot during a seaside stroll, given its small size and translucency. It's like the secret agent of the ocean, quietly doing its thing while evading notice!\n"
     ]
    }
   ],
   "source": [
    "r = graph.invoke({\"messages\": [HumanMessage(\"How big is it? Where does it live?\")]}, config={\"configurable\": {\"thread_id\": 42}})\n",
    "for item in r[\"messages\"]:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f20fd-9559-449a-8c28-26537520d0eb",
   "metadata": {},
   "source": [
    "Let's try and filter some messages out. For example the below will be deleting all but the last two messages using the `RemoveMessage` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1387161f-c20f-40e7-b00c-67d33395bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage, trim_messages\n",
    "\n",
    "def filter_messages(state: MessagesState):\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-4]] # this returns all but the last two messages\n",
    "    return {\"messages\": delete_messages}\n",
    "def assistant_with_trim(state: MessagesState):\n",
    "    trimmed = trim_messages(\n",
    "            state[\"messages\"],\n",
    "            max_tokens=250,\n",
    "            strategy=\"last\",\n",
    "            token_counter=ChatOpenAI(model=\"gpt-4o\"),\n",
    "            allow_partial=False\n",
    "        )\n",
    "    return {\"messages\": [llm.invoke([sys_message] + trimmed)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3f5d3-2f3d-4071-a215-f7e842d36752",
   "metadata": {},
   "source": [
    "Now we can add the above function as a node before the Assistant. So the Assistant would only see the last two messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1e099e0-14e0-4805-9c81-8e9b1acc43cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'assistant' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m builder \u001b[38;5;241m=\u001b[39m StateGraph(MessagesState)\n\u001b[0;32m----> 2\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43massistant\u001b[49m)\n\u001b[1;32m      3\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m\"\u001b[39m, filter_messages)\n\u001b[1;32m      4\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_edge(START, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'assistant' is not defined"
     ]
    }
   ],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"filter\", filter_messages)\n",
    "builder.add_edge(START, \"filter\")\n",
    "builder.add_edge(\"filter\", \"assistant\")\n",
    "builder.add_edge(\"assistant\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5f8de134-706c-4f70-8720-ff6701a651d3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hey AI can you answer some animal questions?', additional_kwargs={}, response_metadata={}, id='0a4f5501-9076-4c4b-8bca-d982ff5be893'),\n",
       " AIMessage(content='Sure, go ahead and ask, I am here to assist', additional_kwargs={}, response_metadata={}, id='ffe4c684-3b4d-47f5-bc59-f4b720a5c7b9'),\n",
       " HumanMessage(content='I am interested to know which of the creatures currently inhabiting Earth has the longest lifespan. Which creature lives the longest?', additional_kwargs={}, response_metadata={}, id='c74388a7-8d81-4376-80a2-0bf9e9f3307e'),\n",
       " AIMessage(content='Ah, the quest for immortality through the animal kingdom! The creature with the longest lifespan is the ocean quahog clam (*Arctica islandica*), some of which have been known to live over 500 years. One particular clam, nicknamed \"Ming,\" was found to be 507 years old! Talk about a slow pace of life.\\n\\nIf you\\'re wondering about vertebrates, the Greenland shark (*Somniosus microcephalus*) holds the record, with some individuals estimated to live up to 400 years. Clearly, the secret to a long life involves living in cold, deep waters and moving at a glacial pace. Maybe we should take notes?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 136, 'prompt_tokens': 90, 'total_tokens': 226, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a20a4ee344', 'finish_reason': 'stop', 'logprobs': None}, id='run-61dcc765-b95a-45ec-affd-0e1aa5eb9c85-0', usage_metadata={'input_tokens': 90, 'output_tokens': 136, 'total_tokens': 226, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       " HumanMessage(content=\"Isn't there some jellyfish that lives longer?\", additional_kwargs={}, response_metadata={}, id='7b0088d3-e244-482d-bc2f-4393c3fd49e8'),\n",
       " AIMessage(content='Ah, you\\'re thinking of the infamous *Turritopsis dohrnii*, often dubbed the \"immortal jellyfish.\" This little marvel of the sea has a fascinating trick up its tentacles: it can revert its cells to an earlier stage of development when it faces environmental stress or injury, essentially starting its life cycle over again. It\\'s like being able to hit a biological \"reset\" button, which theoretically means it could live indefinitely under the right conditions. \\n\\nHowever, while this jellyfish can potentially keep resetting its life clock, it doesn\\'t make them invincible—they still face threats from predators and disease. So, while not immortal in the traditional sense, *Turritopsis dohrnii* certainly has mastered the art of a comeback!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 150, 'prompt_tokens': 244, 'total_tokens': 394, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e5e4913e83', 'finish_reason': 'stop', 'logprobs': None}, id='run-d2b9fa26-3e32-4397-a533-2e3d2e4d8cd9-0', usage_metadata={'input_tokens': 244, 'output_tokens': 150, 'total_tokens': 394, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       " HumanMessage(content='How big is it? Where does it live?', additional_kwargs={}, response_metadata={}, id='399799d4-561c-43b2-9ae8-c8f29277f857'),\n",
       " AIMessage(content='The *Turritopsis dohrnii* is quite the diminutive wonder—it measures only about 4.5 millimeters in diameter, which is about the size of your pinky nail! Despite its tiny size, it has managed to capture a lot of attention with its unique ability to cheat death.\\n\\nAs for its habitat, the \"immortal jellyfish\" is originally from the Mediterranean Sea, but it has spread to various oceans around the world, likely hitching rides in ballast water of ships. It\\'s found in temperate to tropical waters, although it\\'s not the kind of critter you\\'d easily spot during a seaside stroll, given its small size and translucency. It\\'s like the secret agent of the ocean, quietly doing its thing while evading notice!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 153, 'prompt_tokens': 412, 'total_tokens': 565, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e5e4913e83', 'finish_reason': 'stop', 'logprobs': None}, id='run-3f42cc7e-89fc-4334-83a2-f0826b4f7760-0', usage_metadata={'input_tokens': 412, 'output_tokens': 153, 'total_tokens': 565, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       " HumanMessage(content=\"Well if this jellyfish does not really die off, wouldn't we be swamped with the little creatures, sooner or later?\", additional_kwargs={}, response_metadata={}, id='4e32ca8b-2cca-4bcc-9bf3-858e6b29448b'),\n",
       " HumanMessage(content=\"Well if this jellyfish does not really die off, wouldn't we be swamped with the little creatures, sooner or later?\", additional_kwargs={}, response_metadata={}, id='1be25f0a-871a-4cad-bb56-733e64171959'),\n",
       " HumanMessage(content=\"Well if this jellyfish does not really die off, wouldn't we be swamped with the little creatures, sooner or later?\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_so_far.append(HumanMessage(\"Well if this jellyfish does not really die off, wouldn't we be swamped with the little creatures, sooner or later?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7e48605-1d3c-4af2-b086-8075d38d22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_so_far = [HumanMessage(content='Hey AI can you answer some animal questions?', additional_kwargs={}, response_metadata={}, id='0a4f5501-9076-4c4b-8bca-d982ff5be893'),\n",
    " AIMessage(content='Sure, go ahead and ask, I am here to assist', additional_kwargs={}, response_metadata={}, id='ffe4c684-3b4d-47f5-bc59-f4b720a5c7b9'),\n",
    " HumanMessage(content='I am interested to know which of the creatures currently inhabiting Earth has the longest lifespan. Which creature lives the longest?', additional_kwargs={}, response_metadata={}, id='c74388a7-8d81-4376-80a2-0bf9e9f3307e'),\n",
    " AIMessage(content='Ah, the quest for immortality through the animal kingdom! The creature with the longest lifespan is the ocean quahog clam (*Arctica islandica*), some of which have been known to live over 500 years. One particular clam, nicknamed \"Ming,\" was found to be 507 years old! Talk about a slow pace of life.\\n\\nIf you\\'re wondering about vertebrates, the Greenland shark (*Somniosus microcephalus*) holds the record, with some individuals estimated to live up to 400 years. Clearly, the secret to a long life involves living in cold, deep waters and moving at a glacial pace. Maybe we should take notes?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 136, 'prompt_tokens': 90, 'total_tokens': 226, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a20a4ee344', 'finish_reason': 'stop', 'logprobs': None}, id='run-61dcc765-b95a-45ec-affd-0e1aa5eb9c85-0', usage_metadata={'input_tokens': 90, 'output_tokens': 136, 'total_tokens': 226, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
    " HumanMessage(content=\"Isn't there some jellyfish that lives longer?\", additional_kwargs={}, response_metadata={}, id='7b0088d3-e244-482d-bc2f-4393c3fd49e8'),\n",
    " AIMessage(content='Ah, you\\'re thinking of the infamous *Turritopsis dohrnii*, often dubbed the \"immortal jellyfish.\" This little marvel of the sea has a fascinating trick up its tentacles: it can revert its cells to an earlier stage of development when it faces environmental stress or injury, essentially starting its life cycle over again. It\\'s like being able to hit a biological \"reset\" button, which theoretically means it could live indefinitely under the right conditions. \\n\\nHowever, while this jellyfish can potentially keep resetting its life clock, it doesn\\'t make them invincible—they still face threats from predators and disease. So, while not immortal in the traditional sense, *Turritopsis dohrnii* certainly has mastered the art of a comeback!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 150, 'prompt_tokens': 244, 'total_tokens': 394, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e5e4913e83', 'finish_reason': 'stop', 'logprobs': None}, id='run-d2b9fa26-3e32-4397-a533-2e3d2e4d8cd9-0', usage_metadata={'input_tokens': 244, 'output_tokens': 150, 'total_tokens': 394, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
    " HumanMessage(content='How big is it? Where does it live?', additional_kwargs={}, response_metadata={}, id='399799d4-561c-43b2-9ae8-c8f29277f857'),\n",
    " AIMessage(content='The *Turritopsis dohrnii* is quite the diminutive wonder—it measures only about 4.5 millimeters in diameter, which is about the size of your pinky nail! Despite its tiny size, it has managed to capture a lot of attention with its unique ability to cheat death.\\n\\nAs for its habitat, the \"immortal jellyfish\" is originally from the Mediterranean Sea, but it has spread to various oceans around the world, likely hitching rides in ballast water of ships. It\\'s found in temperate to tropical waters, although it\\'s not the kind of critter you\\'d easily spot during a seaside stroll, given its small size and translucency. It\\'s like the secret agent of the ocean, quietly doing its thing while evading notice!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 153, 'prompt_tokens': 412, 'total_tokens': 565, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e5e4913e83', 'finish_reason': 'stop', 'logprobs': None}, id='run-3f42cc7e-89fc-4334-83a2-f0826b4f7760-0', usage_metadata={'input_tokens': 412, 'output_tokens': 153, 'total_tokens': 565, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
    " HumanMessage(content=\"Well if this jellyfish does not really die off, wouldn't we be swamped with the little creatures, sooner or later?\", additional_kwargs={}, response_metadata={}, id='4e32ca8b-2cca-4bcc-9bf3-858e6b29448b')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b36d1f71-5d96-4d6c-9cc6-4df43766e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = graph.invoke({\"messages\": messages_so_far}, config={\"configurable\": {\"thread_id\": 48}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "16088b7a-7142-414d-902d-4cd104d2499a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I am interested to know which of the creatures currently inhabiting Earth has the longest lifespan. Which creature lives the longest?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ah, the quest for immortality through the animal kingdom! The creature with the longest lifespan is the ocean quahog clam (*Arctica islandica*), some of which have been known to live over 500 years. One particular clam, nicknamed \"Ming,\" was found to be 507 years old! Talk about a slow pace of life.\n",
      "\n",
      "If you're wondering about vertebrates, the Greenland shark (*Somniosus microcephalus*) holds the record, with some individuals estimated to live up to 400 years. Clearly, the secret to a long life involves living in cold, deep waters and moving at a glacial pace. Maybe we should take notes?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Isn't there some jellyfish that lives longer?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ah, you're thinking of the infamous *Turritopsis dohrnii*, often dubbed the \"immortal jellyfish.\" This little marvel of the sea has a fascinating trick up its tentacles: it can revert its cells to an earlier stage of development when it faces environmental stress or injury, essentially starting its life cycle over again. It's like being able to hit a biological \"reset\" button, which theoretically means it could live indefinitely under the right conditions. \n",
      "\n",
      "However, while this jellyfish can potentially keep resetting its life clock, it doesn't make them invincible—they still face threats from predators and disease. So, while not immortal in the traditional sense, *Turritopsis dohrnii* certainly has mastered the art of a comeback!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ah, you're thinking of the infamous *Turritopsis dohrnii*, often dubbed the \"immortal jellyfish.\" This little marvel of the sea has a fascinating trick up its tentacles: it can revert its cells to an earlier stage of development when it faces environmental stress or injury, essentially starting its life cycle over again. It's like being able to hit a biological \"reset\" button, which theoretically means it could live indefinitely under the right conditions. \n",
      "\n",
      "However, while this jellyfish can potentially keep resetting its life clock, it doesn't make them invincible—they still face threats from predators and disease. So, while not immortal in the traditional sense, *Turritopsis dohrnii* certainly has mastered the art of a comeback!\n"
     ]
    }
   ],
   "source": [
    "for item in r[\"messages\"]:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "15cd5381-6ef3-4fa5-9588-dd8260f9a0f8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='How big is it? Where does it live?', additional_kwargs={}, response_metadata={}, id='399799d4-561c-43b2-9ae8-c8f29277f857'),\n",
       " AIMessage(content='The *Turritopsis dohrnii* is quite the diminutive wonder—it measures only about 4.5 millimeters in diameter, which is about the size of your pinky nail! Despite its tiny size, it has managed to capture a lot of attention with its unique ability to cheat death.\\n\\nAs for its habitat, the \"immortal jellyfish\" is originally from the Mediterranean Sea, but it has spread to various oceans around the world, likely hitching rides in ballast water of ships. It\\'s found in temperate to tropical waters, although it\\'s not the kind of critter you\\'d easily spot during a seaside stroll, given its small size and translucency. It\\'s like the secret agent of the ocean, quietly doing its thing while evading notice!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 153, 'prompt_tokens': 412, 'total_tokens': 565, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e5e4913e83', 'finish_reason': 'stop', 'logprobs': None}, id='run-3f42cc7e-89fc-4334-83a2-f0826b4f7760-0', usage_metadata={'input_tokens': 412, 'output_tokens': 153, 'total_tokens': 565, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       " HumanMessage(content=\"Well if this jellyfish does not really die off, wouldn't we be swamped with the little creatures, sooner or later?\", additional_kwargs={}, response_metadata={}, id='4e32ca8b-2cca-4bcc-9bf3-858e6b29448b'),\n",
       " HumanMessage(content=\"Well if this jellyfish does not really die off, wouldn't we be swamped with the little creatures, sooner or later?\", additional_kwargs={}, response_metadata={}, id='1be25f0a-871a-4cad-bb56-733e64171959'),\n",
       " AIMessage(content='Ah, the intrigue of the \"immortal\" jellyfish! While *Turritopsis dohrnii* does have a nifty trick up its tentacles with the ability to revert back to its juvenile form, this doesn\\'t necessarily mean they\\'ll take over the oceans. \\n\\nFirst, not all of them manage to pull off this Benjamin Button act successfully. They can still fall victim to predators, disease, and environmental factors. Plus, reverting to a younger state requires specific conditions that aren\\'t always present in their natural habitat.\\n\\nThink of it this way: it\\'s like a superhero with a superpower that only works sometimes, and even then, they have to dodge all kinds of other dangers. So, while they\\'re fascinating and certainly a marvel of nature, we\\'re not at risk of a jellyfish world takeover just yet. They\\'ll just continue their covert operations under the sea!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 171, 'prompt_tokens': 262, 'total_tokens': 433, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e5e4913e83', 'finish_reason': 'stop', 'logprobs': None}, id='run-3d4ea530-7365-409f-bfb5-ff9e751be8dc-0', usage_metadata={'input_tokens': 262, 'output_tokens': 171, 'total_tokens': 433, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e568db-89b9-45b8-9c7c-ca157403f0b5",
   "metadata": {},
   "source": [
    "An example with trimmed messages. We will employ `trim_messsages` function inside the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "572a9a9a-22d4-4217-b5c4-431fb838e68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant_with_trim)\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_edge(\"assistant\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e6536c6-4ce7-42e5-84b1-bec7245fb5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = graph.invoke({\"messages\": messages_so_far}, config={\"configurable\": {\"thread_id\": 48}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7287d8c4-dbeb-4149-a661-05d805bbf83e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hey AI can you answer some animal questions?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure, go ahead and ask, I am here to assist\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I am interested to know which of the creatures currently inhabiting Earth has the longest lifespan. Which creature lives the longest?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ah, the quest for immortality through the animal kingdom! The creature with the longest lifespan is the ocean quahog clam (*Arctica islandica*), some of which have been known to live over 500 years. One particular clam, nicknamed \"Ming,\" was found to be 507 years old! Talk about a slow pace of life.\n",
      "\n",
      "If you're wondering about vertebrates, the Greenland shark (*Somniosus microcephalus*) holds the record, with some individuals estimated to live up to 400 years. Clearly, the secret to a long life involves living in cold, deep waters and moving at a glacial pace. Maybe we should take notes?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Isn't there some jellyfish that lives longer?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ah, you're thinking of the infamous *Turritopsis dohrnii*, often dubbed the \"immortal jellyfish.\" This little marvel of the sea has a fascinating trick up its tentacles: it can revert its cells to an earlier stage of development when it faces environmental stress or injury, essentially starting its life cycle over again. It's like being able to hit a biological \"reset\" button, which theoretically means it could live indefinitely under the right conditions. \n",
      "\n",
      "However, while this jellyfish can potentially keep resetting its life clock, it doesn't make them invincible—they still face threats from predators and disease. So, while not immortal in the traditional sense, *Turritopsis dohrnii* certainly has mastered the art of a comeback!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How big is it? Where does it live?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The *Turritopsis dohrnii* is quite the diminutive wonder—it measures only about 4.5 millimeters in diameter, which is about the size of your pinky nail! Despite its tiny size, it has managed to capture a lot of attention with its unique ability to cheat death.\n",
      "\n",
      "As for its habitat, the \"immortal jellyfish\" is originally from the Mediterranean Sea, but it has spread to various oceans around the world, likely hitching rides in ballast water of ships. It's found in temperate to tropical waters, although it's not the kind of critter you'd easily spot during a seaside stroll, given its small size and translucency. It's like the secret agent of the ocean, quietly doing its thing while evading notice!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Well if this jellyfish does not really die off, wouldn't we be swamped with the little creatures, sooner or later?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ah, the sweet dream of jellyfish world domination! While it's true that the *Turritopsis dohrnii* has the potential to revert to its juvenile form and essentially start its life cycle over, it's not as simple as it sounds for them to take over the world.\n",
      "\n",
      "First, the process of reverting to a younger state isn't always a guarantee—it often requires the jellyfish to be in a stressed or injured state, and even then, it doesn't always survive the process. Plus, they still have to deal with predators, disease, and environmental factors. It's a tough life for a jellyfish, even an \"immortal\" one.\n",
      "\n",
      "Also, their immortality doesn't translate to rapid reproduction. They're not exactly cranking out baby jellyfish at a rate that would flood the oceans. So, while their life cycle is fascinating, they're not likely to stage a jellyfish coup anytime soon. We can breathe easy—for now, at least!\n"
     ]
    }
   ],
   "source": [
    "for item in r[\"messages\"]:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff72b8d9-8cf0-4050-9e24-c7f8a72e3b17",
   "metadata": {},
   "source": [
    "### Summarising instead of trimming or filtering\n",
    "\n",
    "Let's try to summarise a previous conversation once it reaches a certain number of exchanges. Once we summarise we continuously add to the summary every n-new exchanges creating an inexhaustable context window.\n",
    "\n",
    "We'll achieve this as follows:\n",
    "\n",
    "- Add a model calling assistant which takes into account any existing summary + the conversation after.\n",
    "- Add a summarisation node that creates a summary based on the conversation thus far and **deletes** all previous messages\n",
    "- Add a conditional edge which either outputs the current conversation or creates a summary first and then calls the assistant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e34cd19-52e5-4d8b-a820-5aa50ad42753",
   "metadata": {},
   "source": [
    "Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68e5805-8fd3-40b6-8b07-44e535a72239",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_groq\n",
      "  Downloading langchain_groq-0.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
      "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3 in /opt/conda/lib/python3.11/site-packages (from langchain_groq) (0.3.12)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain_groq) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain_groq) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.11/site-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain_groq) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain_groq) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain_groq) (0.1.136)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain_groq) (24.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain_groq) (8.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (3.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (2.2.2)\n",
      "Downloading langchain_groq-0.2.0-py3-none-any.whl (14 kB)\n",
      "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: groq, langchain_groq\n",
      "Successfully installed groq-0.11.0 langchain_groq-0.2.0\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.42.4)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n",
      "Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.42.4\n",
      "    Uninstalling transformers-4.42.4:\n",
      "      Successfully uninstalled transformers-4.42.4\n",
      "Successfully installed tokenizers-0.20.1 transformers-4.45.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_groq\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ea23ef-0215-4050-8d9d-ee2f6702f4c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph-checkpoint-sqlite in /opt/conda/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: aiosqlite<0.21.0,>=0.20.0 in /opt/conda/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (0.20.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (2.0.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /opt/conda/lib/python3.11/site-packages (from aiosqlite<0.21.0,>=0.20.0->langgraph-checkpoint-sqlite) (4.12.2)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.2.38 in /opt/conda/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (0.3.12)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (1.1.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (0.1.136)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (8.5.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (3.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (2.20.1)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (4.4.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.0->langgraph-checkpoint-sqlite) (2.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph-checkpoint-sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aea60af-12db-4b8d-969d-86d6ce0efa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "from langgraph.graph import MessagesState, START, END, StateGraph\n",
    "from pprint import pprint\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import Image, display\n",
    "from typing_extensions import TypedDict, Literal\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import RemoveMessage, trim_messages\n",
    "import sqlite3\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ee973-2c56-4ebb-afeb-7ebaa7691890",
   "metadata": {},
   "source": [
    "The state (we extend the MessagesState with a new property 'summary'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e430d0b0-e624-486c-91c1-2e5fd935bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    summary: str;\n",
    "\n",
    "# lets create the generic System Message as well:\n",
    "sys_msg = SystemMessage('You are an everhelpful assistant trying to assist your human friend. You are polite, thoughtful \\\n",
    "and with great sense of nerdy humour.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db197744-4505-4810-86d4-ae875189177c",
   "metadata": {},
   "source": [
    "The Nodes:\n",
    "\n",
    "- assistant\n",
    "- summariser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76395ea-5737-49b1-a6ad-c731eabe6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: State):\n",
    "    summary = state.get('summary', '')\n",
    "    if summary:\n",
    "        system_msg = SystemMessage(f'{sys_msg.content}\\nSummary of our the conversation thus far:{summary}')\n",
    "    else:\n",
    "        system_msg = sys_msg\n",
    "    result = llm.invoke([system_msg] + state['messages'])\n",
    "    return {'messages': result}\n",
    "\n",
    "def summariser(state: State):\n",
    "    summary = state.get('summary', '')\n",
    "    if summary:\n",
    "        summary_message = f'Extend the current summary: {summary} with the conversation thus far.'\n",
    "    else:\n",
    "        summary_message = 'Summarise the conversation thus far'\n",
    "    result = llm.invoke(state['messages'] + [HumanMessage(summary_message)])\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {'summary': result.content, 'messages': delete_messages}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd4c9c8-b14e-450c-9eed-6831128c03c0",
   "metadata": {},
   "source": [
    "The Condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab114fc-21d0-4416-adf6-a882e5ededc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_summarise(state: State) -> Literal['summariser', END]:\n",
    "    if len(state['messages']) > 6:\n",
    "        return \"summariser\"\n",
    "    else:\n",
    "        return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ecf53-41f7-49c9-b7e2-97b1951d3ec4",
   "metadata": {},
   "source": [
    "Create the Graph with Memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00018099-c540-4ac0-94fa-386bd8bc7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.75)\n",
    "# llm = ChatGroq(model=\"llama-3.1-70b-versatile\", temperature=0.5, model_kwargs={\"top_p\": 0.5})\n",
    "conn = sqlite3.connect(\"./data/sqlite/memory-sum-example.db\", check_same_thread=False)\n",
    "memory = SqliteSaver(conn)\n",
    "# memory = MemorySaver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b278be-b19b-4c81-a9c8-0ba26cffed44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4dbaf1f0e1499282d18e6d14732bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What if we try and load a local model again!!\n",
    "# It just does not work. We must overwrite the reducer of the MessagesState to use the correct template for Llama 3.1 instruct, \n",
    "# instead of the Chat template used.\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    GenerationConfig,\n",
    "    pipeline\n",
    ")\n",
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace, HuggingFaceEndpoint\n",
    "\n",
    "model_name = \"../ext_models/Meta-Llama-3.1-8B-Instruct\"\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, \n",
    "#                                              device_map=DEVICE, \n",
    "#                                              torch_dtype=\"auto\")\n",
    "\n",
    "generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "stop_token = \"<|eot_id|>\"  \n",
    "stop_token_id = tokenizer.encode(stop_token)[0]\n",
    "begin_token = \"<|begin_of_text|>\"\n",
    "begin_token_id = tokenizer.encode(begin_token)[0]\n",
    "generation_config.eos_token_id = stop_token_id\n",
    "generation_config.begin_token_id = begin_token_id\n",
    "config = generation_config.to_dict()\n",
    "\n",
    "trimmed_gen = {\n",
    "    **config,\n",
    "    \"top_p\": 0.9,  # changed from 0.15\n",
    "    \"temperature\":0.1,\n",
    "    \"do_sample\": False,  # changed from true\n",
    "    \"torch_dtype\": torch.bfloat16,  # bfloat16\n",
    "    \"use_fast\": True,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "}\n",
    "\n",
    "llm_pipeline = pipeline(\"text-generation\", \n",
    "                        model=model_name,  \n",
    "                        device_map=DEVICE,\n",
    "                        torch_dtype=torch.bfloat16,\n",
    "                        max_new_tokens=1024,\n",
    "                        return_full_text=False) \n",
    "llm_pipeline.tokenizer.pad_token_id = llm_pipeline.model.config.eos_token_id = stop_token_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadfe7f2-3238-44ce-b72f-a34e85ac15df",
   "metadata": {},
   "source": [
    "> Note: **IMPORTANT**: Passing the tokenizer works wonders and the ChatHuggingFace seems to be fully operational for graph use. Still cannot work well with tools.. Perhaps I need to find another model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5590edc-2c89-4388-8820-261ab2cf4cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_llm_with_pipe = HuggingFacePipeline(pipeline=llm_pipeline, pipeline_kwargs=trimmed_gen)\n",
    "llm = ChatHuggingFace(llm=open_llm_with_pipe, verbose=True, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a13d47b2-dc34-4b09-bcf5-f2635d8dd3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1fded17-05cb-40e5-85a7-9e23fb878130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "builder = StateGraph(State)\n",
    "builder.add_node(\"assistant\", call_model)\n",
    "builder.add_node(\"summariser\", summariser)\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", should_summarise)\n",
    "builder.add_edge(\"summariser\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10792051-4ff4-4c97-9627-f12e907ff528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# messages = [HumanMessage(\"Hey AI can you answer some animal questions?\"), AIMessage(\"Sure, go ahead and ask, I am here to assist\")]\n",
    "messages = [(HumanMessage(\"I am interested to know which of the creatures currently inhabiting Earth has the longest lifespan. \\\n",
    "In other words which creature lives the longest?\"))]\n",
    "config = {\"configurable\": {\"thread_id\": 45}}\n",
    "r = graph.invoke({'messages': messages}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e70993e-dfa6-4a08-82d2-a60fb5e3f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I am interested to know which of the creatures currently inhabiting Earth has the longest lifespan. In other words which creature lives the longest?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "My curious friend, you're asking about the ultimate record holder of longevity on our beloved planet Earth. I've got some fascinating news for you!\n",
      "\n",
      "According to the latest scientific research, the creature that holds the record for the longest lifespan is... (dramatic pause)...the **Turritopsis dohrnii**, also known as the \"immortal jellyfish\"! However, this might not be exactly what you're looking for, as it's a type of jellyfish that can transform its body into a younger state through a process called transdifferentiation, essentially making it theoretically \"immortal.\"\n",
      "\n",
      "But if we're looking for a more traditional, non-regenerative creature with an impressive lifespan, the title goes to the **Ocean quahog**, a type of clam ( genus Arctica). One individual, named **Ming**, was found in 2012 off the coast of Iceland and is estimated to be around **562 years old**! Yes, you read that right – 562 years!\n",
      "\n",
      "However, the oldest land animal on record is the **Bowhead whale**, with an estimated age of around **211 years**, although this is based on radiocarbon dating of eye lens nuclei and not direct observation.\n",
      "\n",
      "Lastly, the longest-lived bird is the **Laysan albatross**, with one individual, named **Wisdom**, estimated to be around **70 years old**.\n",
      "\n",
      "So, while there are some incredible examples of long-lived creatures on our planet, the title of the longest-lived creature is still a matter of some debate among scientists. But I hope this gives you a good idea of the amazing diversity of life on Earth!\n",
      "\n",
      "Would you like to know more about any of these creatures or is there something else I can help you with?\n"
     ]
    }
   ],
   "source": [
    "for item in r[\"messages\"]:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a2c3d3a-1b6c-4656-b367-ef406b772a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "r = graph.invoke({'messages': HumanMessage('Can you tell me more about a wonderful shark that lives hundreds of years, too?')}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e57b2ef-9b4c-4b03-a4b8-0f9baae664b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I am interested to know which of the creatures currently inhabiting Earth has the longest lifespan. In other words which creature lives the longest?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "My curious friend, you're asking about the ultimate record holder of longevity on our beloved planet Earth. I've got some fascinating news for you!\n",
      "\n",
      "According to the latest scientific research, the creature that holds the record for the longest lifespan is... (dramatic pause)...the **Turritopsis dohrnii**, also known as the \"immortal jellyfish\"! However, this might not be exactly what you're looking for, as it's a type of jellyfish that can transform its body into a younger state through a process called transdifferentiation, essentially making it theoretically \"immortal.\"\n",
      "\n",
      "But if we're looking for a more traditional, non-regenerative creature with an impressive lifespan, the title goes to the **Ocean quahog**, a type of clam ( genus Arctica). One individual, named **Ming**, was found in 2012 off the coast of Iceland and is estimated to be around **562 years old**! Yes, you read that right – 562 years!\n",
      "\n",
      "However, the oldest land animal on record is the **Bowhead whale**, with an estimated age of around **211 years**, although this is based on radiocarbon dating of eye lens nuclei and not direct observation.\n",
      "\n",
      "Lastly, the longest-lived bird is the **Laysan albatross**, with one individual, named **Wisdom**, estimated to be around **70 years old**.\n",
      "\n",
      "So, while there are some incredible examples of long-lived creatures on our planet, the title of the longest-lived creature is still a matter of some debate among scientists. But I hope this gives you a good idea of the amazing diversity of life on Earth!\n",
      "\n",
      "Would you like to know more about any of these creatures or is there something else I can help you with?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you tell me more about a wonderful shark that lives hundreds of years, too?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You're referring to the legendary **Greenland shark** (Somniosus microcephalus), my friend! This incredible creature has been making waves in the scientific community with its remarkable age record.\n",
      "\n",
      "Greenland sharks are found in the Arctic and North Atlantic oceans, and they're known for their slow growth rate and unique ability to live for hundreds of years. In fact, a study published in 2016 estimated that a Greenland shark found in the North Atlantic was around **392 years old**! This makes it one of the longest-lived vertebrates on the planet.\n",
      "\n",
      "To put that into perspective, when the first European settlers arrived in the Americas, this shark was already swimming in the oceans. That's a truly mind-boggling thought!\n",
      "\n",
      "But what's even more fascinating is that this shark's slow growth rate is thought to be one of the reasons for its remarkable longevity. They grow at a rate of about 1 cm (0.4 in) per year, which is incredibly slow compared to other shark species. This slow growth rate allows them to live for centuries, making them one of the most enduring creatures on the planet.\n",
      "\n",
      "Greenland sharks are also known for their unique appearance, with a stocky build and a distinctive greenish-brown color. They're apex predators, feeding on fish, seals, and other marine mammals. Despite their fearsome reputation, they're actually relatively small, reaching a maximum length of about 6 meters (20 feet).\n",
      "\n",
      "It's worth noting that the age of the Greenland shark is still a subject of ongoing research, and some scientists have questioned the accuracy of the 392-year estimate. However, it's clear that these incredible creatures are living longer than previously thought, and their longevity is a testament to the incredible diversity and resilience of life on our planet.\n",
      "\n",
      "Would you like to know more about these amazing sharks or is there something else I can help you with?\n"
     ]
    }
   ],
   "source": [
    "for item in r[\"messages\"]:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b70a80bc-df6c-44a0-9506-82f3957207a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I am interested to know which of the creatures currently inhabiting Earth has the longest lifespan. In other words which creature lives the longest?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "My curious friend, you're asking about the ultimate record holder of longevity on our beloved planet Earth. I've got some fascinating news for you!\n",
      "\n",
      "According to the latest scientific research, the creature that holds the record for the longest lifespan is... (dramatic pause)...the **Turritopsis dohrnii**, also known as the \"immortal jellyfish\"! However, this might not be exactly what you're looking for, as it's a type of jellyfish that can transform its body into a younger state through a process called transdifferentiation, essentially making it theoretically \"immortal.\"\n",
      "\n",
      "But if we're looking for a more traditional, non-regenerative creature with an impressive lifespan, the title goes to the **Ocean quahog**, a type of clam ( genus Arctica). One individual, named **Ming**, was found in 2012 off the coast of Iceland and is estimated to be around **562 years old**! Yes, you read that right – 562 years!\n",
      "\n",
      "However, the oldest land animal on record is the **Bowhead whale**, with an estimated age of around **211 years**, although this is based on radiocarbon dating of eye lens nuclei and not direct observation.\n",
      "\n",
      "Lastly, the longest-lived bird is the **Laysan albatross**, with one individual, named **Wisdom**, estimated to be around **70 years old**.\n",
      "\n",
      "So, while there are some incredible examples of long-lived creatures on our planet, the title of the longest-lived creature is still a matter of some debate among scientists. But I hope this gives you a good idea of the amazing diversity of life on Earth!\n",
      "\n",
      "Would you like to know more about any of these creatures or is there something else I can help you with?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you tell me more about a wonderful shark that lives hundreds of years, too?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You're referring to the legendary **Greenland shark** (Somniosus microcephalus), my friend! This incredible creature has been making waves in the scientific community with its remarkable age record.\n",
      "\n",
      "Greenland sharks are found in the Arctic and North Atlantic oceans, and they're known for their slow growth rate and unique ability to live for hundreds of years. In fact, a study published in 2016 estimated that a Greenland shark found in the North Atlantic was around **392 years old**! This makes it one of the longest-lived vertebrates on the planet.\n",
      "\n",
      "To put that into perspective, when the first European settlers arrived in the Americas, this shark was already swimming in the oceans. That's a truly mind-boggling thought!\n",
      "\n",
      "But what's even more fascinating is that this shark's slow growth rate is thought to be one of the reasons for its remarkable longevity. They grow at a rate of about 1 cm (0.4 in) per year, which is incredibly slow compared to other shark species. This slow growth rate allows them to live for centuries, making them one of the most enduring creatures on the planet.\n",
      "\n",
      "Greenland sharks are also known for their unique appearance, with a stocky build and a distinctive greenish-brown color. They're apex predators, feeding on fish, seals, and other marine mammals. Despite their fearsome reputation, they're actually relatively small, reaching a maximum length of about 6 meters (20 feet).\n",
      "\n",
      "It's worth noting that the age of the Greenland shark is still a subject of ongoing research, and some scientists have questioned the accuracy of the 392-year estimate. However, it's clear that these incredible creatures are living longer than previously thought, and their longevity is a testament to the incredible diversity and resilience of life on our planet.\n",
      "\n",
      "Would you like to know more about these amazing sharks or is there something else I can help you with?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Wonderful! Thanks a lot for all this knowledge! What do you think is the oldest living creature that lives on land?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "My friend, I'm glad you asked! While it's challenging to pinpoint a single oldest living creature on land, I'd like to introduce you to the **bristlecone pine tree**, specifically the **Methuselah** tree, found in White Mountains of California, USA.\n",
      "\n",
      "Methuselah is a Great Basin bristlecone pine (Pinus longaeva) that's estimated to be around **4,855 years old**! Yes, you read that right – 4,855 years young (or old, depending on how you look at it). This ancient tree is a member of a species that's known for its remarkable longevity, with some individuals living for over 5,000 years.\n",
      "\n",
      "To put that into perspective, when the pyramids of Giza were being built, Methuselah was just a sapling. When the ancient civilizations of Greece and Rome rose to power, this tree was already a mature adult. It's an incredible thought that this tree has seen the rise and fall of empires, the birth and death of stars, and the evolution of countless species.\n",
      "\n",
      "The age of Methuselah was determined through a process called dendrochronology, which is the study of the growth rings of trees. By counting the rings, scientists can determine the age of the tree, as well as the climate and environmental conditions it's experienced over the centuries.\n",
      "\n",
      "Other contenders for the oldest living creature on land include the **Yew tree** (Taxus baccata), which can live for up to 2,000 years, and the **Redwood trees** (Sequoia sempervirens), which can live for over 2,500 years. However, the bristlecone pine tree takes the crown for the oldest living creature on land.\n",
      "\n",
      "Would you like to know more about these incredible trees or is there something else I can help you with?\n"
     ]
    }
   ],
   "source": [
    "r = graph.invoke({'messages': HumanMessage('Wonderful! Thanks a lot for all this knowledge! What do you think is the oldest living creature that lives on land?')}, config=config)\n",
    "for item in r[\"messages\"]:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99a6739d-d3f7-4004-b08a-a3d744ed4f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Thats really cool! What wonderful trees! What about an old land dwelling animal? (or bird?)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Let me tell you about the **Jonathan**, a Seychelles giant tortoise (Geochelone gigantea) that's been making headlines for its incredible age. Jonathan was born in 1882, which makes him... (dramatic pause)... **136 years old**! Yes, you read that right – 136 years young!\n",
      "\n",
      "Jonathan lives on the island of Saint Helena, a British Overseas Territory in the South Atlantic Ocean. He's been a resident of the Saint Helena National Trust, a wildlife reserve, since 1882, and has become a beloved celebrity of sorts.\n",
      "\n",
      "As a giant tortoise, Jonathan is a member of one of the longest-living animal species on land. They can live for up to 150 years or more in the wild, and their slow growth rate and low metabolic rate contribute to their remarkable longevity.\n",
      "\n",
      "Jonathan has seen the rise and fall of empires, the invention of the automobile, the two World Wars, and the moon landing. He's even met some famous visitors, including the British monarchs, Queen Elizabeth II and Prince Philip.\n",
      "\n",
      "It's worth noting that Jonathan's age has been verified through various records and photographs, making him one of the most well-documented long-lived animals on record.\n",
      "\n",
      "Other contenders for the oldest land-dwelling animal include the **Tuatara** (Sphenodon punctatus), a reptile from New Zealand that can live for up to 200 years, and the **Rockfish**, which can live for up to 282 years. However, Jonathan the tortoise holds the title for the oldest land-dwelling animal.\n",
      "\n",
      "Would you like to know more about these incredible animals or is there something else I can help you with?\n"
     ]
    }
   ],
   "source": [
    "r = graph.invoke({'messages': HumanMessage('Thats really cool! What wonderful trees! What about an old land dwelling animal? (or bird?)')}, config=config)\n",
    "for item in r[\"messages\"]:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ead306b-1de4-4ea4-a271-edc73522f639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Thats really cool! What wonderful trees! What about an old land dwelling animal? (or bird?)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Let me tell you about the **Jonathan**, a Seychelles giant tortoise (Geochelone gigantea) that's been making headlines for its incredible age. Jonathan was born in 1882, which makes him... (dramatic pause)... **136 years old**! Yes, you read that right – 136 years young!\n",
      "\n",
      "Jonathan lives on the island of Saint Helena, a British Overseas Territory in the South Atlantic Ocean. He's been a resident of the Saint Helena National Trust, a wildlife reserve, since 1882, and has become a beloved celebrity of sorts.\n",
      "\n",
      "As a giant tortoise, Jonathan is a member of one of the longest-living animal species on land. They can live for up to 150 years or more in the wild, and their slow growth rate and low metabolic rate contribute to their remarkable longevity.\n",
      "\n",
      "Jonathan has seen the rise and fall of empires, the invention of the automobile, the two World Wars, and the moon landing. He's even met some famous visitors, including the British monarchs, Queen Elizabeth II and Prince Philip.\n",
      "\n",
      "It's worth noting that Jonathan's age has been verified through various records and photographs, making him one of the most well-documented long-lived animals on record.\n",
      "\n",
      "Other contenders for the oldest land-dwelling animal include the **Tuatara** (Sphenodon punctatus), a reptile from New Zealand that can live for up to 200 years, and the **Rockfish**, which can live for up to 282 years. However, Jonathan the tortoise holds the title for the oldest land-dwelling animal.\n",
      "\n",
      "Would you like to know more about these incredible animals or is there something else I can help you with?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Thank you sport! You have been a great assistance. I will ask some more questions later.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It was my pleasure to help and geek out about these incredible creatures with you. I'm always here to assist and provide more info whenever you're ready.\n",
      "\n",
      "Feel free to come back and ask me anything, anytime. I'll be here, ready to dive into more fascinating topics, from the depths of the ocean to the heights of space (or anywhere in between!).\n",
      "\n",
      "Until next time, stay curious, and keep exploring the wonders of our amazing world!\n"
     ]
    }
   ],
   "source": [
    "r = graph.invoke({'messages': HumanMessage('Thank you sport! You have been a great assistance. I will ask some more questions later.')}, config=config)\n",
    "for item in r[\"messages\"]:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7180550c-3503-4fae-be1e-3aed0dde6762",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = graph.get_state({\"configurable\": {\"thread_id\": 44}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87a7f017-e2bd-4fdd-9e40-0e90461b4bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='I am interested to know which of the creatures currently inhabiting Earth has the longest lifespan. In other words which creature lives the longest?', additional_kwargs={}, response_metadata={}, id='554019e1-4ee6-4bb0-ab29-004cdf9c6521'),\n",
      "              HumanMessage(content='I am interested to know which of the creatures currently inhabiting Earth has the longest lifespan. In other words which creature lives the longest?', additional_kwargs={}, response_metadata={}, id='96764edd-f438-4bf1-afbb-4f0786890c06'),\n",
      "              AIMessage(content='A question that\\'s sure to make you live a little longer, knowing about the creatures that outlast us all. \\n\\nAccording to scientific records, the longest-living creature on Earth is the **Turritopsis dohrnii**, also known as the \"immortal jellyfish.\" However, this one\\'s lifespan is more about its ability to cheat death, rather than actually living forever. It can transform its body into a younger state through a process called transdifferentiation, essentially making it biologically immortal.\\n\\nBut, if we\\'re talking about a more traditional sense of lifespan, the longest-living land animal is the **Bowhead whale\\'s cousin, the Ocean quahog (Arctica islandica)**, nope, not quite, actually it\\'s the **Ocean quahog\\'s cousin, the Bowhead whale\\'s cousin, the Greenland shark\\'s cousin, nope, the actual answer is the **Ocean quahog\\'s cousin, the Greenland shark\\'s cousin, nope**... I\\'m just kidding about the cousins.\\n\\nSeriously, the longest-living land animal is actually the **Ocean quahog\\'s cousin, no, not really, it\\'s actually the **Turritopsis dohrnii\\'s** cousin, no... actually, I\\'m just kidding about the cousins again. \\n\\nSeriously, the longest-living land animal is actually the **Turritopsis dohrnii\\'s cousin, no, it\\'s actually the **Turritopsis dohrnii**\\'s land cousin, no... I\\'m kidding again.\\n\\nActually, the longest-living land animal is the **Turritopsis dohrnii\\'s... no, I\\'ll stop with the cousins. Seriously, the longest-living land animal is actually the **Bowhead whale\\'s cousin, no... I mean, not really, it\\'s actually the **Turritopsis dohrnii\\'s**... no, just kidding.\\n\\nSeriously, the longest-living land animal is actually the **Ocean quahog (Arctica islandica)** cousin\\'s cousin\\'s cousin, no... actually, I\\'m just kidding. The actual longest-living land animal is the **Ocean quahog (Arctica islandica)**\\'s... no, I mean, the actual answer is the **Ocean quahog (Arctica islandica)**\\'s... cousin... no, I mean, the actual answer is the **Ocean quahog (Arctica islandica)**, but not really.\\n\\nSeriously, the longest-living land animal is actually the **Ocean quahog (Arctica islandica)**, but actually it\\'s the **Turritopsis dohrnii**\\'s cousin... no, I mean, not really.\\n\\nActually, I think I got a bit carried away with the cousins. Seriously, the longest-living land animal is actually the **Ocean quahog (Arctica islandica)**, but actually it\\'s the **Bowhead whale\\'s** cousin, no... just kidding.\\n\\nSeriously, the longest-living land animal is actually the **Ocean quahog (Arctica islandica)**, which can live up to **562 years**.', additional_kwargs={}, response_metadata={}, id='run-5f1141d3-f8e1-4bd0-9860-60e86c4b9a3f-0')]}\n"
     ]
    }
   ],
   "source": [
    "pprint(current_state[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
